{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83e96ec-da8c-4227-a0d4-1474eab921e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_gnn as tfgnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scipy\n",
    "import os\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import sympy as sympy\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import math as math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd176ff-1b8d-4458-b46e-a2840067c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.244\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0\n",
      "        value: 3.75\n",
      "        value: 8\n",
      "        value: 0.097\n",
      "        value: 0.055\n",
      "        value: 498\n",
      "        value: 4.62\n",
      "        value: 2.91\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 3.15\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.5\n",
      "        value: 2.99\n",
      "        value: 57\n",
      "        value: 0.068\n",
      "        value: -0.19\n",
      "        value: 1.18\n",
      "        value: 10.98\n",
      "        value: 2.8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.88\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 3.1\n",
      "        value: 3.5\n",
      "        value: 8\n",
      "        value: 590\n",
      "        value: 0.00024\n",
      "        value: 0.0543\n",
      "        value: 3.88\n",
      "        value: 2.98\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.7\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 5.4\n",
      "        value: 5\n",
      "        value: 8\n",
      "        value: 0.0071\n",
      "        value: 4.1\n",
      "        value: 0.00044\n",
      "        value: 2.85\n",
      "        value: 3.25\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.98\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.9\n",
      "        value: 3\n",
      "        value: 57\n",
      "        value: -0.0048\n",
      "        value: 0.022\n",
      "        value: -0.095\n",
      "        value: 2.56\n",
      "        value: 9.58\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.97\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 2.7\n",
      "        value: 3.38\n",
      "        value: 57\n",
      "        value: -0.00011\n",
      "        value: 0.0091\n",
      "        value: 0.228\n",
      "        value: 3.19\n",
      "        value: 7.43\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.66\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"features\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 4.7\n",
      "        value: 5.2\n",
      "        value: 8\n",
      "        value: 45\n",
      "        value: -0.088\n",
      "        value: 0.00512\n",
      "        value: 4.73\n",
      "        value: 2.9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "/Users/haydenprescott/DLNNP/DL_GCN_Potential/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_gnn.models import gcn\n",
    "from tensorflow_gnn.models import graph_sage\n",
    "from google.protobuf import text_format as text_format\n",
    "import tensorflow_gnn.proto.graph_schema_pb2 as schema_pb2\n",
    "from Determine_Bonds_Get_Input import initialize_dataset\n",
    "from Determine_Bonds_Get_Input import take_data_batch\n",
    "from Determine_Bonds_Get_Input import convert_floats_to_records\n",
    "from Determine_Bonds_Get_Input import build_graph_tensor\n",
    "from Determine_Bonds_Get_Input import molecular_graph\n",
    "from sympy.utilities.iterables import multiset_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25300e6f-2d04-4af5-b992-e6902964e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int32, None), 'node_sets': {'nuclei': NodeSetSpec({'features': {'d1': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'ACSF': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'exp3': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'z': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'r': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'exp2': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'd2': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'exp1': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'd3': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int32, None)}, 'edge_sets': {}}, TensorShape([]), tf.int32, tf.int32, None)\n"
     ]
    }
   ],
   "source": [
    "def construct_molecular_graph_schema(proto_file, proto_message):\n",
    "    graph_schema = \"\"\"\n",
    "    # proto-file: proto_file\n",
    "    # proto-message: proto_message\n",
    "    node_sets {\n",
    "      key: \"nuclei\"\n",
    "      value {\n",
    "        features {\n",
    "          key: \"z\"\n",
    "          value {\n",
    "            description: \"the atomic number of this atom\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "         }\n",
    "       } \n",
    "\n",
    "        features {\n",
    "          key: \"r\"\n",
    "          value {\n",
    "            description: \"the radial seperation of the nucleus from a common origin\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "        features{\n",
    "          key: \"ACSF\"\n",
    "          value {\n",
    "            description: \"atom-centered symmetry function describing environment near nucleus\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "\n",
    "        features{\n",
    "          key: \"d1\"\n",
    "          value {\n",
    "            description: \"first unoptimized SCF contraction coefficient\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "        features{\n",
    "          key: \"d2\"\n",
    "          value {\n",
    "            description: \"second unoptimized SCF contraction coefficient\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "        features{\n",
    "          key: \"d3\"\n",
    "          value {\n",
    "            description: \"thrid unoptimized SCF contraction coefficient\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "\n",
    "        features{\n",
    "          key: \"exp1\"\n",
    "          value {\n",
    "            description: \"first Gaussian exponential term\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "          \n",
    "          \n",
    "        features{\n",
    "          key: \"exp2\"\n",
    "          value {\n",
    "            description: \"second Gaussian exponential term\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "          \n",
    "        features{\n",
    "          key: \"exp3\"\n",
    "          value {\n",
    "            description: \"third Gaussian exponential term\"\n",
    "            dtype: DT_FLOAT\n",
    "            shape { dim { size: -1 } }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "    \"\"\"\n",
    "    graph_schema = graph_schema.replace(\"proto_file\", proto_file)\n",
    "    graph_schema = graph_schema.replace(\"proto_message\", proto_message)\n",
    "    return graph_schema\n",
    "    \n",
    "\n",
    "# These are test vals for n_nuclei and n_bonding pairs before the dataset is loaded in and initialized\n",
    "proto_file = \"//third_party/py/tensorflow_gnn/proto/graph_schema.proto\"\n",
    "proto_message = \" tensorflow_gnn.GraphSchema\"\n",
    "\n",
    "graph_schema = construct_molecular_graph_schema(proto_file, proto_message)\n",
    "graph_schema = text_format.Merge(graph_schema, schema_pb2.GraphSchema())\n",
    "graph_tensor_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)\n",
    "print(graph_tensor_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725f2c6d-ada7-4762-9233-3c3a07c0c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build initial-state graph tensor from tensor spec and graph schema\n",
    "record_filepath = \"test_data.tfrecord\"\n",
    "csv_filepath = \"/users/haydenprescott/documents/test.csv\"\n",
    "record_filename = \"test_data.tfrecord\" \n",
    "input_data_batch = tf.data.TFRecordDataset(filenames = [record_filepath])\n",
    "\n",
    "def generate_initial_graph_tensor(csv_filepath, record_filepath, record_filename):\n",
    "    initial_state, variable_state = build_graph_tensor(csv_filepath, record_filepath, record_filename)\n",
    "    return initial_state\n",
    "\n",
    "def generate_variable_state_tensor(csv_filepath, record_filepath, record_filename):\n",
    "    initial_state, variable_state = build_graph_tensor(csv_filepath, record_filepath, record_filename)\n",
    "    return variable_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3037fa42-0528-4943-9eaf-bc13e95cfdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'r' b'ACSF' b'z' b'd1' b'd2' b'd3' b'exp1' b'exp2' b'exp3']\n",
      " [b'0.0' b'3.75' b'8.0' b'0.097' b'0.055' b'498.0' b'4.62' b'2.91'\n",
      "  b'0.244']\n",
      " [b'2.5' b'2.99' b'57.0' b'0.068' b'-0.19' b'1.18' b'10.98' b'2.8'\n",
      "  b'3.15']\n",
      " [b'3.1' b'3.5' b'8.0' b'590.0' b'0.00024' b'0.0543' b'3.88' b'2.98'\n",
      "  b'0.88']\n",
      " [b'5.4' b'5.0' b'8.0' b'0.0071' b'4.1' b'0.00044' b'2.85' b'3.25' b'0.7']\n",
      " [b'1.9' b'3.0' b'57.0' b'-0.0048' b'0.022' b'-0.095' b'2.56' b'9.58'\n",
      "  b'2.98']\n",
      " [b'2.7' b'3.38' b'57.0' b'-0.00011' b'0.0091' b'0.228' b'3.19' b'7.43'\n",
      "  b'0.97']\n",
      " [b'4.7' b'5.2' b'8.0' b'45.0' b'-0.088' b'0.00512' b'4.73' b'2.9'\n",
      "  b'0.66']]\n",
      "\n",
      "\n",
      "[[b'0.0' b'3.75' b'8.0' b'0.097' b'0.055' b'498.0' b'4.62' b'2.91'\n",
      "  b'0.244']\n",
      " [b'2.5' b'2.99' b'57.0' b'0.068' b'-0.19' b'1.18' b'10.98' b'2.8'\n",
      "  b'3.15']\n",
      " [b'3.1' b'3.5' b'8.0' b'590.0' b'0.00024' b'0.0543' b'3.88' b'2.98'\n",
      "  b'0.88']\n",
      " [b'5.4' b'5.0' b'8.0' b'0.0071' b'4.1' b'0.00044' b'2.85' b'3.25' b'0.7']\n",
      " [b'1.9' b'3.0' b'57.0' b'-0.0048' b'0.022' b'-0.095' b'2.56' b'9.58'\n",
      "  b'2.98']\n",
      " [b'2.7' b'3.38' b'57.0' b'-0.00011' b'0.0091' b'0.228' b'3.19' b'7.43'\n",
      "  b'0.97']\n",
      " [b'4.7' b'5.2' b'8.0' b'45.0' b'-0.088' b'0.00512' b'4.73' b'2.9'\n",
      "  b'0.66']]\n"
     ]
    }
   ],
   "source": [
    "initial_state_tensor = generate_initial_graph_tensor(csv_filepath, record_filepath, record_filename)\n",
    "variable_state_tensor = generate_variable_state_tensor(csv_filepath, record_filepath, record_filename)\n",
    "bonding_states = {\"s\":0, \"p\":(1,2), \"d\":(3,7), \"f\":(8,)}\n",
    "delocalization_placeholder = sympy.symbols(\"None\", real = True)\n",
    "aromatic_rings = np.array([[delocalization_placeholder]])\n",
    "aromatic_cages = np.array([[delocalization_placeholder]])\n",
    "print(initial_state_tensor)\n",
    "print(\"\\n\")\n",
    "print(variable_state_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f70d66-5011-4640-82f3-e6813cd16126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Input 0: 65\n",
      "Input 1: 67\n",
      "Input 2: 83\n",
      "Input 3: 70\n"
     ]
    }
   ],
   "source": [
    "print(type(initial_state_tensor))\n",
    "for i, state_graph in enumerate(initial_state_tensor.take(1)):\n",
    "      print(f\"Input {i}: {state_graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d02ff20-7ea3-40d4-8acb-12f70cfc5b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "molecular_graph_details = molecular_graph(orbital_overlaps = np.array([\"1_2\", \"2_1\", \"1_6\", \"6_1\", \"1_7\", \"7_1\", \"2_3\", \"3_2\", \"3_4\", \"4_3\", \"3_7\", \"7_3\", \"4_5\", \"5_4\", \"5_6\", \"6_5\", \"5_7\", \"7_5\"]), n_atoms = 7, maximum_s_el = 2, maximum_p_el = 4, maximum_d_el = 0, maximum_f_el = 0)\n",
    "adj_matrix = molecular_graph_details.build_adj_matrix(molecular_graph_details.n_atoms, molecular_graph_details.orbital_overlaps)\n",
    "print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1ba8f9-5417-450c-83db-0c2c06842792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25       0.28867513 0.         0.         0.         0.28867513\n",
      "  0.25      ]\n",
      " [0.28867513 0.33333333 0.28867513 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.28867513 0.25       0.28867513 0.         0.\n",
      "  0.25      ]\n",
      " [0.         0.         0.28867513 0.33333333 0.28867513 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.28867513 0.25       0.28867513\n",
      "  0.25      ]\n",
      " [0.28867513 0.         0.         0.         0.28867513 0.33333333\n",
      "  0.        ]\n",
      " [0.25       0.         0.25       0.         0.25       0.\n",
      "  0.25      ]]\n",
      "[3. 2. 3. 2. 3. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "def graph_tensor_avg_convolution(adj_matrix, n_atoms):\n",
    "    D = np.array([])\n",
    "    identity = np.eye(n_atoms, n_atoms)\n",
    "    i = 0\n",
    "    for i in np.arange(0, n_atoms):\n",
    "        atom_i_row = adj_matrix[i]\n",
    "        D = np.append(D, np.sum(atom_i_row))\n",
    "        i += 1\n",
    "    adj_normalized = adj_matrix + identity\n",
    "    adj_norm_shape = np.zeros_like(adj_normalized)\n",
    "    np.fill_diagonal(adj_norm_shape, D)\n",
    "    D_normalized = adj_norm_shape + identity\n",
    "    D_inv = np.linalg.inv(D_normalized)\n",
    "    D_inv_root = scipy.linalg.sqrtm(D_inv)\n",
    "    comparison = D_inv_root @ adj_normalized @ D_inv_root\n",
    "    adj_normalized = np.matmul(D_inv_root, adj_normalized)\n",
    "    adj_normalized = np.matmul(adj_normalized, D_inv_root)\n",
    "    return adj_normalized\n",
    "\n",
    "def compute_node_connection_degrees(adj_matrix, n_atoms):\n",
    "    degree_vector = np.array([])\n",
    "    i = 0\n",
    "    for i in np.arange(0, n_atoms):\n",
    "        atom_i_adjacency_row = adj_matrix[i]\n",
    "        degree_vector = np.append(degree_vector, np.sum(atom_i_adjacency_row))\n",
    "        i += 1\n",
    "    return degree_vector\n",
    "    \n",
    "\n",
    "n_atoms = molecular_graph_details.n_atoms\n",
    "print(graph_tensor_avg_convolution(adj_matrix, n_atoms))\n",
    "print(compute_node_connection_degrees(adj_matrix, n_atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7b9efb-8423-4e69-b9b3-e5cab4918a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1\n",
      "[[ 2.67611070e+00  4.07636061e+00  3.69089653e+01  1.12938482e+01\n",
      "  -6.04713318e-02  1.24907735e+02  6.42802666e+00  4.40564663e+00\n",
      "   1.41534155e+00]\n",
      " [ 1.72822625e+00  3.08956139e+00  2.36188022e+01  1.70368998e+02\n",
      "  -4.73869189e-02  1.44169225e+02  6.11373864e+00  2.63362988e+00\n",
      "   1.37447085e+00]\n",
      " [ 4.23053356e+00  4.48151433e+00  2.27638837e+01  1.58771680e+02\n",
      "   1.10677978e+00  3.55618676e-01  6.14487711e+00  3.21648456e+00\n",
      "   1.49639927e+00]\n",
      " [ 3.24337567e+00  3.54305504e+00  2.14305504e+01  1.70319310e+02\n",
      "   1.37308680e+00 -1.16024113e-02  2.80906787e+00  4.70909302e+00\n",
      "   1.34761935e+00]\n",
      " [ 3.98826859e+00  4.46909763e+00  3.50138837e+01  1.12508178e+01\n",
      "   1.16969500e+00  4.34749477e-02  3.56609781e+00  6.20305044e+00\n",
      "   1.39208747e+00]\n",
      " [ 1.44848276e+00  3.07522383e+00  3.77638837e+01  2.65791807e-02\n",
      "   2.52613187e-02  1.43808793e+02  3.13602080e+00  6.08221910e+00\n",
      "   1.25402197e+00]\n",
      " [ 2.42500000e+00  3.86250000e+00  2.02500000e+01  1.58773050e+02\n",
      "  -2.69000000e-03  1.24491105e+02  3.94750000e+00  4.59250000e+00\n",
      "   1.19100000e+00]]\n",
      "[[ 0.000e+00  3.750e+00  8.000e+00  9.700e-02  5.500e-02  4.980e+02\n",
      "   4.620e+00  2.910e+00  2.440e-01]\n",
      " [ 2.500e+00  2.990e+00  5.700e+01  6.800e-02 -1.900e-01  1.180e+00\n",
      "   1.098e+01  2.800e+00  3.150e+00]\n",
      " [ 3.100e+00  3.500e+00  8.000e+00  5.900e+02  2.400e-04  5.430e-02\n",
      "   3.880e+00  2.980e+00  8.800e-01]\n",
      " [ 5.400e+00  5.000e+00  8.000e+00  7.100e-03  4.100e+00  4.400e-04\n",
      "   2.850e+00  3.250e+00  7.000e-01]\n",
      " [ 1.900e+00  3.000e+00  5.700e+01 -4.800e-03  2.200e-02 -9.500e-02\n",
      "   2.560e+00  9.580e+00  2.980e+00]\n",
      " [ 2.700e+00  3.380e+00  5.700e+01 -1.100e-04  9.100e-03  2.280e-01\n",
      "   3.190e+00  7.430e+00  9.700e-01]\n",
      " [ 4.700e+00  5.200e+00  8.000e+00  4.500e+01 -8.800e-02  5.120e-03\n",
      "   4.730e+00  2.900e+00  6.600e-01]] (3, 6)\n",
      "<class 'numpy.ndarray'> <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "variable_state_tensor = variable_state_tensor.astype(\"float\")\n",
    "initial_state_floats = initial_state_tensor[1:].astype(\"float\")\n",
    "initial_state_labels = initial_state_tensor[0].astype(\"str\")\n",
    "print(initial_state_labels[3])\n",
    "contraction_coefficient_range = (list(initial_state_labels).index(\"d1\"), list(initial_state_labels).index(\"exp1\"))\n",
    "exponential_range = (list(initial_state_labels).index(\"exp1\"), len(initial_state_labels) - 1)\n",
    "conv_op = graph_tensor_avg_convolution(adj_matrix, n_atoms)\n",
    "print(conv_op.transpose() @ variable_state_tensor)\n",
    "print(initial_state_floats, contraction_coefficient_range)\n",
    "print(type(initial_state_floats), type(contraction_coefficient_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1299381-6411-47e3-9caf-68c835613dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RGCN layer architecture for predictive cluster energy and structure model, set up forward and backward computation, n_layers = 11 (10 computational, 1 readout of SCF contraction coefficients) by default to ensure interdependency of electron density in all bonds on largest computed delocalized surfces\n",
    "class Computational_RGCN_Layer:\n",
    "    def __init__(self, input_tensor, convolution_operation, weight_paramaters, bias_paramaters, base_weights, base_biases, orbital_overlap_schemes, activation_fxn, atom_node_connections, layer_eqn_terms):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.convolution_operation = convolution_operation\n",
    "        self.weight_paramaters = weight_paramaters\n",
    "        self.bias_paramaters = bias_paramaters\n",
    "        self.base_weights = base_weights\n",
    "        self.base_biases = base_biases\n",
    "        self.orbital_overlap_schemes = orbital_overlap_schemes\n",
    "        self.activation_fxn = activation_fxn\n",
    "        self.atom_node_connections = atom_node_connections\n",
    "        self.layer_eqn_terms = layer_eqn_terms\n",
    "        \n",
    "        \n",
    "    def apply_convolution(self, convolution_operation, input_tensor):\n",
    "        H_i = input_tensor\n",
    "        H_i_conv = convolution_operation @ H_i\n",
    "        H_i_conv_T = H_i_conv.transpose()\n",
    "        return H_i_conv, H_i_conv_T\n",
    "        \n",
    "    def compute_weights_given_orbital_overlap_types(self, orbital_overlap_schemes, base_weights, weight_paramaters, layer_eqn_terms, input_tensor):\n",
    "        i = 0\n",
    "        ith_state_weights = np.zeros((len(input_tensor.transpose()), len(input_tensor.transpose())))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, computational_weight_paramaters will be set to an input_tensor * input_tensor matrix of ones, but will be set to the output of the update_weight_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_weights = weight_paramaters[i].transpose() @ base_weights\n",
    "            ith_state_weights = ith_state_weights + overlap_type_weights\n",
    "            i += 1\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        weight_expression = sympy.concrete.summations.Sum(layer_eqn_terms[0] * layer_eqn_terms[1], (b, 1, len(orbital_overlap_schemes)))\n",
    "        return ith_state_weights, weight_expression\n",
    "\n",
    "    def compute_biases_given_orbital_overlap_types(self, orbital_overlap_schemes, base_biases, bias_paramaters, layer_eqn_terms, input_tensor):\n",
    "        i = 0\n",
    "        ith_state_biases = np.zeros((len(input_tensor.transpose(),)))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, computational_bias_paramaters will be set to an input_tensor * 1 vector of ones, but will be set to the output of the update_bias_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_biases = bias_paramaters[i] @ base_biases\n",
    "            ith_state_biases = ith_state_biases + overlap_type_biases\n",
    "            i += 1\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        bias_expression = sympy.concrete.summations.Sum(layer_eqn_terms[2] * layer_eqn_terms[3], (b, 1, len(orbital_overlap_schemes)))\n",
    "        return ith_state_biases, bias_expression\n",
    "\n",
    "    def lin_reg_operation(self, convolution_operation, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, layer_eqn_terms, orbital_overlap_schemes, atom_node_connections):\n",
    "        ith_state_weights,ith_state_weight_expression = self.compute_weights_given_orbital_overlap_types(orbital_overlap_schemes, base_weights, weight_paramaters, layer_eqn_terms, input_tensor)\n",
    "        ith_state_biases,ith_state_bias_expression = self.compute_biases_given_orbital_overlap_types(orbital_overlap_schemes, base_biases, bias_paramaters, layer_eqn_terms, input_tensor)\n",
    "        H_i_conv, H_i_conv_T = self.apply_convolution(convolution_operation, input_tensor)\n",
    "        H_i_lin = np.array([])\n",
    "        H_i_lin = H_i_lin[np.newaxis, :]\n",
    "        H_i_lin_reg = (ith_state_weights @ H_i_conv_T).transpose() + ith_state_biases\n",
    "        i = 0\n",
    "        for i in np.arange(0, len(atom_node_connections)):\n",
    "            H_i_lin = np.append(H_i_lin, H_i_lin_reg[i] * (1/atom_node_connections[i]))\n",
    "            i += 1\n",
    "        H_i_lin = H_i_lin.reshape(np.shape(H_i_lin_reg))  \n",
    "        H_i_lin_T = H_i_lin.transpose()\n",
    "        CiR = sympy.symbols(\"CiR\", real = True)\n",
    "        i = sympy.symbols(\"i\", real = True)\n",
    "        lin_reg_expression = sympy.concrete.summations.Sum((1/CiR) * (layer_eqn_terms[4] * layer_eqn_terms[7] + layer_eqn_terms[5]), (i, 1, len(atom_node_connections)))\n",
    "        return H_i_lin, H_i_lin_T, lin_reg_expression\n",
    "\n",
    "    def gelu(self, input_tensor):\n",
    "        activation_output = (0.5 * input_tensor) * (1 + np.tanh(np.sqrt(2/np.pi) * (input_tensor + 0.044715*input_tensor**3)))\n",
    "        return activation_output\n",
    "\n",
    "    def forward_graph_update(self, convolution_operation, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, layer_eqn_terms, orbital_overlap_schemes, activation_fxn, atom_node_connections):\n",
    "        computational_activation = activation_fxn\n",
    "        H_i_conv, H_i_conv_T = self.apply_convolution(convolution_operation, input_tensor)\n",
    "        ith_state_weights, ith_state_weight_expression = self.compute_weights_given_orbital_overlap_types(orbital_overlap_schemes, base_weights, weight_paramaters, layer_eqn_terms, input_tensor)\n",
    "        ith_state_biases, ith_state_bias_expression = self.compute_biases_given_orbital_overlap_types(orbital_overlap_schemes, base_biases, bias_paramaters, layer_eqn_terms, input_tensor)\n",
    "        H_i_lin, H_i_lin_T, computational_lin_reg = self.lin_reg_operation(convolution_operation, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, layer_eqn_terms, orbital_overlap_schemes, atom_node_connections)\n",
    "        if computational_activation == \"gelu\":\n",
    "            H_i = self.gelu(H_i_lin)\n",
    "            gelu_expression = (0.5 * layer_eqn_terms[6]) * (1 + sympy.functions.elementary.hyperbolic.tanh((sympy.sqrt(2/np.pi)) * (layer_eqn_terms[6] + 0.044715*layer_eqn_terms[6]**3)))\n",
    "        else:\n",
    "            computational_activation = None\n",
    "            pass\n",
    "        return H_i, H_i_conv, H_i_conv_T, H_i_lin, H_i_lin_T, computational_lin_reg, ith_state_weights, ith_state_biases, ith_state_weight_expression, ith_state_bias_expression, gelu_expression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ccc8db-00f8-4e33-b932-af1eda72307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Readout_RGCN_Layer:\n",
    "    def __init__(self, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, orbital_overlap_schemes, activation_fxn, n_contraction_coeff, atom_node_connections, readout_layer_eqn, contraction_coefficient_range, initial_state_floats, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.weight_paramaters = weight_paramaters\n",
    "        self.bias_paramaters = bias_paramaters\n",
    "        self.base_weights = base_weights\n",
    "        self.base_biases = base_biases\n",
    "        self.orbital_overlap_schemes = orbital_overlap_schemes\n",
    "        self.activation_fxn = activation_fxn\n",
    "        self.n_contraction_coeff = n_contraction_coeff\n",
    "        self.atom_node_connections = atom_node_connections\n",
    "        self.readout_layer_eqn = readout_layer_eqn\n",
    "        self.contraction_coefficient_range = contraction_coefficient_range\n",
    "        self.initial_state_floats = initial_state_floats\n",
    "        self.maximum_s_el = maximum_s_el\n",
    "        self.maximum_p_el = maximum_p_el\n",
    "        self.maximum_d_el = maximum_d_el\n",
    "        self.maximum_f_el = maximum_f_el\n",
    "    \n",
    "    def compute_weights_given_orbital_overlap_types(self, orbital_overlap_schemes, base_weights, weight_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff):\n",
    "        i = 0\n",
    "        nth_state_weights = np.zeros((len(input_tensor.transpose()), n_contraction_coeff))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, readout_weight_paramaters will be set to an input_tensor * input_tensor matrix of ones, but will be set to the output of the update_weight_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_weights = weight_paramaters[i].transpose() @ base_weights\n",
    "            nth_state_weights = nth_state_weights + overlap_type_weights\n",
    "            i += 1\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        weight_expression = sympy.concrete.summations.Sum(readout_layer_eqn[0] * readout_layer_eqn[1], (b, 1, len(orbital_overlap_schemes)))\n",
    "        return nth_state_weights, weight_expression\n",
    "\n",
    "    def compute_biases_given_orbital_overlap_types(self, orbital_overlap_schemes, base_biases, bias_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff):\n",
    "        i = 0\n",
    "        nth_state_biases = np.zeros((n_contraction_coeff,))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, readout_bias_paramaters will be set to an input_tensor * 1 vector of ones, but will be set to the output of the update_bias_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_biases = bias_paramaters[i] @ base_biases\n",
    "            nth_state_biases = nth_state_biases + overlap_type_biases\n",
    "            i += 1\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        bias_expression = sympy.concrete.summations.Sum(readout_layer_eqn[2] * readout_layer_eqn[3], (b, 1, len(orbital_overlap_schemes)))\n",
    "        return nth_state_biases, bias_expression\n",
    "\n",
    "    def lin_reg_operation(self, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, readout_layer_eqn, orbital_overlap_schemes, n_contraction_coeff, atom_node_connections):\n",
    "        nth_state_weights, nth_state_weight_expression = self.compute_weights_given_orbital_overlap_types(orbital_overlap_schemes, base_weights, weight_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff)\n",
    "        nth_state_biases, nth_state_bias_expression = self.compute_biases_given_orbital_overlap_types(orbital_overlap_schemes, base_biases, bias_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff)\n",
    "        H_n_lin = np.array([])\n",
    "        H_n_lin = H_n_lin[np.newaxis, :]\n",
    "        readout_input_transpose = input_tensor.transpose()\n",
    "        H_n_lin_reg = (nth_state_weights.transpose() @ readout_input_transpose).transpose() + nth_state_biases\n",
    "        i = 0\n",
    "        for i in np.arange(0, len(atom_node_connections)):\n",
    "            H_n_lin = np.append(H_n_lin, H_n_lin_reg[i] * (1/atom_node_connections[i]))\n",
    "            i += 1\n",
    "        H_n_lin = H_n_lin.reshape(np.shape(H_n_lin_reg))\n",
    "        CiR = sympy.symbols(\"CiR\", real = True)\n",
    "        i = sympy.symbols(\"i\", real = True)\n",
    "        lin_reg_expression = sympy.concrete.summations.Sum((1/CiR) * (readout_layer_eqn[4] * readout_layer_eqn[7] + readout_layer_eqn[5]), (i, 1, len(atom_node_connections)))\n",
    "        return H_n_lin, lin_reg_expression\n",
    "\n",
    "    def Lrelu(self, input_tensor):\n",
    "        activation_output = np.maximum(input_tensor, 0.01 * input_tensor)\n",
    "        return activation_output\n",
    "\n",
    "    def readout_graph_update(self, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, readout_layer_eqn, orbital_overlap_schemes, activation_fxn, n_contraction_coeff, atom_node_connections, initial_state_floats, contraction_coefficient_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        readout_activation = activation_fxn\n",
    "        nth_state_weights, nth_state_weight_expression = self.compute_weights_given_orbital_overlap_types(orbital_overlap_schemes, base_weights, weight_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff)\n",
    "        nth_state_biases, nth_state_bias_expression = self.compute_biases_given_orbital_overlap_types(orbital_overlap_schemes, base_biases, bias_paramaters, readout_layer_eqn, input_tensor, n_contraction_coeff)\n",
    "        H_n_lin, readout_lin_reg = self.lin_reg_operation(input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, readout_layer_eqn, orbital_overlap_schemes, n_contraction_coeff, atom_node_connections)\n",
    "        if readout_activation == \"Lrelu\":\n",
    "            H_n = self.Lrelu(H_n_lin)\n",
    "            H_n_vals = H_n.flatten()\n",
    "            i = 0\n",
    "            j = 0\n",
    "            for i in np.arange(0, len(initial_state_floats)):\n",
    "                unoptimized_contraction_coeff = initial_state_floats[i][contraction_coefficient_range[0] : contraction_coefficient_range[1]]\n",
    "                for j in np.arange(0, len(unoptimized_contraction_coeff)):\n",
    "                    if unoptimized_contraction_coeff[j] == 0:\n",
    "                        if contraction_coefficient_range[0] < j < contraction_coefficient_range[0] + 1:\n",
    "                            H_n_vals[i][maximum_s_el - 1 : maximum_s_el + maximum_p_el] == 0\n",
    "                            j += 1\n",
    "                        elif contraction_coefficient_range[0] + 1 < j < contraction_coefficient_range[0] + 3:\n",
    "                            H_n_vals[j][maximum_s_el + maximum_p_el - 1 : maximum_s_el + maximum_p_el + maximum_d_el] == 0\n",
    "                            j += 1\n",
    "                        elif contraction_coefficient_range[0] + 3 < j < contraction_coefficient_range[0] + 7:\n",
    "                            H_n_vals[j][maximum_s_el + maximum_p_el + maximum_d_el - 1 : maximum_s_el + maximum_p_el + maximum_d_el + maximum_f_el] == 0\n",
    "                            j += 1\n",
    "                        elif j >= contraction_coefficient_range[0] + 7:\n",
    "                            H_n_vals[i][maximum_s_el + maximum_p_el + maximum_d_el + maximum_f_el - 1 : len(H_n_vals[i])] == 0\n",
    "                            j += 1     \n",
    "                    i += 1\n",
    "            H_n = H_n_vals.reshape(np.shape(H_n))\n",
    "            Lrelu_expression = sympy.Piecewise((0.01 * readout_layer_eqn[6], readout_layer_eqn[6] < 0), (readout_layer_eqn[6], readout_layer_eqn[6] >= 0))\n",
    "        else:\n",
    "            readout_activation = None\n",
    "            pass\n",
    "        return H_n, H_n_lin, readout_lin_reg, nth_state_weights, nth_state_biases, nth_state_weight_expression, nth_state_bias_expression, Lrelu_expression  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67348b6-c4b3-4ba1-a0a9-2d29c95d8cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b26e3aa-9bab-488f-bee2-5109f1990264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[2895.77344353, 2895.77344353, 2895.77344353, 2895.77344353,\n",
      "        2895.77344353, 2895.77344353, 2895.77344353, 2895.77344353,\n",
      "        2895.77344353],\n",
      "       [7966.10846781, 7966.10846781, 7966.10846781, 7966.10846781,\n",
      "        7966.10846781, 7966.10846781, 7966.10846781, 7966.10846781,\n",
      "        7966.10846781],\n",
      "       [3053.51655804, 3053.51655804, 3053.51655804, 3053.51655804,\n",
      "        3053.51655804, 3053.51655804, 3053.51655804, 3053.51655804,\n",
      "        3053.51655804],\n",
      "       [4719.68001451, 4719.68001451, 4719.68001451, 4719.68001451,\n",
      "        4719.68001451, 4719.68001451, 4719.68001451, 4719.68001451,\n",
      "        4719.68001451],\n",
      "       [1021.44710212, 1021.44710212, 1021.44710212, 1021.44710212,\n",
      "        1021.44710212, 1021.44710212, 1021.44710212, 1021.44710212,\n",
      "        1021.44710212],\n",
      "       [4446.46092564, 4446.46092564, 4446.46092564, 4446.46092564,\n",
      "        4446.46092564, 4446.46092564, 4446.46092564, 4446.46092564,\n",
      "        4446.46092564],\n",
      "       [4807.949475  , 4807.949475  , 4807.949475  , 4807.949475  ,\n",
      "        4807.949475  , 4807.949475  , 4807.949475  , 4807.949475  ,\n",
      "        4807.949475  ]]), array([[ 2.67611070e+00,  4.07636061e+00,  3.69089653e+01,\n",
      "         1.12938482e+01, -6.04713318e-02,  1.24907735e+02,\n",
      "         6.42802666e+00,  4.40564663e+00,  1.41534155e+00],\n",
      "       [ 1.72822625e+00,  3.08956139e+00,  2.36188022e+01,\n",
      "         1.70368998e+02, -4.73869189e-02,  1.44169225e+02,\n",
      "         6.11373864e+00,  2.63362988e+00,  1.37447085e+00],\n",
      "       [ 4.23053356e+00,  4.48151433e+00,  2.27638837e+01,\n",
      "         1.58771680e+02,  1.10677978e+00,  3.55618676e-01,\n",
      "         6.14487711e+00,  3.21648456e+00,  1.49639927e+00],\n",
      "       [ 3.24337567e+00,  3.54305504e+00,  2.14305504e+01,\n",
      "         1.70319310e+02,  1.37308680e+00, -1.16024113e-02,\n",
      "         2.80906787e+00,  4.70909302e+00,  1.34761935e+00],\n",
      "       [ 3.98826859e+00,  4.46909763e+00,  3.50138837e+01,\n",
      "         1.12508178e+01,  1.16969500e+00,  4.34749477e-02,\n",
      "         3.56609781e+00,  6.20305044e+00,  1.39208747e+00],\n",
      "       [ 1.44848276e+00,  3.07522383e+00,  3.77638837e+01,\n",
      "         2.65791807e-02,  2.52613187e-02,  1.43808793e+02,\n",
      "         3.13602080e+00,  6.08221910e+00,  1.25402197e+00],\n",
      "       [ 2.42500000e+00,  3.86250000e+00,  2.02500000e+01,\n",
      "         1.58773050e+02, -2.69000000e-03,  1.24491105e+02,\n",
      "         3.94750000e+00,  4.59250000e+00,  1.19100000e+00]]), array([[ 2.67611070e+00,  1.72822625e+00,  4.23053356e+00,\n",
      "         3.24337567e+00,  3.98826859e+00,  1.44848276e+00,\n",
      "         2.42500000e+00],\n",
      "       [ 4.07636061e+00,  3.08956139e+00,  4.48151433e+00,\n",
      "         3.54305504e+00,  4.46909763e+00,  3.07522383e+00,\n",
      "         3.86250000e+00],\n",
      "       [ 3.69089653e+01,  2.36188022e+01,  2.27638837e+01,\n",
      "         2.14305504e+01,  3.50138837e+01,  3.77638837e+01,\n",
      "         2.02500000e+01],\n",
      "       [ 1.12938482e+01,  1.70368998e+02,  1.58771680e+02,\n",
      "         1.70319310e+02,  1.12508178e+01,  2.65791807e-02,\n",
      "         1.58773050e+02],\n",
      "       [-6.04713318e-02, -4.73869189e-02,  1.10677978e+00,\n",
      "         1.37308680e+00,  1.16969500e+00,  2.52613187e-02,\n",
      "        -2.69000000e-03],\n",
      "       [ 1.24907735e+02,  1.44169225e+02,  3.55618676e-01,\n",
      "        -1.16024113e-02,  4.34749477e-02,  1.43808793e+02,\n",
      "         1.24491105e+02],\n",
      "       [ 6.42802666e+00,  6.11373864e+00,  6.14487711e+00,\n",
      "         2.80906787e+00,  3.56609781e+00,  3.13602080e+00,\n",
      "         3.94750000e+00],\n",
      "       [ 4.40564663e+00,  2.63362988e+00,  3.21648456e+00,\n",
      "         4.70909302e+00,  6.20305044e+00,  6.08221910e+00,\n",
      "         4.59250000e+00],\n",
      "       [ 1.41534155e+00,  1.37447085e+00,  1.49639927e+00,\n",
      "         1.34761935e+00,  1.39208747e+00,  1.25402197e+00,\n",
      "         1.19100000e+00]]), array([[2895.77344353, 2895.77344353, 2895.77344353, 2895.77344353,\n",
      "        2895.77344353, 2895.77344353, 2895.77344353, 2895.77344353,\n",
      "        2895.77344353],\n",
      "       [7966.10846781, 7966.10846781, 7966.10846781, 7966.10846781,\n",
      "        7966.10846781, 7966.10846781, 7966.10846781, 7966.10846781,\n",
      "        7966.10846781],\n",
      "       [3053.51655804, 3053.51655804, 3053.51655804, 3053.51655804,\n",
      "        3053.51655804, 3053.51655804, 3053.51655804, 3053.51655804,\n",
      "        3053.51655804],\n",
      "       [4719.68001451, 4719.68001451, 4719.68001451, 4719.68001451,\n",
      "        4719.68001451, 4719.68001451, 4719.68001451, 4719.68001451,\n",
      "        4719.68001451],\n",
      "       [1021.44710212, 1021.44710212, 1021.44710212, 1021.44710212,\n",
      "        1021.44710212, 1021.44710212, 1021.44710212, 1021.44710212,\n",
      "        1021.44710212],\n",
      "       [4446.46092564, 4446.46092564, 4446.46092564, 4446.46092564,\n",
      "        4446.46092564, 4446.46092564, 4446.46092564, 4446.46092564,\n",
      "        4446.46092564],\n",
      "       [4807.949475  , 4807.949475  , 4807.949475  , 4807.949475  ,\n",
      "        4807.949475  , 4807.949475  , 4807.949475  , 4807.949475  ,\n",
      "        4807.949475  ]]), array([[2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ],\n",
      "       [2895.77344353, 7966.10846781, 3053.51655804, 4719.68001451,\n",
      "        1021.44710212, 4446.46092564, 4807.949475  ]]), Sum((H_i_conv*Wi + bi)/CiR, (i, 1, 7)), array([[45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45.]]), array([45., 45., 45., 45., 45., 45., 45., 45., 45.]), Sum(A_RBTi*VBi, (b, 1, 5)), Sum(A_RBBi*VBBi, (b, 1, 5)), 0.5*H_i*(tanh(0.0356774081363001*H_i**3 + 0.797884560802865*H_i) + 1))\n"
     ]
    }
   ],
   "source": [
    "# test forward compute and hidden layers\n",
    "orbital_overlap_types = np.array([0,1,2,3,4])\n",
    "# for the entries in the overlap types (edge connection types) vector, a 0 represents sigma overlap only (single M.O), 1 represents sigma + pi M.O's, 2 represents sigma + 2 pi M.O's, 3 represents a delta M.O, and 4 represents an M.O with delta and sigma or delta and pi characteristics within the density of states. Vector is in order from 1 to 5 atomic orbital overlaps\n",
    "input_layer = Computational_RGCN_Layer(input_tensor = variable_state_tensor, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), base_weights = np.ones((len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), base_biases = np.ones((len(variable_state_tensor.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBTi\", real = True), sympy.symbols(\"VBi\", real = True), sympy.symbols(\"A_RBBi\", real = True), sympy.symbols(\"VBBi\", real = True), sympy.symbols(\"Wi\", real = True), sympy.symbols(\"bi\", real = True), sympy.symbols(\"H_i\", real = True), sympy.symbols(\"H_i_conv\", real = True)]))\n",
    "#print(input_layer.apply_convolution(input_layer.convolution_operation, input_layer.input_tensor))                          \n",
    "#print(input_layer.compute_weights_given_orbital_overlap_types(input_layer.orbital_overlap_schemes, input_layer.base_weights, input_layer.weight_paramaters, input_layer.layer_eqn_terms, input_layer.input_tensor))\n",
    "#print(input_layer.compute_biases_given_orbital_overlap_types(input_layer.orbital_overlap_schemes, input_layer.base_biases, input_layer.bias_paramaters, input_layer.layer_eqn_terms, input_layer.input_tensor))\n",
    "#print(input_layer.lin_reg_operation(input_layer.convolution_operation, input_layer.input_tensor, input_layer.weight_paramaters, input_layer.bias_paramaters, input_layer.base_weights, input_layer.base_biases, input_layer.layer_eqn_terms, input_layer.orbital_overlap_schemes, input_layer.atom_node_connections))\n",
    "print(input_layer.forward_graph_update(input_layer.convolution_operation, input_layer.input_tensor, input_layer.weight_paramaters, input_layer.bias_paramaters, input_layer.base_weights, input_layer.base_biases, input_layer.layer_eqn_terms, input_layer.orbital_overlap_schemes, input_layer.activation_fxn, input_layer.atom_node_connections))                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e921093-650f-4f8a-8c75-c0d1f88794d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375],\n",
      "       [1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213],\n",
      "       [ 412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ],\n",
      "       [ 955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921],\n",
      "       [ 137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ],\n",
      "       [ 900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297],\n",
      "       [ 649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167]]), array([[ 390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375,  390946.08154375,  390946.08154375,\n",
      "         390946.08154375],\n",
      "       [1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213, 1613161.96473213, 1613161.96473213,\n",
      "        1613161.96473213],\n",
      "       [ 412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ,  412241.4020022 ,  412241.4020022 ,\n",
      "         412241.4020022 ],\n",
      "       [ 955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921,  955760.20293921,  955760.20293921,\n",
      "         955760.20293921],\n",
      "       [ 137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ,  137912.0254525 ,  137912.0254525 ,\n",
      "         137912.0254525 ],\n",
      "       [ 900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297,  900433.33744297,  900433.33744297,\n",
      "         900433.33744297],\n",
      "       [ 649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167,  649089.84579167,  649089.84579167,\n",
      "         649089.84579167]]), Sum((H_n-1_T*Wn_T + bn)/CiR, (i, 1, 7)), array([[45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.],\n",
      "       [45., 45., 45., 45., 45., 45., 45., 45., 45., 45.]]), array([50., 50., 50., 50., 50., 50., 50., 50., 50., 50.]), Sum(A_RBTn*VBn, (b, 1, 5)), Sum(A_RBBn*VBBn, (b, 1, 5)), Piecewise((0.01*H_n-1, H_n-1 < 0), (H_n-1, True)))\n"
     ]
    }
   ],
   "source": [
    "# test readout layer\n",
    "H_i, H_i_conv, H_i_conv_T, H_i_lin, H_i_lin_T, computational_lin_reg, ith_state_weights, ith_state_biases, ith_state_weight_expression, ith_state_bias_expression, gelu_expression = input_layer.forward_graph_update(input_layer.convolution_operation, input_layer.input_tensor, input_layer.weight_paramaters, input_layer.bias_paramaters, input_layer.base_weights, input_layer.base_biases, input_layer.layer_eqn_terms, input_layer.orbital_overlap_schemes, input_layer.activation_fxn, input_layer.atom_node_connections)\n",
    "readout_node_features = 10\n",
    "readout_layer = Readout_RGCN_Layer(input_tensor = H_i, weight_paramaters = np.ones((len(orbital_overlap_types), len(H_i.transpose()), len(H_i.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), readout_node_features, readout_node_features)), base_weights = np.ones((len(H_i.transpose()), readout_node_features)), base_biases = np.ones((readout_node_features,)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"Lrelu\", n_contraction_coeff = readout_node_features, atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), readout_layer_eqn = np.array([sympy.symbols(\"A_RBTn\", real = True), sympy.symbols(\"VBn\", real = True), sympy.symbols(\"A_RBBn\", real = True), sympy.symbols(\"VBBn\", real = True), sympy.symbols(\"Wn_T\", real = True), sympy.symbols(\"bn\", real = True), sympy.symbols(\"H_n-1\", real = True), sympy.symbols(\"H_n-1_T\", real = True)]), contraction_coefficient_range = contraction_coefficient_range, initial_state_floats = initial_state_floats, maximum_s_el = molecular_graph_details.maximum_s_el, maximum_p_el = molecular_graph_details.maximum_p_el, maximum_d_el = molecular_graph_details.maximum_d_el, maximum_f_el = molecular_graph_details.maximum_f_el)\n",
    "#print(readout_layer.compute_weights_given_orbital_overlap_types(readout_layer.orbital_overlap_schemes, readout_layer.base_weights, readout_layer.weight_paramaters, readout_layer.readout_layer_eqn, readout_layer.input_tensor, readout_layer.n_contraction_coeff))\n",
    "#print(readout_layer.compute_biases_given_orbital_overlap_types(readout_layer.orbital_overlap_schemes, readout_layer.base_biases, readout_layer.bias_paramaters, readout_layer.readout_layer_eqn, readout_layer.input_tensor, readout_layer.n_contraction_coeff))\n",
    "#print(readout_layer.lin_reg_operation(readout_layer.input_tensor, readout_layer.weight_paramaters, readout_layer.bias_paramaters, readout_layer.base_weights, readout_layer.base_biases, readout_layer.readout_layer_eqn, readout_layer.orbital_overlap_schemes, readout_layer.n_contraction_coeff, readout_layer.atom_node_connections))\n",
    "print(readout_layer.readout_graph_update(readout_layer.input_tensor, readout_layer.weight_paramaters, readout_layer.bias_paramaters, readout_layer.base_weights, readout_layer.base_biases, readout_layer.readout_layer_eqn, readout_layer.orbital_overlap_schemes, readout_layer.activation_fxn, readout_layer.n_contraction_coeff, readout_layer.atom_node_connections, readout_layer.initial_state_floats, readout_layer.contraction_coefficient_range, readout_layer.maximum_s_el, readout_layer.maximum_p_el, readout_layer.maximum_d_el, readout_layer.maximum_f_el))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafa00c3-4b7d-456c-80a6-8ad6b80d48f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.89577344e+03 2.89577344e+03 2.89577344e+03 2.89577344e+03\n",
      " 2.89577344e+03 2.89577344e+03 2.89577344e+03 2.89577344e+03\n",
      " 2.89577344e+03 7.96610847e+03 7.96610847e+03 7.96610847e+03\n",
      " 7.96610847e+03 7.96610847e+03 7.96610847e+03 7.96610847e+03\n",
      " 7.96610847e+03 7.96610847e+03 3.05351656e+03 3.05351656e+03\n",
      " 3.05351656e+03 3.05351656e+03 3.05351656e+03 3.05351656e+03\n",
      " 3.05351656e+03 3.05351656e+03 3.05351656e+03 4.71968001e+03\n",
      " 4.71968001e+03 4.71968001e+03 4.71968001e+03 4.71968001e+03\n",
      " 4.71968001e+03 4.71968001e+03 4.71968001e+03 4.71968001e+03\n",
      " 1.02144710e+03 1.02144710e+03 1.02144710e+03 1.02144710e+03\n",
      " 1.02144710e+03 1.02144710e+03 1.02144710e+03 1.02144710e+03\n",
      " 1.02144710e+03 4.44646093e+03 4.44646093e+03 4.44646093e+03\n",
      " 4.44646093e+03 4.44646093e+03 4.44646093e+03 4.44646093e+03\n",
      " 4.44646093e+03 4.44646093e+03 4.80794947e+03 4.80794947e+03\n",
      " 4.80794947e+03 4.80794947e+03 4.80794947e+03 4.80794947e+03\n",
      " 4.80794947e+03 4.80794947e+03 4.80794947e+03 7.43747667e+05\n",
      " 7.43747667e+05 7.43747667e+05 7.43747667e+05 7.43747667e+05\n",
      " 7.43747667e+05 7.43747667e+05 7.43747667e+05 7.43747667e+05\n",
      " 8.85510770e+05 8.85510770e+05 8.85510770e+05 8.85510770e+05\n",
      " 8.85510770e+05 8.85510770e+05 8.85510770e+05 8.85510770e+05\n",
      " 8.85510770e+05 7.59719158e+05 7.59719158e+05 7.59719158e+05\n",
      " 7.59719158e+05 7.59719158e+05 7.59719158e+05 7.59719158e+05\n",
      " 7.59719158e+05 7.59719158e+05 5.56809889e+05 5.56809889e+05\n",
      " 5.56809889e+05 5.56809889e+05 5.56809889e+05 5.56809889e+05\n",
      " 5.56809889e+05 5.56809889e+05 5.56809889e+05 5.53972125e+05\n",
      " 5.53972125e+05 5.53972125e+05 5.53972125e+05 5.53972125e+05\n",
      " 5.53972125e+05 5.53972125e+05 5.53972125e+05 5.53972125e+05\n",
      " 5.29146457e+05 5.29146457e+05 5.29146457e+05 5.29146457e+05\n",
      " 5.29146457e+05 5.29146457e+05 5.29146457e+05 5.29146457e+05\n",
      " 5.29146457e+05 3.97545672e+05 3.97545672e+05 3.97545672e+05\n",
      " 3.97545672e+05 3.97545672e+05 3.97545672e+05 3.97545672e+05\n",
      " 3.97545672e+05 3.97545672e+05 9.36494745e+07 9.36494745e+07\n",
      " 9.36494745e+07 9.36494745e+07 9.36494745e+07 9.36494745e+07\n",
      " 9.36494745e+07 9.36494745e+07 9.36494745e+07 1.47659731e+08\n",
      " 1.47659731e+08 1.47659731e+08 1.47659731e+08 1.47659731e+08\n",
      " 1.47659731e+08 1.47659731e+08 1.47659731e+08 1.47659731e+08\n",
      " 9.52665879e+07 9.52665879e+07 9.52665879e+07 9.52665879e+07\n",
      " 9.52665879e+07 9.52665879e+07 9.52665879e+07 9.52665879e+07\n",
      " 9.52665879e+07 1.14378767e+08 1.14378767e+08 1.14378767e+08\n",
      " 1.14378767e+08 1.14378767e+08 1.14378767e+08 1.14378767e+08\n",
      " 1.14378767e+08 1.14378767e+08 7.44347009e+07 7.44347009e+07\n",
      " 7.44347009e+07 7.44347009e+07 7.44347009e+07 7.44347009e+07\n",
      " 7.44347009e+07 7.44347009e+07 7.44347009e+07 1.11577844e+08\n",
      " 1.11577844e+08 1.11577844e+08 1.11577844e+08 1.11577844e+08\n",
      " 1.11577844e+08 1.11577844e+08 1.11577844e+08 1.11577844e+08\n",
      " 8.28557460e+07 8.28557460e+07 8.28557460e+07 8.28557460e+07\n",
      " 8.28557460e+07 8.28557460e+07 8.28557460e+07 8.28557460e+07\n",
      " 8.28557460e+07 1.60598359e+10 1.60598359e+10 1.60598359e+10\n",
      " 1.60598359e+10 1.60598359e+10 1.60598359e+10 1.60598359e+10\n",
      " 1.60598359e+10 1.60598359e+10 2.10104442e+10 2.10104442e+10\n",
      " 2.10104442e+10 2.10104442e+10 2.10104442e+10 2.10104442e+10\n",
      " 2.10104442e+10 2.10104442e+10 2.10104442e+10 1.62235686e+10\n",
      " 1.62235686e+10 1.62235686e+10 1.62235686e+10 1.62235686e+10\n",
      " 1.62235686e+10 1.62235686e+10 1.62235686e+10 1.62235686e+10\n",
      " 1.76407466e+10 1.76407466e+10 1.76407466e+10 1.76407466e+10\n",
      " 1.76407466e+10 1.76407466e+10 1.76407466e+10 1.76407466e+10\n",
      " 1.76407466e+10 1.41143400e+10 1.41143400e+10 1.41143400e+10\n",
      " 1.41143400e+10 1.41143400e+10 1.41143400e+10 1.41143400e+10\n",
      " 1.41143400e+10 1.41143400e+10 1.73571532e+10 1.73571532e+10\n",
      " 1.73571532e+10 1.73571532e+10 1.73571532e+10 1.73571532e+10\n",
      " 1.73571532e+10 1.73571532e+10 1.73571532e+10 1.16844697e+10\n",
      " 1.16844697e+10 1.16844697e+10 1.16844697e+10 1.16844697e+10\n",
      " 1.16844697e+10 1.16844697e+10 1.16844697e+10 1.16844697e+10\n",
      " 2.43159945e+12 2.43159945e+12 2.43159945e+12 2.43159945e+12\n",
      " 2.43159945e+12 2.43159945e+12 2.43159945e+12 2.43159945e+12\n",
      " 2.43159945e+12 3.30538675e+12 3.30538675e+12 3.30538675e+12\n",
      " 3.30538675e+12 3.30538675e+12 3.30538675e+12 3.30538675e+12\n",
      " 3.30538675e+12 3.30538675e+12 2.44817738e+12 2.44817738e+12\n",
      " 2.44817738e+12 2.44817738e+12 2.44817738e+12 2.44817738e+12\n",
      " 2.44817738e+12 2.44817738e+12 2.44817738e+12 2.96420487e+12\n",
      " 2.96420487e+12 2.96420487e+12 2.96420487e+12 2.96420487e+12\n",
      " 2.96420487e+12 2.96420487e+12 2.96420487e+12 2.96420487e+12\n",
      " 2.23461799e+12 2.23461799e+12 2.23461799e+12 2.23461799e+12\n",
      " 2.23461799e+12 2.23461799e+12 2.23461799e+12 2.23461799e+12\n",
      " 2.23461799e+12 2.93549103e+12 2.93549103e+12 2.93549103e+12\n",
      " 2.93549103e+12 2.93549103e+12 2.93549103e+12 2.93549103e+12\n",
      " 2.93549103e+12 2.93549103e+12 1.96027473e+12 1.96027473e+12\n",
      " 1.96027473e+12 1.96027473e+12 1.96027473e+12 1.96027473e+12\n",
      " 1.96027473e+12 1.96027473e+12 1.96027473e+12 3.91439895e+14\n",
      " 3.91439895e+14 3.91439895e+14 3.91439895e+14 3.91439895e+14\n",
      " 3.91439895e+14 3.91439895e+14 3.91439895e+14 3.91439895e+14\n",
      " 5.08369328e+14 5.08369328e+14 5.08369328e+14 5.08369328e+14\n",
      " 5.08369328e+14 5.08369328e+14 5.08369328e+14 5.08369328e+14\n",
      " 5.08369328e+14 3.93118411e+14 3.93118411e+14 3.93118411e+14\n",
      " 3.93118411e+14 3.93118411e+14 3.93118411e+14 3.93118411e+14\n",
      " 3.93118411e+14 3.93118411e+14 4.73824662e+14 4.73824662e+14\n",
      " 4.73824662e+14 4.73824662e+14 4.73824662e+14 4.73824662e+14\n",
      " 4.73824662e+14 4.73824662e+14 4.73824662e+14 3.71495523e+14\n",
      " 3.71495523e+14 3.71495523e+14 3.71495523e+14 3.71495523e+14\n",
      " 3.71495523e+14 3.71495523e+14 3.71495523e+14 3.71495523e+14\n",
      " 4.70917386e+14 4.70917386e+14 4.70917386e+14 4.70917386e+14\n",
      " 4.70917386e+14 4.70917386e+14 4.70917386e+14 4.70917386e+14\n",
      " 4.70917386e+14 3.06270097e+14 3.06270097e+14 3.06270097e+14\n",
      " 3.06270097e+14 3.06270097e+14 3.06270097e+14 3.06270097e+14\n",
      " 3.06270097e+14 3.06270097e+14 6.17116350e+16 6.17116350e+16\n",
      " 6.17116350e+16 6.17116350e+16 6.17116350e+16 6.17116350e+16\n",
      " 6.17116350e+16 6.17116350e+16 6.17116350e+16 8.01776307e+16\n",
      " 8.01776307e+16 8.01776307e+16 8.01776307e+16 8.01776307e+16\n",
      " 8.01776307e+16 8.01776307e+16 8.01776307e+16 8.01776307e+16\n",
      " 6.18815848e+16 6.18815848e+16 6.18815848e+16 6.18815848e+16\n",
      " 6.18815848e+16 6.18815848e+16 6.18815848e+16 6.18815848e+16\n",
      " 6.18815848e+16 7.66799833e+16 7.66799833e+16 7.66799833e+16\n",
      " 7.66799833e+16 7.66799833e+16 7.66799833e+16 7.66799833e+16\n",
      " 7.66799833e+16 7.66799833e+16 5.96922673e+16 5.96922673e+16\n",
      " 5.96922673e+16 5.96922673e+16 5.96922673e+16 5.96922673e+16\n",
      " 5.96922673e+16 5.96922673e+16 5.96922673e+16 7.63856217e+16\n",
      " 7.63856217e+16 7.63856217e+16 7.63856217e+16 7.63856217e+16\n",
      " 7.63856217e+16 7.63856217e+16 7.63856217e+16 7.63856217e+16\n",
      " 4.93534325e+16 4.93534325e+16 4.93534325e+16 4.93534325e+16\n",
      " 4.93534325e+16 4.93534325e+16 4.93534325e+16 4.93534325e+16\n",
      " 4.93534325e+16 9.84989495e+18 9.84989495e+18 9.84989495e+18\n",
      " 9.84989495e+18 9.84989495e+18 9.84989495e+18 9.84989495e+18\n",
      " 9.84989495e+18 9.84989495e+18 1.26368437e+19 1.26368437e+19\n",
      " 1.26368437e+19 1.26368437e+19 1.26368437e+19 1.26368437e+19\n",
      " 1.26368437e+19 1.26368437e+19 1.26368437e+19 9.86710237e+18\n",
      " 9.86710237e+18 9.86710237e+18 9.86710237e+18 9.86710237e+18\n",
      " 9.86710237e+18 9.86710237e+18 9.86710237e+18 9.86710237e+18\n",
      " 1.22827069e+19 1.22827069e+19 1.22827069e+19 1.22827069e+19\n",
      " 1.22827069e+19 1.22827069e+19 1.22827069e+19 1.22827069e+19\n",
      " 1.22827069e+19 9.64543398e+18 9.64543398e+18 9.64543398e+18\n",
      " 9.64543398e+18 9.64543398e+18 9.64543398e+18 9.64543398e+18\n",
      " 9.64543398e+18 9.64543398e+18 1.22529028e+19 1.22529028e+19\n",
      " 1.22529028e+19 1.22529028e+19 1.22529028e+19 1.22529028e+19\n",
      " 1.22529028e+19 1.22529028e+19 1.22529028e+19 7.85156354e+18\n",
      " 7.85156354e+18 7.85156354e+18 7.85156354e+18 7.85156354e+18\n",
      " 7.85156354e+18 7.85156354e+18 7.85156354e+18 7.85156354e+18\n",
      " 1.56740610e+21 1.56740610e+21 1.56740610e+21 1.56740610e+21\n",
      " 1.56740610e+21 1.56740610e+21 1.56740610e+21 1.56740610e+21\n",
      " 1.56740610e+21 2.00557784e+21 2.00557784e+21 2.00557784e+21\n",
      " 2.00557784e+21 2.00557784e+21 2.00557784e+21 2.00557784e+21\n",
      " 2.00557784e+21 2.00557784e+21 1.56914835e+21 1.56914835e+21\n",
      " 1.56914835e+21 1.56914835e+21 1.56914835e+21 1.56914835e+21\n",
      " 1.56914835e+21 1.56914835e+21 1.56914835e+21 1.96972148e+21\n",
      " 1.96972148e+21 1.96972148e+21 1.96972148e+21 1.96972148e+21\n",
      " 1.96972148e+21 1.96972148e+21 1.96972148e+21 1.96972148e+21\n",
      " 1.54670442e+21 1.54670442e+21 1.54670442e+21 1.54670442e+21\n",
      " 1.54670442e+21 1.54670442e+21 1.54670442e+21 1.54670442e+21\n",
      " 1.54670442e+21 1.96670382e+21 1.96670382e+21 1.96670382e+21\n",
      " 1.96670382e+21 1.96670382e+21 1.96670382e+21 1.96670382e+21\n",
      " 1.96670382e+21 1.96670382e+21 1.25597233e+21 1.25597233e+21\n",
      " 1.25597233e+21 1.25597233e+21 1.25597233e+21 1.25597233e+21\n",
      " 1.25597233e+21 1.25597233e+21 1.25597233e+21 2.50093379e+23\n",
      " 2.50093379e+23 2.50093379e+23 2.50093379e+23 2.50093379e+23\n",
      " 2.50093379e+23 2.50093379e+23 2.50093379e+23 2.50093379e+23\n",
      " 3.18729172e+23 3.18729172e+23 3.18729172e+23 3.18729172e+23\n",
      " 3.18729172e+23 3.18729172e+23 3.18729172e+23 3.18729172e+23\n",
      " 3.18729172e+23 2.50269782e+23 2.50269782e+23 2.50269782e+23\n",
      " 2.50269782e+23 2.50269782e+23 2.50269782e+23 2.50269782e+23\n",
      " 2.50269782e+23 2.50269782e+23 3.15098717e+23 3.15098717e+23\n",
      " 3.15098717e+23 3.15098717e+23 3.15098717e+23 3.15098717e+23\n",
      " 3.15098717e+23 3.15098717e+23 3.15098717e+23 2.47997334e+23\n",
      " 2.47997334e+23 2.47997334e+23 2.47997334e+23 2.47997334e+23\n",
      " 2.47997334e+23 2.47997334e+23 2.47997334e+23 2.47997334e+23\n",
      " 3.14793178e+23 3.14793178e+23 3.14793178e+23 3.14793178e+23\n",
      " 3.14793178e+23 3.14793178e+23 3.14793178e+23 3.14793178e+23\n",
      " 3.14793178e+23 2.00449053e+23 2.00449053e+23 2.00449053e+23\n",
      " 2.00449053e+23 2.00449053e+23 2.00449053e+23 2.00449053e+23\n",
      " 2.00449053e+23 2.00449053e+23 3.98948973e+25 3.98948973e+25\n",
      " 3.98948973e+25 3.98948973e+25 3.98948973e+25 3.98948973e+25\n",
      " 3.98948973e+25 3.98948973e+25 3.98948973e+25 5.07638057e+25\n",
      " 5.07638057e+25 5.07638057e+25 5.07638057e+25 5.07638057e+25\n",
      " 5.07638057e+25 5.07638057e+25 5.07638057e+25 5.07638057e+25\n",
      " 3.99127581e+25 3.99127581e+25 3.99127581e+25 3.99127581e+25\n",
      " 3.99127581e+25 3.99127581e+25 3.99127581e+25 3.99127581e+25\n",
      " 3.99127581e+25 5.03962220e+25 5.03962220e+25 5.03962220e+25\n",
      " 5.03962220e+25 5.03962220e+25 5.03962220e+25 5.03962220e+25\n",
      " 5.03962220e+25 5.03962220e+25 3.96826728e+25 3.96826728e+25\n",
      " 3.96826728e+25 3.96826728e+25 3.96826728e+25 3.96826728e+25\n",
      " 3.96826728e+25 3.96826728e+25 3.96826728e+25 5.03652862e+25\n",
      " 5.03652862e+25 5.03652862e+25 5.03652862e+25 5.03652862e+25\n",
      " 5.03652862e+25 5.03652862e+25 5.03652862e+25 5.03652862e+25\n",
      " 3.20223222e+25 3.20223222e+25 3.20223222e+25 3.20223222e+25\n",
      " 3.20223222e+25 3.20223222e+25 3.20223222e+25 3.20223222e+25\n",
      " 3.20223222e+25]\n",
      "(7, 10)\n"
     ]
    }
   ],
   "source": [
    "# build forward computation loop, get contraction coefficient prediction for wavefunction of bonding electrons in each involved atom in cluster\n",
    "hidden_state_eqns = np.array([])\n",
    "weight_eqns = np.array([])\n",
    "bias_eqns = np.array([])\n",
    "lin_eqns = np.array([])\n",
    "hidden_states = np.array([])\n",
    "input_layer = Computational_RGCN_Layer(input_tensor = variable_state_tensor, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), base_weights = np.ones((len(variable_state_tensor.transpose()), len(variable_state_tensor.transpose()))), base_biases = np.ones((len(variable_state_tensor.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT1\", real = True), sympy.symbols(\"VB1\", real = True), sympy.symbols(\"A_RBB1\", real = True), sympy.symbols(\"VBB1\", real = True), sympy.symbols(\"W1\", real = True), sympy.symbols(\"B1\", real = True), sympy.symbols(\"H_1\", real = True), sympy.symbols(\"H_o_conv\", real = True)]))\n",
    "H_1_val, H_o_conv, H_o_conv_T, H_1_lin_val, H_1_lin_T_val, H_1_lin, W1_vals, B1_vals, W1, B1, H1 = input_layer.forward_graph_update(input_layer.convolution_operation, input_layer.input_tensor, input_layer.weight_paramaters, input_layer.bias_paramaters, input_layer.base_weights, input_layer.base_biases, input_layer.layer_eqn_terms, input_layer.orbital_overlap_schemes, input_layer.activation_fxn, input_layer.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H1)\n",
    "weight_eqns = np.append(weight_eqns, W1)\n",
    "bias_eqns = np.append(bias_eqns, B1)\n",
    "lin_eqns = np.append(lin_eqns, H_1_lin)\n",
    "hidden_states = np.append(hidden_states, H_1_val)\n",
    "\n",
    "first_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_1_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_1_val.transpose()), len(H_1_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_1_val.transpose()), len(H_1_val.transpose()))), base_weights = np.ones((len(H_1_val.transpose()), len(H_1_val.transpose()))), base_biases = np.ones((len(H_1_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT2\", real = True), sympy.symbols(\"VB2\", real = True), sympy.symbols(\"A_RBB2\", real = True), sympy.symbols(\"VBB2\", real = True), sympy.symbols(\"W2\", real = True), sympy.symbols(\"B2\", real = True), sympy.symbols(\"H_2\", real = True), sympy.symbols(\"H_1_conv\", real = True)]))\n",
    "H_2_val, H_1_conv, H_1_conv_T, H_2_lin_val, H_2_lin_T_val, H_2_lin, W2_vals, B2_vals, W2, B2, H2 = first_hidden_encoding.forward_graph_update(first_hidden_encoding.convolution_operation, first_hidden_encoding.input_tensor, first_hidden_encoding.weight_paramaters, first_hidden_encoding.bias_paramaters, first_hidden_encoding.base_weights, first_hidden_encoding.base_biases, first_hidden_encoding.layer_eqn_terms, first_hidden_encoding.orbital_overlap_schemes, first_hidden_encoding.activation_fxn, first_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H2)\n",
    "weight_eqns = np.append(weight_eqns, W2)\n",
    "bias_eqns = np.append(bias_eqns, B2)\n",
    "lin_eqns = np.append(lin_eqns, H_2_lin)\n",
    "hidden_states = np.append(hidden_states, H_2_val)\n",
    "\n",
    "second_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_2_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_2_val.transpose()), len(H_2_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_2_val.transpose()), len(H_2_val.transpose()))), base_weights = np.ones((len(H_2_val.transpose()), len(H_2_val.transpose()))), base_biases = np.ones((len(H_2_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT3\", real = True), sympy.symbols(\"VB3\", real = True), sympy.symbols(\"A_RBB3\", real = True), sympy.symbols(\"VBB3\", real = True), sympy.symbols(\"W3\", real = True), sympy.symbols(\"B3\", real = True), sympy.symbols(\"H_3\", real = True), sympy.symbols(\"H_2_conv\", real = True)]))\n",
    "H_3_val, H_2_conv, H_2_conv_T, H_3_lin_val, H_3_lin_T_val, H_3_lin, W3_vals, B3_vals, W3, B3, H3 = second_hidden_encoding.forward_graph_update(second_hidden_encoding.convolution_operation, second_hidden_encoding.input_tensor, second_hidden_encoding.weight_paramaters, second_hidden_encoding.bias_paramaters, second_hidden_encoding.base_weights, second_hidden_encoding.base_biases, second_hidden_encoding.layer_eqn_terms, second_hidden_encoding.orbital_overlap_schemes, second_hidden_encoding.activation_fxn, second_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H3)\n",
    "weight_eqns = np.append(weight_eqns, W3)\n",
    "bias_eqns = np.append(bias_eqns, B3)\n",
    "lin_eqns = np.append(lin_eqns, H_3_lin)\n",
    "hidden_states = np.append(hidden_states, H_3_val)\n",
    "\n",
    "third_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_3_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_3_val.transpose()), len(H_3_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_3_val.transpose()), len(H_3_val.transpose()))), base_weights = np.ones((len(H_3_val.transpose()), len(H_3_val.transpose()))), base_biases = np.ones((len(H_3_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT4\", real = True), sympy.symbols(\"VB4\", real = True), sympy.symbols(\"A_RBB4\", real = True), sympy.symbols(\"VBB4\", real = True), sympy.symbols(\"W4\", real = True), sympy.symbols(\"B4\", real = True), sympy.symbols(\"H_4\", real = True), sympy.symbols(\"H_3_conv\", real = True)]))\n",
    "H_4_val, H_3_conv, H_3_conv_T, H_4_lin_val, H_4_lin_T_val, H_4_lin, W4_vals, B4_vals, W4, B4, H4 = third_hidden_encoding.forward_graph_update(third_hidden_encoding.convolution_operation, third_hidden_encoding.input_tensor, third_hidden_encoding.weight_paramaters, third_hidden_encoding.bias_paramaters, third_hidden_encoding.base_weights, third_hidden_encoding.base_biases, third_hidden_encoding.layer_eqn_terms, third_hidden_encoding.orbital_overlap_schemes, third_hidden_encoding.activation_fxn, third_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H4)\n",
    "weight_eqns = np.append(weight_eqns, W4)\n",
    "bias_eqns = np.append(bias_eqns, B4)\n",
    "lin_eqns = np.append(lin_eqns, H_4_lin)\n",
    "hidden_states = np.append(hidden_states, H_4_val)\n",
    "\n",
    "fourth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_4_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_4_val.transpose()), len(H_4_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_4_val.transpose()), len(H_4_val.transpose()))), base_weights = np.ones((len(H_4_val.transpose()), len(H_4_val.transpose()))), base_biases = np.ones((len(H_4_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT5\", real = True), sympy.symbols(\"VB5\", real = True), sympy.symbols(\"A_RBB5\", real = True), sympy.symbols(\"VBB5\", real = True), sympy.symbols(\"W5\", real = True), sympy.symbols(\"B5\", real = True), sympy.symbols(\"H_5\", real = True), sympy.symbols(\"H_4_conv\", real = True)]))\n",
    "H_5_val, H_4_conv, H_4_conv_T, H_5_lin_val, H_5_lin_T_val, H_5_lin, W5_vals, B5_vals, W5, B5, H5 = fourth_hidden_encoding.forward_graph_update(fourth_hidden_encoding.convolution_operation, fourth_hidden_encoding.input_tensor, fourth_hidden_encoding.weight_paramaters, fourth_hidden_encoding.bias_paramaters, fourth_hidden_encoding.base_weights, fourth_hidden_encoding.base_biases, fourth_hidden_encoding.layer_eqn_terms, fourth_hidden_encoding.orbital_overlap_schemes, fourth_hidden_encoding.activation_fxn, fourth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H5)\n",
    "weight_eqns = np.append(weight_eqns, W5)\n",
    "bias_eqns = np.append(bias_eqns, B5)\n",
    "lin_eqns = np.append(lin_eqns, H_5_lin)\n",
    "hidden_states = np.append(hidden_states, H_5_val)\n",
    "\n",
    "fifth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_5_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_5_val.transpose()), len(H_5_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_5_val.transpose()), len(H_5_val.transpose()))), base_weights = np.ones((len(H_5_val.transpose()), len(H_5_val.transpose()))), base_biases = np.ones((len(H_5_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT6\", real = True), sympy.symbols(\"VB6\", real = True), sympy.symbols(\"A_RBB6\", real = True), sympy.symbols(\"VBB6\", real = True), sympy.symbols(\"W6\", real = True), sympy.symbols(\"B6\", real = True), sympy.symbols(\"H_6\", real = True), sympy.symbols(\"H_5_conv\", real = True)]))\n",
    "H_6_val, H_5_conv, H_5_conv_T, H_6_lin_val, H_6_lin_T_val, H_6_lin, W6_vals, B6_vals, W6, B6, H6 = fifth_hidden_encoding.forward_graph_update(fifth_hidden_encoding.convolution_operation, fifth_hidden_encoding.input_tensor, fifth_hidden_encoding.weight_paramaters, fifth_hidden_encoding.bias_paramaters, fifth_hidden_encoding.base_weights, fifth_hidden_encoding.base_biases, fifth_hidden_encoding.layer_eqn_terms, fifth_hidden_encoding.orbital_overlap_schemes, fifth_hidden_encoding.activation_fxn, fifth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H6)\n",
    "weight_eqns = np.append(weight_eqns, W6)\n",
    "bias_eqns = np.append(bias_eqns, B6)\n",
    "lin_eqns = np.append(lin_eqns, H_6_lin)\n",
    "hidden_states = np.append(hidden_states, H_6_val)\n",
    "\n",
    "sixth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_6_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_6_val.transpose()), len(H_6_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_6_val.transpose()), len(H_6_val.transpose()))), base_weights = np.ones((len(H_6_val.transpose()), len(H_6_val.transpose()))), base_biases = np.ones((len(H_6_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT7\", real = True), sympy.symbols(\"VB7\", real = True), sympy.symbols(\"A_RBB7\", real = True), sympy.symbols(\"VBB7\", real = True), sympy.symbols(\"W7\", real = True), sympy.symbols(\"B7\", real = True), sympy.symbols(\"H_7\", real = True), sympy.symbols(\"H_6_conv\", real = True)]))\n",
    "H_7_val, H_6_conv, H_6_conv_T, H_7_lin_val, H_7_lin_T_val, H_7_lin, W7_vals, B7_vals, W7, B7, H7 = sixth_hidden_encoding.forward_graph_update(sixth_hidden_encoding.convolution_operation, sixth_hidden_encoding.input_tensor, sixth_hidden_encoding.weight_paramaters, sixth_hidden_encoding.bias_paramaters, sixth_hidden_encoding.base_weights, sixth_hidden_encoding.base_biases, sixth_hidden_encoding.layer_eqn_terms, sixth_hidden_encoding.orbital_overlap_schemes, sixth_hidden_encoding.activation_fxn, sixth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H7)\n",
    "weight_eqns = np.append(weight_eqns, W7)\n",
    "bias_eqns = np.append(bias_eqns, B7)\n",
    "lin_eqns = np.append(lin_eqns, H_7_lin)\n",
    "hidden_states = np.append(hidden_states, H_7_val)\n",
    "\n",
    "seventh_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_7_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_7_val.transpose()), len(H_7_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_7_val.transpose()), len(H_7_val.transpose()))), base_weights = np.ones((len(H_7_val.transpose()), len(H_7_val.transpose()))), base_biases = np.ones((len(H_7_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT8\", real = True), sympy.symbols(\"VB8\", real = True), sympy.symbols(\"A_RBB8\", real = True), sympy.symbols(\"VBB8\", real = True), sympy.symbols(\"W8\", real = True), sympy.symbols(\"B8\", real = True), sympy.symbols(\"H_8\", real = True), sympy.symbols(\"H_7_conv\", real = True)]))\n",
    "H_8_val, H_7_conv, H_7_conv_T, H_8_lin_val, H_8_lin_T_val, H_8_lin, W8_vals, B8_vals, W8, B8, H8 = seventh_hidden_encoding.forward_graph_update(seventh_hidden_encoding.convolution_operation, seventh_hidden_encoding.input_tensor, seventh_hidden_encoding.weight_paramaters, seventh_hidden_encoding.bias_paramaters, seventh_hidden_encoding.base_weights, seventh_hidden_encoding.base_biases, seventh_hidden_encoding.layer_eqn_terms, seventh_hidden_encoding.orbital_overlap_schemes, seventh_hidden_encoding.activation_fxn, seventh_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H8)\n",
    "weight_eqns = np.append(weight_eqns, W8)\n",
    "bias_eqns = np.append(bias_eqns, B8)\n",
    "lin_eqns = np.append(lin_eqns, H_8_lin)\n",
    "hidden_states = np.append(hidden_states, H_8_val)\n",
    "\n",
    "eighth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_8_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_8_val.transpose()), len(H_8_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_8_val.transpose()), len(H_8_val.transpose()))), base_weights = np.ones((len(H_8_val.transpose()), len(H_8_val.transpose()))), base_biases = np.ones((len(H_8_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT9\", real = True), sympy.symbols(\"VB9\", real = True), sympy.symbols(\"A_RBB9\", real = True), sympy.symbols(\"VBB9\", real = True), sympy.symbols(\"W9\", real = True), sympy.symbols(\"B9\", real = True), sympy.symbols(\"H_9\", real = True), sympy.symbols(\"H_8_conv\", real = True)]))\n",
    "H_9_val, H_8_conv, H_8_conv_T, H_9_lin_val, H_9_lin_T_val, H_9_lin, W9_vals, B9_vals, W9, B9, H9 = eighth_hidden_encoding.forward_graph_update(eighth_hidden_encoding.convolution_operation, eighth_hidden_encoding.input_tensor, eighth_hidden_encoding.weight_paramaters, eighth_hidden_encoding.bias_paramaters, eighth_hidden_encoding.base_weights, eighth_hidden_encoding.base_biases, eighth_hidden_encoding.layer_eqn_terms, eighth_hidden_encoding.orbital_overlap_schemes, eighth_hidden_encoding.activation_fxn, eighth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H9)\n",
    "weight_eqns = np.append(weight_eqns, W9)\n",
    "bias_eqns = np.append(bias_eqns, B9)\n",
    "lin_eqns = np.append(lin_eqns, H_9_lin)\n",
    "hidden_states = np.append(hidden_states, H_9_val)\n",
    "\n",
    "ninth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_9_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_9_val.transpose()), len(H_9_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_9_val.transpose()), len(H_9_val.transpose()))), base_weights = np.ones((len(H_9_val.transpose()), len(H_9_val.transpose()))), base_biases = np.ones((len(H_9_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT10\", real = True), sympy.symbols(\"VB10\", real = True), sympy.symbols(\"A_RBB9\", real = True), sympy.symbols(\"VBB9\", real = True), sympy.symbols(\"W10\", real = True), sympy.symbols(\"B10\", real = True), sympy.symbols(\"H_10\", real = True), sympy.symbols(\"H_9_conv\", real = True)]))\n",
    "H_10_val, H_9_conv, H_9_conv_T, H_10_lin_val, H_10_lin_T_val, H_10_lin, W10_vals, B10_vals, W10, B10, H10 = ninth_hidden_encoding.forward_graph_update(ninth_hidden_encoding.convolution_operation, ninth_hidden_encoding.input_tensor, ninth_hidden_encoding.weight_paramaters, ninth_hidden_encoding.bias_paramaters, ninth_hidden_encoding.base_weights, ninth_hidden_encoding.base_biases, ninth_hidden_encoding.layer_eqn_terms, ninth_hidden_encoding.orbital_overlap_schemes, ninth_hidden_encoding.activation_fxn, ninth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H10)\n",
    "weight_eqns = np.append(weight_eqns, W10)\n",
    "bias_eqns = np.append(bias_eqns, B10)\n",
    "lin_eqns = np.append(lin_eqns, H_10_lin)\n",
    "hidden_states = np.append(hidden_states, H_10_val)\n",
    "\n",
    "tenth_hidden_encoding = Computational_RGCN_Layer(input_tensor = H_10_val, convolution_operation = graph_tensor_avg_convolution(adj_matrix, n_atoms), weight_paramaters = np.ones((len(orbital_overlap_types), len(H_10_val.transpose()), len(H_10_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), len(H_10_val.transpose()), len(H_10_val.transpose()))), base_weights = np.ones((len(H_10_val.transpose()), len(H_10_val.transpose()))), base_biases = np.ones((len(H_10_val.transpose()),)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"gelu\", atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), layer_eqn_terms = np.array([sympy.symbols(\"A_RBT11\", real = True), sympy.symbols(\"VB11\", real = True), sympy.symbols(\"A_RBB10\", real = True), sympy.symbols(\"VBB10\", real = True), sympy.symbols(\"W11\", real = True), sympy.symbols(\"B11\", real = True), sympy.symbols(\"H_11\", real = True), sympy.symbols(\"H_10_conv\", real = True)]))\n",
    "H_11_val, H_10_conv, H_10_conv_T, H_11_lin_val, H_11_lin_T_val, H_11_lin, W11_vals, B11_vals, W11, B11, H11 = tenth_hidden_encoding.forward_graph_update(tenth_hidden_encoding.convolution_operation, tenth_hidden_encoding.input_tensor, tenth_hidden_encoding.weight_paramaters, tenth_hidden_encoding.bias_paramaters, tenth_hidden_encoding.base_weights, tenth_hidden_encoding.base_biases, tenth_hidden_encoding.layer_eqn_terms, tenth_hidden_encoding.orbital_overlap_schemes, tenth_hidden_encoding.activation_fxn, tenth_hidden_encoding.atom_node_connections)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H11)\n",
    "weight_eqns = np.append(weight_eqns, W11)\n",
    "bias_eqns = np.append(bias_eqns, B11)\n",
    "lin_eqns = np.append(lin_eqns, H_11_lin)\n",
    "hidden_states = np.append(hidden_states, H_11_val)\n",
    "\n",
    "readout_layer = Readout_RGCN_Layer(input_tensor = H_11_val, weight_paramaters = np.ones((len(orbital_overlap_types), len(H_11_val.transpose()), len(H_11_val.transpose()))), bias_paramaters = np.ones((len(orbital_overlap_types), readout_node_features, readout_node_features)), base_weights = np.ones((len(H_11_val.transpose()), readout_node_features)), base_biases = np.ones((readout_node_features,)), orbital_overlap_schemes = orbital_overlap_types, activation_fxn = \"Lrelu\", n_contraction_coeff = readout_node_features, atom_node_connections = compute_node_connection_degrees(adj_matrix, n_atoms), readout_layer_eqn = np.array([sympy.symbols(\"A_RBTf\", real = True), sympy.symbols(\"VBf\", real = True), sympy.symbols(\"A_RBBf\", real = True), sympy.symbols(\"VBBf\", real = True), sympy.symbols(\"Wf_T\", real = True), sympy.symbols(\"bf\", real = True), sympy.symbols(\"H_f-1\", real = True), sympy.symbols(\"H_f-1_T\", real = True)]), contraction_coefficient_range = contraction_coefficient_range, initial_state_floats = initial_state_floats, maximum_s_el = molecular_graph_details.maximum_s_el, maximum_p_el = molecular_graph_details.maximum_p_el, maximum_d_el = molecular_graph_details.maximum_d_el, maximum_f_el = molecular_graph_details.maximum_f_el)\n",
    "H_f_val, H_f_lin_val, H_f_lin, Wf_val, Bf_val, Wf, Bf, H_f = readout_layer.readout_graph_update(readout_layer.input_tensor, readout_layer.weight_paramaters, readout_layer.bias_paramaters, readout_layer.base_weights, readout_layer.base_biases, readout_layer.readout_layer_eqn, readout_layer.orbital_overlap_schemes, readout_layer.activation_fxn, readout_layer.n_contraction_coeff, readout_layer.atom_node_connections, readout_layer.initial_state_floats, readout_layer.contraction_coefficient_range, readout_layer.maximum_s_el, readout_layer.maximum_p_el, readout_layer.maximum_d_el, readout_layer.maximum_f_el)\n",
    "hidden_state_eqns = np.append(hidden_state_eqns, H_f)\n",
    "weight_eqns = np.append(weight_eqns, Wf)\n",
    "bias_eqns = np.append(bias_eqns, Bf)\n",
    "lin_eqns = np.append(lin_eqns, H_f_lin)\n",
    "\n",
    "\n",
    "#print(H_f_val, hidden_state_eqns, weight_eqns, bias_eqns, lin_eqns)\n",
    "print(hidden_states)\n",
    "print(np.shape(H_f_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72780c47-5602-4cf5-9d39-2f04f55d4d7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 663)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:663\u001b[0;36m\u001b[0m\n\u001b[0;31m    a_cage_gradient_changes = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Set up gradient descent algorithm for backpropagation, Lrelu + Gelu activation optimization on DFT-calculated cluster energy dataset\n",
    "class System_Energy_Optimizer:\n",
    "    def __init__(self, LR_o, K, t, input_tensor, C_i_C_n, H_o_H_f, hidden_state_eqns, W_o_W_f, B_o_B_f, lin_regs, E_xc, n_bonding_electrons, n_atoms, unit_charge, atomic_orbital_states, R_inner, delta_o_cut, maximum_density_bound, gradient_descent_schedule, exponential_range, nuclear_separation_matrix, bond_separation_matrix, pos_matrix, degree_vector, atomic_positions, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, aromatic_rings, aromatic_cages, orbital_tracker, KS_functional_tracker):\n",
    "        self.LR_o = LR_o\n",
    "        self.K = K\n",
    "        self.t = t\n",
    "        self.input_tensor = input_tensor\n",
    "        self.C_i_C_n = C_i_C_n\n",
    "        self.H_o_H_f = H_o_H_f\n",
    "        self.hidden_state_eqns = hidden_state_eqns\n",
    "        self.W_o_W_f = W_o_W_f\n",
    "        self.B_o_B_f = B_o_B_f\n",
    "        self.lin_regs = lin_regs\n",
    "        self.E_xc = E_xc\n",
    "        self.n_bonding_electrons = n_bonding_electrons\n",
    "        self.n_atoms = n_atoms\n",
    "        self.unit_charge = unit_charge\n",
    "        self.atomic_orbital_states = atomic_orbital_states\n",
    "        self.R_inner = R_inner\n",
    "        self.delta_o_cut = delta_o_cut\n",
    "        self.maximum_density_bound = maximum_density_bound\n",
    "        self.gradient_descent_schedule = gradient_descent_schedule\n",
    "        self.exponential_range = exponential_range\n",
    "        self.nuclear_separation_matrix = nuclear_separation_matrix\n",
    "        self.bond_separation_matrix = bond_separation_matrix\n",
    "        self.pos_matrix = pos_matrix\n",
    "        self.degree_vector = degree_vector\n",
    "        self.atomic_positions = atomic_positions\n",
    "        self.maximum_s_el = maximum_s_el\n",
    "        self.maximum_p_el = maximum_p_el\n",
    "        self.maximum_d_el = maximum_d_el\n",
    "        self.maximum_f_el = maximum_f_el\n",
    "        self.aromatic_rings = aromatic_rings\n",
    "        self.aromatic_cages = aromatic_cages\n",
    "        self.orbital_tracker = orbital_tracker\n",
    "        self.KS_functional_tracker = KS_functional_tracker\n",
    "\n",
    "    \n",
    "    def construct_grad_descent_schedule(self, LR_o, t, K, gradient_descent_schedule):\n",
    "        # implement RMS normalization for stochastic gradient descent - calculate gradients as cumulative moving average of sqaures, normalize by square root of mean-square gradient, and update weights in direction of gloabl min in accordance with sign of previous gradient with respect to the previous weight \n",
    "        # paper link: https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a\n",
    "        if gradient_descent_schedule == \"MBGD\":\n",
    "            LR = LR_o * np.exp(-K * t)\n",
    "        return LR\n",
    "   \n",
    "    def construct_single_electron_wavefunctions(self, input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        s_MO_set = sympy.Array([])\n",
    "        p_MO_set = sympy.Array([])\n",
    "        d_MO_set = sympy.Array([])\n",
    "        f_MO_set = sympy.Array([])\n",
    "        s_ref_set = sympy.Array([])\n",
    "        p_ref_set = sympy.Array([])\n",
    "        d_ref_set = sympy.Array([])\n",
    "        f_ref_set = sympy.Array([])\n",
    "        s_exp_set = sympy.Array([])\n",
    "        p_exp_set = sympy.Array([])\n",
    "        d_exp_set = sympy.Array([])\n",
    "        f_exp_set = sympy.Array([])\n",
    "        exp_set = sympy.Array([])\n",
    "        one_electron_MOs = np.array([])\n",
    "        gaussian_terms = []\n",
    "        coefficient_sequence = []\n",
    "        exp_set = []\n",
    "        r = sympy.symbols(\"r\", real = True)\n",
    "        j = sympy.symbols(\"j\", real = True)\n",
    "        s_exponentials = 1\n",
    "        p_exponentials = atomic_orbital_states[\"p\"][1] - atomic_orbital_states[\"s\"]\n",
    "        d_exponentials = atomic_orbital_states[\"d\"][1] - atomic_orbital_states[\"p\"][1]\n",
    "        f_exponentials = atomic_orbital_states[\"f\"][0]\n",
    "        i = 0\n",
    "        for i in range(0, n_atoms):\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials - 1:\n",
    "                exp_start = exponential_range[s_exponentials - 1]\n",
    "                s_coefficient_range = C_i_C_n[i][0:maximum_s_el * s_exponentials]\n",
    "                j = 0\n",
    "                for j in range(0, len(s_coefficient_range)):\n",
    "                    current_contraction_coeff = s_coefficient_range[j]\n",
    "                    if current_contraction_coeff != 0:\n",
    "                        current_s_MO = current_contraction_coeff * sympy.exp(-input_tensor[i][exp_start] * r)\n",
    "                        s_MO_set = np.append(s_MO_set, np.array([current_s_MO, i + 1]))\n",
    "                        s_ref_set = np.append(s_ref_set, current_s_MO)\n",
    "                        s_exp_set = np.append(s_exp_set, sympy.exp(-input_tensor[i][exp_start] * r))\n",
    "                        gaussian_terms.append(current_s_MO)\n",
    "                        coefficient_sequence.append(current_contraction_coeff)\n",
    "                        j += s_exponentials\n",
    "            else:\n",
    "                pass\n",
    "            exp_range_vals = np.arange(exponential_range[0], exponential_range[1] + 1)\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el:\n",
    "                p_coefficient_range = C_i_C_n[i][maximum_s_el * s_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials]\n",
    "                j = 0\n",
    "                p_MO_contributions = 0\n",
    "                while j <= len(p_coefficient_range):\n",
    "                    current_contraction_coeffs = p_coefficient_range[j: j + p_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            p_exp_set = np.append(p_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r))\n",
    "                            p_MO_contributions = p_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += p_exponentials\n",
    "                    if j <= len(p_coefficient_range):\n",
    "                        p_MO_set = np.append(p_MO_set, np.array([p_MO_contributions, i + 1]))  \n",
    "                        p_ref_set = np.append(p_ref_set, p_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el:\n",
    "                d_coefficient_range = C_i_C_n[i][maximum_s_el * s_exponentials + maximum_p_el * p_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el + d_exponentials]\n",
    "                j = 0\n",
    "                d_MO_contributions = 0\n",
    "                while j <= len(d_coefficient_range):\n",
    "                    current_contraction_coeffs = d_coefficient_range[j: j + d_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            d_exp_set = np.append(d_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r))\n",
    "                            d_MO_contributions = d_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += d_exponentials\n",
    "                    if j <= len(d_coefficient_range):\n",
    "                        d_MO_set = np.append(d_MO_set, np.array([d_MO_contributions, i + 1])) \n",
    "                        d_ref_set = np.append(d_ref_set, d_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el:\n",
    "                f_coefficient_range = C_i_C_n[i][s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el * d_exponentials + maximum_f_el * f_exponentials]\n",
    "                j = 0\n",
    "                f_MO_contributions = 0\n",
    "                while j <= len(f_coefficient_range):\n",
    "                    current_contraction_coeffs = d_coefficient_range[j: j + f_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            f_exp_set = np.append(f_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r))\n",
    "                            f_MO_contributions = f_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += f_exponentials\n",
    "                    if j <= len(f_coefficient_range):\n",
    "                        f_MO_set = np.append(f_MO_set, np.array([f_MO_contributions, i + 1])) \n",
    "                        f_ref_set = np.append(f_ref_set, f_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            i += 1\n",
    "        Ci = sympy.symbols(\"Ci\", real = True)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, s_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, p_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, d_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, f_MO_set)\n",
    "        exp_set = np.append(exp_set, s_exp_set)\n",
    "        exp_set = np.append(exp_set, p_exp_set)\n",
    "        exp_set = np.append(exp_set, d_exp_set)\n",
    "        exp_set = np.append(exp_set, f_exp_set)\n",
    "        one_electron_MO_eqns = np.array([])\n",
    "        k = 0\n",
    "        for k in range(0, len(s_ref_set) * s_exponentials):\n",
    "            current_s_MO_eqn = Ci * exp_set[k]\n",
    "            one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_s_MO_eqn)\n",
    "            k += 1\n",
    "        p_gaussian_start_index = (len(s_ref_set) * s_exponentials) - 1\n",
    "        p_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        p_gaussian_count = p_gaussian_end_index - p_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(p_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials]\n",
    "            current_exponentials = exp_set[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials* k + p_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        d_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        d_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        d_gaussian_count = d_gaussian_end_index - d_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(d_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials]\n",
    "            current_exponentials = exp_set[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials* k + d_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        f_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        f_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials + len(f_ref_set) * f_exponentials) - 1\n",
    "        f_gaussian_count = f_gaussian_end_index - f_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(f_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials]\n",
    "            current_exponentials = exp_set[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials* k + f_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "                    \n",
    "        return one_electron_MOs, one_electron_MO_eqns, r\n",
    "\n",
    "    def compute_effective_density_cutoffs(self, input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, maximum_density_bound, bond_separation_matrix, pos_matrix, nuclear_separation_matrix):\n",
    "        single_el_wavefunctions, single_el_wavefunction_eqs, r = self.construct_single_electron_wavefunctions(energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.n_atoms, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el)\n",
    "        normalized_dist_fxns = np.array([])\n",
    "        maximum_el_density_radii = np.array([])\n",
    "        i = 0\n",
    "        while i < len(single_el_wavefunctions):\n",
    "            norm_constant = sympy.symbols(\"A\", real = True)\n",
    "            normalized_wavefunc = norm_constant * single_el_wavefunctions[i]\n",
    "            total_probability_density = sympy.integrals.integrate(normalized_wavefunc, (r, R_inner, maximum_density_bound))\n",
    "            norm_constant = sympy.solve(total_probability_density - 1, norm_constant)\n",
    "            normalized_wavefunc = norm_constant[0] * single_el_wavefunctions[i]\n",
    "            normalized_dist_fxns = np.append(normalized_dist_fxns, normalized_wavefunc)\n",
    "            enclosed_probability_density = sympy.integrals.integrate(normalized_wavefunc, r)\n",
    "            inner_cutoff_single_electron_density = enclosed_probability_density.replace(r, R_inner)\n",
    "            ith_electron_density_range = ((enclosed_probability_density - inner_cutoff_single_electron_density) - 0.98)**2\n",
    "            ith_density_range_fxn = sympy.lambdify(r, ith_electron_density_range)\n",
    "            min_square_enclosed_density = scipy.optimize.minimize_scalar(ith_density_range_fxn)\n",
    "            ith_maximum_density_radius = min_square_enclosed_density.x\n",
    "            maximum_el_density_radii = np.append(maximum_el_density_radii, ith_maximum_density_radius)\n",
    "            maximum_el_density_radii = np.append(maximum_el_density_radii, single_el_wavefunctions[i + 1])\n",
    "            i += 2\n",
    "        j = 0\n",
    "        k = 0\n",
    "        domain_overlap_matrix = np.zeros((int((len(maximum_el_density_radii)/2)), int((len(maximum_el_density_radii)/2))))\n",
    "        inner_overlap_cutoff_matrix = np.zeros((int((len(maximum_el_density_radii)/2)), int((len(maximum_el_density_radii)/2))))\n",
    "        outer_overlap_cutoff_matrix = np.zeros((int((len(maximum_el_density_radii)/2)), int((len(maximum_el_density_radii)/2))))\n",
    "        while j < len(maximum_el_density_radii):\n",
    "            jth_domain_center = pos_matrix[single_el_wavefunctions[j+1]-1]\n",
    "            while k < len(maximum_el_density_radii):\n",
    "                kth_domain_center = pos_matrix[single_el_wavefunctions[k+1]-1]\n",
    "                if k == j:\n",
    "                    overlap_state = 0\n",
    "                    domain_overlap_matrix[j][k] = overlap_state\n",
    "                    print(overlap_state)\n",
    "                elif single_el_wavefunctions[k+1] == single_el_wavefunctions[j+1]:\n",
    "                    overlap_state = 1\n",
    "                    domain_overlap_matrix[int(j/2)][int(k/2)] = overlap_state\n",
    "                    inner_overlap_cutoff_matrix[int(j/2)][int(k/2)] = 0\n",
    "                    if maximum_el_density_radii[j] == maximum_el_density_radii[k]:\n",
    "                        outer_overlap_cutoff_matrix[int(j/2)][int(k/2)] = maximum_el_density_radii[j]\n",
    "                    else:\n",
    "                        outer_overlap_cutoff_matrix[int(j/2)][int(k/2)] = min(np.array([maximum_el_density_radii[j], maximum_el_density_radii[k]]))\n",
    "                else:\n",
    "                    x_pos = sympy.symbols(\"x\", real = True)\n",
    "                    y_pos = sympy.symbols(\"y\", real = True)\n",
    "                    z_pos = sympy.symbols(\"z\", real = True)\n",
    "                    k_max_density_enclosure_sphere = sympy.sqrt((x_pos -  pos_matrix[single_el_wavefunctions[k+1]-1][0])**2 + (y_pos -  pos_matrix[single_el_wavefunctions[k+1]-1][1])**2 + (z_pos -  pos_matrix[single_el_wavefunctions[k+1]-1][2])**2) - maximum_el_density_radii[k]\n",
    "                    jth_nucleus_separation_function = sympy.sqrt((x_pos - pos_matrix[single_el_wavefunctions[j+1]-1][0])**2 + (y_pos - pos_matrix[single_el_wavefunctions[j+1]-1][1])**2 + (z_pos - pos_matrix[single_el_wavefunctions[j+1]-1][2])**2)   \n",
    "                    constraint_surface = k_max_density_enclosure_sphere + maximum_el_density_radii[k]\n",
    "                    constraint_gradient = np.array([sympy.diff(constraint_surface, x_pos), sympy.diff(constraint_surface, y_pos), sympy.diff(constraint_surface, z_pos)])\n",
    "                    nucleus_separation_gradient = np.array([sympy.diff(jth_nucleus_separation_function, x_pos), sympy.diff(jth_nucleus_separation_function, y_pos), sympy.diff(jth_nucleus_separation_function, z_pos)])\n",
    "                    lagrangian = sympy.symbols(\"lambda\", real = True)\n",
    "                    min_point_and_lagrangian = sympy.solve([k_max_density_enclosure_sphere, nucleus_separation_gradient[0] - lagrangian * constraint_gradient[0],  nucleus_separation_gradient[1] - lagrangian * constraint_gradient[1], nucleus_separation_gradient[2] - lagrangian * constraint_gradient[2]], x_pos, y_pos, z_pos, lagrangian, dict = True)\n",
    "                    x_min = min_point_and_lagrangian[0][x_pos]\n",
    "                    lagrangian = min_point_and_lagrangian[0][lagrangian]\n",
    "                    x_min_chars = str(x_min)\n",
    "                    if \"x\" in x_min_chars or \"y\" in x_min_chars or \"z\" in x_min_chars:\n",
    "                        guess_vectors = 0\n",
    "                        while guess_vectors < 1:\n",
    "                            initial_x = np.random.uniform(pos_matrix[single_el_wavefunctions[k+1]-1][0],  pos_matrix[single_el_wavefunctions[k+1]-1][0] + maximum_el_density_radii[k])\n",
    "                            initial_y = np.random.uniform(pos_matrix[single_el_wavefunctions[k+1]-1][1],  pos_matrix[single_el_wavefunctions[k+1]-1][1] + maximum_el_density_radii[k])\n",
    "                            initial_density_enclosure_sphere = k_max_density_enclosure_sphere.replace(x_pos, initial_x).replace(y_pos, initial_y)\n",
    "                            initial_z = sympy.solve(initial_density_enclosure_sphere, z_pos)\n",
    "                            if len(initial_z)== 0:\n",
    "                                continue\n",
    "                            else:\n",
    "                                guess_vector = np.array([initial_x, initial_y, initial_z[0]])\n",
    "                                guess_vectors += 1\n",
    "                        kth_axial_angle = sympy.symbols(\"theta\", real = True)\n",
    "                        k_theta = sympy.solve(sympy.tan(kth_axial_angle) - (initial_y / initial_x))[0]\n",
    "                        k_azimuthl_angle = sympy.symbols(\"phi\", real = True)\n",
    "                        k_phi = sympy.solve(k_azimuthl_angle - sympy.acos(initial_z[0] / (sympy.sqrt(initial_x**2 + initial_y**2 + initial_z[0]**2))))[0]\n",
    "                        k_theta_mirror = k_theta + np.pi\n",
    "                        k_phi_mirror = np.pi - k_phi\n",
    "                        x_mirror = maximum_el_density_radii[k] * sympy.sin(k_phi_mirror) * sympy.cos(k_theta_mirror)\n",
    "                        y_mirror = maximum_el_density_radii[k] * sympy.sin(k_phi_mirror) * sympy.sin(k_theta_mirror)\n",
    "                        z_mirror = maximum_el_density_radii[k] * sympy.cos(k_phi_mirror)\n",
    "                        test_point_radius = (sympy.sqrt((x_mirror - initial_x)**2 + (y_mirror - initial_y)**2 + (z_mirror - initial_z[0])**2)) / 2\n",
    "                        if abs(test_point_radius - maximum_el_density_radii[k]) < 1e-10:\n",
    "                            kth_density_radius_scaling_factor = test_point_radius / nuclear_separation_matrix[single_el_wavefunctions[j+1]-1][single_el_wavefunctions[k+1]-1]\n",
    "                            x_min = (pos_matrix[k][0] - pos_matrix[j][0]) * kth_density_radius_scaling_factor\n",
    "                            y_min = (pos_matrix[k][1] - pos_matrix[j][1]) * kth_density_radius_scaling_factor\n",
    "                            z_min = (pos_matrix[k][2] - pos_matrix[j][2]) * kth_density_radius_scaling_factor\n",
    "                        if sympy.sqrt(x_min**2 + y_min**2 + z_min**2) < maximum_el_density_radii[j]:\n",
    "                            overlap_state = 1\n",
    "                            domain_overlap_matrix[int(j/2)][int(k/2)] = overlap_state\n",
    "                            j_k_inner_overlap_cutoff = sympy.sqrt(x_min**2 + y_min**2 + z_min**2)\n",
    "                            j_k_outer_overlap_cutoff = maximum_el_density_radii[j]\n",
    "                            inner_overlap_cutoff_matrix[int(j/2)][int(2/k)] = j_k_inner_overlap_cutoff\n",
    "                            outer_overlap_cutoff_matrix[int(j/2)][int(k/2)] = j_k_outer_overlap_cutoff\n",
    "                            print(overlap_state, j_k_inner_overlap_cutoff, j_k_outer_overlap_cutoff)\n",
    "                        else:\n",
    "                            overlap_state = 0\n",
    "                            domain_overlap_matrix[int(j/2)][int(k/2)] = overlap_state \n",
    "                            print(overlap_state)\n",
    "                    else:\n",
    "                        y_min = min_point_and_lagrangian[0][y_pos]\n",
    "                        z_min = min_point_and_lagrangian[0][z_pos]\n",
    "                        if jth_nucleus_separation_function.replace(x_pos, x_min).replace(y_pos, y_min).replace(z_pos, z_min) < maximum_el_density_radii[j]:\n",
    "                            overlap_state = 1\n",
    "                            domain_overlap_matrix[int(j/2)][int(k/2)] = overlap_state\n",
    "                            j_k_inner_overlap_cutoff = jth_nucleus_separation_function.replace(x_pos, x_min).replace(y_pos, y_min).replace(z_pos, z_min)\n",
    "                            j_k_outer_overlap_cutoff = maximum_el_density_radii[j]\n",
    "                            inner_overlap_cutoff_matrix[int(j/2)][int(k/2)] = j_k_inner_overlap_cutoff\n",
    "                            outer_overlap_cutoff_matrix[int(j/2)][int(k/2)] = j_k_outer_overlap_cutoff\n",
    "                            print(overlap_state, j_k_inner_overlap_cutoff, j_k_outer_overlap_cutoff)\n",
    "                        else:\n",
    "                            overlap_state = 0\n",
    "                            domain_overlap_matrix[int(j/2)][int(k/2)] = overlap_state\n",
    "                            print(overlap_state)\n",
    "                k += 2\n",
    "            j += 2\n",
    "        return maximum_el_density_radii, domain_overlap_matrix, inner_overlap_cutoff_matrix, outer_overlap_cutoff_matrix\n",
    "\n",
    "    def slater_determinant(self, input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, n_bonding_electrons):\n",
    "        single_el_wavefunctions, single_el_wavefunction_eqs, r = self.construct_single_electron_wavefunctions(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el)\n",
    "        i = 0\n",
    "        current_wavefunction_combinations = np.array([])\n",
    "        wavefunction_combination_matrix = np.array([])\n",
    "        electron_set = np.array([])\n",
    "        wavefunc_set = np.array([])\n",
    "        lower_diag = np.array([])\n",
    "        while i < len(single_el_wavefunctions):\n",
    "            wavefunc_set = np.append(wavefunc_set, single_el_wavefunctions[i])\n",
    "            i += 2\n",
    "        for j in np.arange(0, len(wavefunc_set)):\n",
    "            for k in np.arange(0, n_bonding_electrons):\n",
    "                current_electron = sympy.symbols(\"r\" + str(k), real = True)\n",
    "                current_wavefunction_combinations = np.append(current_wavefunction_combinations, wavefunc_set[j].replace(r, current_electron))\n",
    "                k += 1\n",
    "            j += 1\n",
    "        wavefunction_combination_matrix = current_wavefunction_combinations.reshape(len(wavefunc_set), n_bonding_electrons)\n",
    "        wavefunction_combination_matrix = sympy.Matrix(wavefunction_combination_matrix)\n",
    "        perm, lower, upper = wavefunction_combination_matrix.LUdecomposition()\n",
    "        perm = np.array(perm)\n",
    "        lower = np.array(lower)\n",
    "        upper = np.array(upper)\n",
    "        print(lower)\n",
    "        if len(perm) > 0:\n",
    "            perm_diagonal_swaps = len(np.diag(perm)) - np.sum(np.diag(perm)) - 1\n",
    "        else:\n",
    "            perm_diagonal_swaps = 0\n",
    "        #for i in np.arange(0, len(lower)):\n",
    "            #print(lower[i][i])\n",
    "            #lower_diag = np.append(lower_diag, lower[i][i])\n",
    "            #print(i)\n",
    "        #perm_det = (-1)**perm_diagonal_swaps\n",
    "        #lower_det = np.prod(np.diag(lower))\n",
    "        #upper_det = np.prod(np.diag(upper))\n",
    "        #overall_system_wavefunc = upper_det * lower_det * perm_det\n",
    "        return lower[0][0], lower[1][1], lower[2][2], lower[3][3], lower[4][4], lower[5][5]\n",
    "        \n",
    "\n",
    "    def MC_functional_integration_estimate(self, input_tensor, n_atoms, atomic_orbital_states, C_i_C_n, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, delta_o_cut, maximum_density_bound, nuclear_separation_matrix, bond_separation_matrix, atomic_positions, aromatic_rings, aromatic_cages, orbital_tracker, KS_functional_tracker, pos_matrix):  \n",
    "        single_electron_wavefunctions, single_electron_eqns, r = self.construct_single_electron_wavefunctions(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el)\n",
    "        r_eff_max, domain_overlap_matrix, inner_overlap_matrix, outer_overlap_matrix = self.compute_effective_density_cutoffs(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, maximum_density_bound, pos_matrix)\n",
    "        BCP_bias_decay = -0.1\n",
    "        # implement either straight-line distance of random var point on sphere from zero-gradient point of single-electron wavefunction, or staight-line distance from random R3 point from R3 line separating nuclei in bond\n",
    "        MC_estimate = 0\n",
    "        n_random_samples = 1000\n",
    "        gradient_eval_samples = 500 #for evaluation of electron density gradient at every pm of the internuclear/ring/cage max effective separation\n",
    "        sample_count = 0\n",
    "        prev_gradient_sample = 0\n",
    "        atomic_numbers = input_tensor.transpose()[2]\n",
    "        a = 2 * orbital_tracker\n",
    "        print(a)\n",
    "        if KS_functional_tracker == \"v_ext\":\n",
    "            while a <= (2 * orbital_tracker) + 1:\n",
    "                max_density_separations = np.array([])\n",
    "                random_pos_samples = np.array([])\n",
    "                known_rings = np.array([])\n",
    "                known_cages = np.array([])\n",
    "                point_pdf_score = np.array([])\n",
    "                nucleus_a_inner_cutoffs = np.array([])\n",
    "                corrected_nuclear_separations = np.array([])\n",
    "                for j in np.arange(0, len(aromatic_rings)):\n",
    "                    if single_electron_wavefunctions[a+1] in aromatic_rings[j]:\n",
    "                        nucleus_on_ring = True\n",
    "                        electron_i_aromatic_ring = j\n",
    "                        known_rings = np.append(known_rings, j)\n",
    "                    else:\n",
    "                        nucleus_on_ring = False\n",
    "                for k in np.arange(0, len(aromatic_cages)):\n",
    "                    if single_electron_wavefunctions[a+1] in aromatic_cages[j]:\n",
    "                        nucleus_on_cage = True\n",
    "                        electron_i_cage_surface = j\n",
    "                        known_cages = np.append(known_cages, j)\n",
    "                    else:\n",
    "                        nucleus_on_cage = False\n",
    "                if nucleus_on_ring == True:\n",
    "                    RCPs = np.array([])\n",
    "                    ring_gradient_changes = []\n",
    "                    ring_atom_separations = np.array([])\n",
    "                    ring_density_gradient_step = 0\n",
    "                    nuclei_on_ring = aromicatic_rings[electron_i_aromatic_ring]\n",
    "                    for k in np.arange(0, len(nuclei_on_ring)):\n",
    "                        ring_atom_separations = np.append(ring_atom_separations, np.sqrt((pos_matrix[nuclei_on_ring[k]][0] - pos_matrix[single_electron_wavefunctions[a+1] - 1][0])**2 + (pos_matrix[nuclei_on_ring[k]][1] - pos_matrix[single_electron_wavefunctions[a+1] - 1][1])**2 + (pos_matrix[nuclei_on_ring[k]][2] - pos_matrix[single_electron_wavefunctions[a+1] - 1][2])**2))\n",
    "                    adjusted_max_ring_pos = max(ring_atom_separations) - 2*R_inner\n",
    "                    ring_density_gradient_step = ring_density_gradient_step + (adjusted_max_ring_pos / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    ring_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        ring_density_gradient_eval_set = np.append(ring_density_gradient_eval_set, R_inner + j * ring_density_gradient_step)\n",
    "                        j += 1\n",
    "                    j = 0\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, ring_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        ring_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(ring_gradient_changes)))\n",
    "                    gradient_min_separation = ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                        RCPs = np.append(RCPs, gradient_min_separation)\n",
    "                    possible_density_maxima = np.array([R_inner])\n",
    "                    possible_density_maxima = np.append(possible_density_maxima, RCPs)\n",
    "                    for j in np.arange(0, len(ring_atom_separations)):\n",
    "                        possible_density_maxima = np.append(possible_density_maxima, ring_atom_separations[j] - R_inner)\n",
    "                    least_separation_from_density_max = min(possible_density_maxima)\n",
    "                elif nucleus_on_cage == True:\n",
    "                    CCPs = np.array([])\n",
    "                    cage_gradient_changes = []\n",
    "                    cage_atom_separations = np.array([])\n",
    "                    cage_density_gradient_step = 0\n",
    "                    nuclei_on_cage = aromatic_cages[electron_i_cage_surface]\n",
    "                    for k in np.arange(0, len(nuclei_on_cage)):\n",
    "                        cage_atom_separations = np.append(cage_atom_separations, np.sqrt((pos_matrix[nuclei_on_cage[j]][0] - pos_matrix[single_electron_wavefunctions[a+1] - 1][0])**2 + (pos_matrix[nuclei_on_cage[j]][1] - pos_matrix[single_electron_wavefunctions[a+1] - 1][1])**2 + (pos_matrix[nuclei_on_cage[j]][2] - pos_matrix[single_electron_wavefunctions[a+1] - 1][2])**2))\n",
    "                    adjusted_max_cage_pos = max(cage_atom_separations) - 2*R_inner\n",
    "                    cage_density_gradient_step = cage_densiy_gradient_step + (adjusted_max_cage_pos / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    cage_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        cage_density_gradient_eval_set = np.append(cage_density_gradient_eval_set, R_inner + j * cage_density_gradient_step)\n",
    "                        j += 1\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    j = 0\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, cage_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        cage_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(cage_gradient_changes)))\n",
    "                    gradient_min_separation = cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(cage_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(cage_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                        CCPs = np.append(CCPs, gradient_min_separation)\n",
    "                    possible_density_maxima = np.array([R_inner])\n",
    "                    possible_density_maxima = np.append(possible_density_maxima, CCPs)\n",
    "                    for j in np.arange(0, len(cage_atom_separations)):\n",
    "                        possible_density_maxima = np.append(possible_density_maxima, cage_atom_separations[j] - R_inner)\n",
    "                    least_separation_from_density_max = min(possible_density_maxima)\n",
    "                else:\n",
    "                    BCPs = np.array([])\n",
    "                    bond_gradient_changes = []\n",
    "                    bond_density_gradient_step = 0\n",
    "                    bond_maximum_separation = max(bond_separation_matrix[single_electron_wavefunctions[a+1] - 1]) \n",
    "                    adjusted_bond_max_separation = bond_maximum_separation - 2*R_inner\n",
    "                    bond_density_gradient_step = bond_density_gradient_step + (adjusted_bond_max_separation / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    bond_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        bond_density_gradient_eval_set = np.append(bond_density_gradient_eval_set, R_inner + j * bond_density_gradient_step)\n",
    "                        j += 1\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    j = 0\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, bond_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        bond_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(bond_gradient_changes)))\n",
    "                    gradient_min_separation = bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(bond_maximum_separation - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(bond_maximum_separation - next_max_pos)]) < R_inner):\n",
    "                        BCPs = np.append(BCPs, gradient_min_separation)\n",
    "                    possible_density_maxima = np.array([R_inner])\n",
    "                    possible_density_maxima = np.append(possible_density_maxima, BCPs)\n",
    "                    for j in np.arange(0, len(bond_separation_matrix[single_electron_wavefunctions[a+1] - 1])):\n",
    "                        if bond_separation_matrix[single_electron_wavefunctions[a+1] - 1][j] != 0:\n",
    "                            possible_density_maxima = np.append(possible_density_maxima, bond_separation_matrix[single_electron_wavefunctions[a+1] - 1][j] - R_inner)\n",
    "                        else:\n",
    "                            continue\n",
    "                ath_effective_density_limit = r_eff_max[a]\n",
    "                directional_effective_density_limit = sympy.symbols(\"x_eff\", real = True)\n",
    "                directional_max_expression = sympy.sqrt(3 *  directional_effective_density_limit**2) - r_eff_max[a]\n",
    "                directional_density_limit = np.abs(np.array(sympy.solvers.solve(directional_max_expression, directional_effective_density_limit)))\n",
    "                for j in np.arange(0, len(nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1])):\n",
    "                    if nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j] != 0:\n",
    "                        nucleus_a_inner_cutoffs = np.append(nucleus_a_inner_cutoffs, nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j] - R_inner)\n",
    "                        corrected_nuclear_separations = np.append(corrected_nuclear_separations, nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j])\n",
    "                while sample_count < n_random_samples:\n",
    "                    random_x = np.random.uniform(-directional_density_limit[0], directional_density_limit[0])\n",
    "                    random_y = np.random.uniform(-directional_density_limit[0], directional_density_limit[0])\n",
    "                    random_z = np.random.uniform(-directional_density_limit[0], directional_density_limit[0])\n",
    "                    for j in np.arange(0, len(nucleus_a_inner_cutoffs)):\n",
    "                        if nucleus_a_inner_cutoffs[j] < np.sqrt(random_x**2 + random_y**2 + random_z**2) < corrected_nuclear_separations[j]:\n",
    "                            inner_cutoff_flag = True\n",
    "                        else:\n",
    "                            inner_cutoff_flag = False\n",
    "                    if inner_cutoff_flag == True:\n",
    "                        continue\n",
    "                    elif np.sqrt(random_x**2 + random_y**2 + random_z**2) >= R_inner and np.sqrt(random_x**2 + random_y**2 + random_z**2) <= r_eff_max[a]:\n",
    "                        random_pos_samples = np.append(random_pos_samples, (random_x**2 + random_y**2 + random_z**2)**(1/2))  \n",
    "                        sample_count += 1\n",
    "                    else:\n",
    "                        continue\n",
    "                max_density_separations = np.array([])\n",
    "                for j in np.arange(0, len(random_pos_samples)):\n",
    "                    for k in np.arange(0, len(possible_density_maxima)):\n",
    "                        max_density_separations = np.append(max_density_separations, abs(random_pos_samples[j] - possible_density_maxima[k]))\n",
    "                max_density_separations = max_density_separations.reshape(len(random_pos_samples), len(possible_density_maxima))\n",
    "                for j in np.arange(0, len(max_density_separations)):\n",
    "                    point_pdf_score = np.append(point_pdf_score, min(max_density_separations[j]))\n",
    "                for j in np.arange(0, n_atoms):\n",
    "                    v_ext = ath_electron_density_surface * (-atomic_numbers[j] / abs(atomic_positions[j] - r))\n",
    "                    wavefunction_domain_volume= (4/3) * np.pi * ath_effective_density_limit**3\n",
    "                for k in np.arange(0, n_random_samples):\n",
    "                    BCP_bias = sympy.exp(BCP_bias_decay * point_pdf_score[k])\n",
    "                    PDF = BCP_bias / wavefunction_domain_volume\n",
    "                    KS_functional_sample = v_ext.replace(r, random_pos_samples[k])\n",
    "                    MC_estimate = MC_estimate + KS_functional_sample\n",
    "                MC_integral_approx = ((1 / PDF) / n_random_samples) + MC_estimate\n",
    "                print(MC_integral_approx)\n",
    "                a += 2\n",
    "        elif KS_functional_tracker == \"v_coul\" or KS_functional_tracker == \"v_xc\":\n",
    "            while a <= (2 * orbital_tracker) + 1:\n",
    "                a_max_density_separations = np.array([])\n",
    "                a_random_samples = np.array([])\n",
    "                a_known_rings = np.array([])\n",
    "                a_known_cages = np.array([])\n",
    "                a_point_pdf_score = np.array([])\n",
    "                nucleus_a_inner_cutoffs = np.array([])\n",
    "                bond_a_corrected_nuclear_separations = np.array([])\n",
    "                for j in np.arange(0, len(aromatic_rings)):\n",
    "                    if single_electron_wavefunctions[a+1] in aromatic_rings[j]:\n",
    "                        nucleus_on_ring = True\n",
    "                        electron_i_aromatic_ring = j\n",
    "                        a_known_rings = np.append(a_known_rings, j)\n",
    "                    else:\n",
    "                        nucleus_on_ring = False\n",
    "                for k in np.arange(0, len(aromatic_cages)):\n",
    "                    if single_electron_wavefunctions[a+1] in aromatic_cages[j]:\n",
    "                        nucleus_on_cage = True\n",
    "                        electron_i_cage_surface = j\n",
    "                        a_known_cages = np.append(a_known_cages, j)\n",
    "                    else:\n",
    "                        nucleus_on_cage = False\n",
    "                if nucleus_on_ring == True:\n",
    "                    a_RCPs = np.array([])\n",
    "                    a_ring_gradient_changes = []\n",
    "                    a_ring_atom_separations = np.array([])\n",
    "                    ring_density_gradient_step = 0\n",
    "                    nuclei_on_a_ring = aromicatic_rings[electron_i_aromatic_ring]\n",
    "                    for k in np.arange(0, len(nuclei_on_a_ring)):\n",
    "                        a_ring_atom_separations = np.append(a_ring_atom_separations, np.sqrt((pos_matrix[nuclei_on_a_ring[k]][0] - pos_matrix[single_electron_wavefunctions[a+1] - 1][0])**2 + (pos_matrix[nuclei_on_a_ring[k]][1] - pos_matrix[single_electron_wavefunctions[a+1] - 1][1])**2 + (pos_matrix[nuclei_on_a_ring[k]][2] - pos_matrix[single_electron_wavefunctions[a+1] - 1][2])**2))\n",
    "                    adjusted_max_a_ring_pos = max(a_ring_atom_separations) - 2*R_inner\n",
    "                    ring_density_gradient_step = ring_density_gradient_step + (adjusted_max_a_ring_pos / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    a_ring_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        a_ring_density_gradient_eval_set = np.append(a_ring_density_gradient_eval_set, R_inner + j * ring_density_gradient_step)\n",
    "                        j += 1\n",
    "                    j = 0\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, a_ring_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        a_ring_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(a_ring_gradient_changes)))\n",
    "                    gradient_min_separation = a_ring_density_gradient_eval_set[a_ring_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, a_ring_density_gradient_eval_set[a_ring_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, a_ring_density_gradient_eval_set[a_ring_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, a_ring_density_gradient_eval_set[a_ring_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                        a_RCPs = np.append(a_RCPs, gradient_min_separation)\n",
    "                elif nucleus_on_cage == True:\n",
    "                     a_CCPs = np.array([])\n",
    "                    a_cage_gradient_changes = []\n",
    "                    a_cage_atom_separations = np.array([])\n",
    "                    cage_density_gradient_step = 0\n",
    "                    nuclei_on_a_cage = aromicatic_cages[electron_i_aromatic_cage]\n",
    "                    for k in np.arange(0, len(nuclei_on_a_cage)):\n",
    "                        a_cage_atom_separations = np.append(a_cage_atom_separations, np.sqrt((pos_matrix[nuclei_on_a_cage[k]][0] - pos_matrix[single_electron_wavefunctions[a+1] - 1][0])**2 + (pos_matrix[nuclei_on_a_cage[k]][1] - pos_matrix[single_electron_wavefunctions[a+1] - 1][1])**2 + (pos_matrix[nuclei_on_a_cage[k]][2] - pos_matrix[single_electron_wavefunctions[a+1] - 1][2])**2))\n",
    "                    adjusted_max_a_cage_pos = max(a_cage_atom_separations) - 2*R_inner\n",
    "                    cage_density_gradient_step = cage_density_gradient_step + (adjusted_max_a_cage_pos / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    a_cage_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        a_cage_density_gradient_eval_set = np.append(a_cage_density_gradient_eval_set, R_inner + j * cage_density_gradient_step)\n",
    "                        j += 1\n",
    "                    j = 0\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, a_cage_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        a_cage_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(a_cage_gradient_changes)))\n",
    "                    gradient_min_separation = a_cage_density_gradient_eval_set[a_cage_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, a_cage_density_gradient_eval_set[a_cage_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, a_cage_density_gradient_eval_set[a_cage_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, a_cage_density_gradient_eval_set[a_cage_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                        a_CCPs = np.append(a_CCPs, gradient_min_separation)\n",
    "                else:\n",
    "                    a_BCPs = np.array([])\n",
    "                    a_bond_gradient_changes = []\n",
    "                    a_bond_density_gradient_step = 0\n",
    "                    a_bond_maximum_separation = max(bond_separation_matrix[single_electron_wavefunctions[a+1] - 1]) \n",
    "                    adjusted_a_bond_max_separation = a_bond_maximum_separation - 2*R_inner\n",
    "                    bond_density_gradient_step = bond_density_gradient_step + (adjusted_a_bond_max_separation / gradient_eval_samples)\n",
    "                    j = 0\n",
    "                    a_bond_density_gradient_eval_set = np.array([R_inner])\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        a_bond_density_gradient_eval_set = np.append(a_bond_density_gradient_eval_set, R_inner + j * bond_density_gradient_step)\n",
    "                        j += 1\n",
    "                    ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                    ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                    j = 0\n",
    "                    while j <= gradient_eval_samples:\n",
    "                        current_gradient_sample = ath_electron_density_gradient.replace(r, a_bond_density_gradient_eval_set[j])\n",
    "                        current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                        a_bond_gradient_changes.append(current_gradient_change)\n",
    "                        prev_gradient_sample = current_gradient_sample\n",
    "                        j += 1\n",
    "                    gradient_min = min(np.abs(np.array(a_bond_gradient_changes)))\n",
    "                    gradient_min_separation = a_bond_density_gradient_eval_set[a_bond_gradient_changes.index(gradient_min)]\n",
    "                    preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                    next_density_vals = [ath_electron_density_surface.replace(r, a_bond_density_gradient_eval_set[a_bond_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, a_bond_density_gradient_eval_set[a_bond_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, a_bond_density_gradient_eval_set[a_bond_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                    preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                    next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                    preceeding_max = max(preceeding_density_vals)\n",
    "                    next_max = max(next_density_vals)\n",
    "                    preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                    next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                    if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(bond_maximum_separation - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(bond_maximum_separation - next_max_pos)]) < R_inner):\n",
    "                        a_BCPs = np.append(a_BCPs, gradient_min_separation)\n",
    "                if len(a_RCPs) > 0:\n",
    "                    a_possible_density_maxima = np.array([R_inner])\n",
    "                    a_possible_density_maxima = np.append(possible_density_maxima, a_RCPs)\n",
    "                    for j in np.arange(0, len(a_ring_atom_separations)):\n",
    "                        a_possible_density_maxima = np.append(a_possible_density_maxima, a_ring_atom_separations[j] - R_inner)\n",
    "                    least_separation_from_a_density_max = min(a_possible_density_maxima)\n",
    "                elif len(a_CCPs) > 0:\n",
    "                    a_possible_density_maxima = np.array([R_inner])\n",
    "                    a_possible_density_maxima = np.append(a_possible_density_maxima, a_CCPs)\n",
    "                    for j in np.arange(0, len(a_cage_atom_separations)):\n",
    "                        a_possible_density_maxima = np.append(a_possible_density_maxima, a_cage_atom_separations[j] - R_inner)\n",
    "                    least_separation_from_a_density_max = min(a_possible_density_maxima)\n",
    "                else:\n",
    "                    a_possible_density_maxima = np.array([R_inner])\n",
    "                    a_possible_density_maxima = np.append(a_possible_density_maxima, a_BCPs)\n",
    "                    for j in np.arange(0, len(bond_separation_matrix[single_electron_wavefunctions[a+1] - 1])):\n",
    "                        if bond_separation_matrix[single_electron_wavefunctions[a+1] - 1][j] != 0:\n",
    "                            a_possible_density_maxima = np.append(a_possible_density_maxima, bond_separation_matrix[single_electron_wavefunctions[a+1] - 1][j] - R_inner)\n",
    "                        else:\n",
    "                            continue  \n",
    "                ath_effective_density_limit = r_eff_max[a]\n",
    "                ath_directional_effective_density_limit = sympy.symbols(\"x_eff_a\", real = True)\n",
    "                ath_directional_max_expression = sympy.sqrt(3 *  ath_directional_effective_density_limit**2) - r_eff_max[a]\n",
    "                ath_directional_density_limit = np.abs(np.array(sympy.solvers.solve(ath_directional_max_expression, ath_directional_effective_density_limit)))\n",
    "                for j in np.arange(0, len(nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1])):\n",
    "                    if nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j] != 0:\n",
    "                        nucleus_a_inner_cutoffs = np.append(nucleus_a_inner_cutoffs, nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j] - R_inner)\n",
    "                        bond_a_corrected_nuclear_separations = np.append(bond_a_corrected_nuclear_separations, nuclear_separation_matrix[single_electron_wavefunctions[a+1]-1][j])\n",
    "                b = 0\n",
    "                while b < len(n_bonding_electrons):\n",
    "                    if b != a:\n",
    "                        b_max_density_separations = np.array([])\n",
    "                        b_random_samples = np.array([])\n",
    "                        b_point_pdf_score = np.array([])\n",
    "                        nucleus_b_inner_cutoffs = np.array([])\n",
    "                        bond_b_corrected_nuclear_separations = np.array([])\n",
    "                        for j in np.arange(0, len(aromatic_rings)):\n",
    "                            if single_electron_wavefunctions[2*b+1] in aromatic_rings[j]:\n",
    "                                nucleus_on_ring = True\n",
    "                                electron_i_aromatic_ring = j\n",
    "                                known_rings = np.append(known_rings, j)\n",
    "                            else:\n",
    "                                nucleus_on_ring = False\n",
    "                        for k in np.arange(0, len(aromatic_cages)):\n",
    "                            if single_electron_wavefunctions[a+1] in aromatic_cages[j]:\n",
    "                                nucleus_on_cage = True\n",
    "                                electron_i_cage_surface = j\n",
    "                                known_cages = np.append(known_cages, j)\n",
    "                            else:\n",
    "                                nucleus_on_cage = False\n",
    "                        if nucleus_on_ring == True:\n",
    "                            if known_rings[0] == a_known_rings[0]:\n",
    "                                b_RCPs = a_RCPs\n",
    "                            else:\n",
    "                                b_RCPs = np.array([])\n",
    "                                b_ring_gradient_changes = []\n",
    "                                b_ring_atom_separations = np.array([])\n",
    "                                ring_density_gradient_step = 0\n",
    "                                nuclei_on_b_ring = aromicatic_rings[electron_i_aromatic_ring]\n",
    "                                for k in np.arange(0, len(nuclei_on_b_ring)):\n",
    "                                    b_ring_atom_separations = np.append(b_ring_atom_separations, np.sqrt((pos_matrix[nuclei_on_b_ing[k]][0] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][0])**2 + (pos_matrix[nuclei_on_b_ring[k]][1] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][1])**2 + (pos_matrix[nuclei_on_b_ring[k]][2] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][2])**2))\n",
    "                                adjusted_max_b_ring_pos = max(b_ring_atom_separations) - 2*R_inner\n",
    "                                ring_density_gradient_step = ring_density_gradient_step + (adjusted_max_b_ring_pos / gradient_eval_samples)\n",
    "                                j = 0\n",
    "                                b_ring_density_gradient_eval_set = np.array([R_inner])\n",
    "                                while j <= gradient_eval_samples:\n",
    "                                    ring_density_gradient_eval_set = np.append(ring_density_gradient_eval_set, R_inner + j * ring_density_gradient_step)\n",
    "                                    j += 1\n",
    "                                j = 0\n",
    "                                bth_electron_density_surface = single_electron_wavefunctions[2*b]**2\n",
    "                                bth_electron_density_gradient = sympy.diff(bth_electron_density_surface, r)\n",
    "                                while j <= gradient_eval_samples:\n",
    "                                    current_gradient_sample = bth_electron_density_gradient.replace(r, ring_density_gradient_eval_set[j])\n",
    "                                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                                    b_ring_gradient_changes.append(current_gradient_change)\n",
    "                                    prev_gradient_sample = current_gradient_sample\n",
    "                                    j += 1\n",
    "                                gradient_min = min(np.abs(np.array(b_ringring_gradient_changes)))\n",
    "                                gradient_min_separation = b_ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)]\n",
    "                                preceeding_density_vals = [bth_electron_density_surface.replace(r, gradient_min_separation - 0.01), bth_electron_density_surface.replace(r, gradient_min_separation - 0.02), bth_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                                next_density_vals = [bth_electron_density_surface.replace(r, b_ring_density_gradient_eval_set[b_ring_gradient_changes.index(gradient_min)] + 0.01), bth_electron_density_surface.replace(r, b_ring_density_gradient_eval_set[b_ring_gradient_changes.index(gradient_min)] + 0.02), bth_electron_density_surface.replace(r, b_ring_density_gradient_eval_set[b_ring_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                                preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                                preceeding_max = max(preceeding_density_vals)\n",
    "                                next_max = max(next_density_vals)\n",
    "                                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                                if (bth_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(b_ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (bth_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(b_ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                                    b_RCPs = np.append(b_RCPs, gradient_min_separation)\n",
    "                        elif nucleus_on_cage == True:\n",
    "                            if known_cages[0] == a_known_cages[0]:\n",
    "                                b_CCPs = a_CCPs\n",
    "                            else:\n",
    "                                b_CCPs = np.array([])\n",
    "                                b_cage_gradient_changes = []\n",
    "                                b_cage_atom_separations = np.array([])\n",
    "                                cage_density_gradient_step = 0\n",
    "                                nuclei_on_b_cage = aromicatic_rings[electron_i_aromatic_cage]\n",
    "                                for k in np.arange(0, len(nuclei_on_b_cage)):\n",
    "                                    b_cage_atom_separations = np.append(b_cage_atom_separations, np.sqrt((pos_matrix[nuclei_on_b_cage[k]][0] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][0])**2 + (pos_matrix[nuclei_on_b_cage[k]][1] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][1])**2 + (pos_matrix[nuclei_on_b_cage[k]][2] - pos_matrix[single_electron_wavefunctions[2*b+1] - 1][2])**2))\n",
    "                                adjusted_max_b_cage_pos = max(b_cage_atom_separations) - 2*R_inner\n",
    "                                cage_density_gradient_step = cage_density_gradient_step + (adjusted_max_b_cage_pos / gradient_eval_samples)\n",
    "                                j = 0\n",
    "                                b_cage_density_gradient_eval_set = np.array([R_inner])\n",
    "                                while j <= gradient_eval_samples:\n",
    "                                    cage_density_gradient_eval_set = np.append(cage_density_gradient_eval_set, R_inner + j * cage_density_gradient_step)\n",
    "                                    j += 1\n",
    "                                j = 0\n",
    "                                bth_electron_density_surface = single_electron_wavefunctions[2*b]**2\n",
    "                                bth_electron_density_gradient = sympy.diff(bth_electron_density_surface, r)\n",
    "                                while j <= gradient_eval_samples:\n",
    "                                    current_gradient_sample = bth_electron_density_gradient.replace(r, cage_density_gradient_eval_set[j])\n",
    "                                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                                    b_cage_gradient_changes.append(current_gradient_change)\n",
    "                                    prev_gradient_sample = current_gradient_sample\n",
    "                                    j += 1\n",
    "                                gradient_min = min(np.abs(np.array(b_cage_gradient_changes)))\n",
    "                                gradient_min_separation = b_cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)]\n",
    "                                preceeding_density_vals = [bth_electron_density_surface.replace(r, gradient_min_separation - 0.01), bth_electron_density_surface.replace(r, gradient_min_separation - 0.02), bth_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                                next_density_vals = [bth_electron_density_surface.replace(r, b_cage_density_gradient_eval_set[b_cage_gradient_changes.index(gradient_min)] + 0.01), bth_electron_density_surface.replace(r, b_cage_density_gradient_eval_set[b_cage_gradient_changes.index(gradient_min)] + 0.02), bth_electron_density_surface.replace(r, b_cage_density_gradient_eval_set[b_cage_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                                preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                                preceeding_max = max(preceeding_density_vals)\n",
    "                                next_max = max(next_density_vals)\n",
    "                                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                                if (bth_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(b_cage_atom_separations) - preceeding_max_pos)]) < R_inner) and (bth_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(b_cage_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                                    b_CCPs = np.append(b_CCPs, gradient_min_separation)\n",
    "                        else:\n",
    "                            b_BCPs = np.array([])\n",
    "                            b_bond_gradient_changes = []\n",
    "                            b_bond_density_gradient_step = 0\n",
    "                            b_bond_maximum_separation = max(bond_separation_matrix[single_electron_wavefunctions[2*b+1] - 1]) \n",
    "                            adjusted_b_bond_max_separation = b_bond_maximum_separation - 2*R_inner\n",
    "                            bond_density_gradient_step = bond_density_gradient_step + (adjusted_b_bond_max_separation / gradient_eval_samples)\n",
    "                            j = 0\n",
    "                            b_bond_density_gradient_eval_set = np.array([R_inner])\n",
    "                            while j <= gradient_eval_samples:\n",
    "                                b_bond_density_gradient_eval_set = np.append(b_bond_density_gradient_eval_set, R_inner + j * bond_density_gradient_step)\n",
    "                                j += 1\n",
    "                            bth_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                            bth_electron_density_gradient = sympy.diff(bth_electron_density_surface, r)\n",
    "                            j = 0\n",
    "                            while j <= gradient_eval_samples:\n",
    "                                current_gradient_sample = bth_electron_density_gradient.replace(r, abbond_density_gradient_eval_set[j])\n",
    "                                current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                                b_bond_gradient_changes.append(current_gradient_change)\n",
    "                                prev_gradient_sample = current_gradient_sample\n",
    "                                j += 1\n",
    "                            gradient_min = min(np.abs(np.array(b_bond_gradient_changes)))\n",
    "                            gradient_min_separation = b_bond_density_gradient_eval_set[b_bond_gradient_changes.index(gradient_min)]\n",
    "                            preceeding_density_vals = [bth_electron_density_surface.replace(r, gradient_min_separation - 0.01), bth_electron_density_surface.replace(r, gradient_min_separation - 0.02), bth_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                            next_density_vals = [bth_electron_density_surface.replace(r, b_bond_density_gradient_eval_set[b_bond_gradient_changes.index(gradient_min)] + 0.01), bth_electron_density_surface.replace(r, b_bond_density_gradient_eval_set[b_bond_gradient_changes.index(gradient_min)] + 0.02), bth_electron_density_surface.replace(r, b_bond_density_gradient_eval_set[b_bond_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                            preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                            next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                            preceeding_max = max(preceeding_density_vals)\n",
    "                            next_max = max(next_density_vals)\n",
    "                            preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                            next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                            if (bth_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(b_bond_maximum_separation - preceeding_max_pos)]) < R_inner) and (bth_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(b_bond_maximum_separation - next_max_pos)]) < R_inner):\n",
    "                                b_BCPs = np.append(a_BCPs, gradient_min_separation)\n",
    "                        if len(b_RCPs) > 0:\n",
    "                            b_possible_density_maxima = np.array([R_inner])\n",
    "                            b_possible_density_maxima = np.append(b_possible_density_maxima, b_RCPs)\n",
    "                            for j in np.arange(0, len(b_ring_atom_separations)):\n",
    "                                b_possible_density_maxima = np.append(b_possible_density_maxima, b_ring_atom_separations[j] - R_inner)\n",
    "                            least_separation_from_b_density_max = min(b_possible_density_maxima)\n",
    "                        elif len(b_CCPs) > 0:\n",
    "                            b_possible_density_maxima = np.array([R_inner])\n",
    "                            b_possible_density_maxima = np.append(b_possible_density_maxima, b_CCPs)\n",
    "                            for j in np.arange(0, len(b_cage_atom_separations)):\n",
    "                                b_possible_density_maxima = np.append(b_possible_density_maxima, b_cage_atom_separations[j] - R_inner)\n",
    "                            least_separation_from_b_density_max = min(b_possible_density_maxima)\n",
    "                        else:\n",
    "                            b_possible_density_maxima = np.array([R_inner])\n",
    "                            b_possible_density_maxima = np.append(b_possible_density_maxima, b_BCPs)\n",
    "                            for j in np.arange(0, len(bond_separation_matrix[single_electron_wavefunctions[2*b+1] - 1])):\n",
    "                                if bond_separation_matrix[single_electron_wavefunctions[2*b+1] - 1][j] != 0:\n",
    "                                    b_possible_density_maxima = np.append(b_possible_density_maxima, bond_separation_matrix[single_electron_wavefunctions[2*b+1] - 1][j] - R_inner)\n",
    "                                else:\n",
    "                                    continue \n",
    "                    bth_effective_density_limit = r_eff_max[b]\n",
    "                    bth_directional_effective_density_limit = sympy.symbols(\"x_eff_b\", real = True)\n",
    "                    bth_directional_max_expression = sympy.sqrt(3 *  bth_directional_effective_density_limit**2) - r_eff_max[b]\n",
    "                    bth_directional_density_limit = np.abs(np.array(sympy.solvers.solve(bth_directional_max_expression, bth_directional_effective_density_limit)))\n",
    "                    for j in np.arange(0, len(nuclear_separation_matrix[single_electron_wavefunctions[2*b+1]-1])):\n",
    "                        if nuclear_separation_matrix[single_electron_wavefunctions[2*b+1]-1][j] != 0:\n",
    "                            nucleus_b_inner_cutoffs = np.append(nucleus_b_inner_cutoffs, nuclear_separation_matrix[single_electron_wavefunctions[2*b+1]-1][j] - R_inner)\n",
    "                            bond_b_corrected_nuclear_separations = np.append(bond_b_corrected_nuclear_separations, nuclear_separation_matrix[single_electron_wavefunctions[2*b+1]-1][j])\n",
    "                    if domain_overlap_matrix[a][b] == 0:\n",
    "                        while sample_count < n_random_samples:\n",
    "                            a_random_x = np.random.uniform(-ath_directional_density_limit[0], ath_directional_density_limit[0])\n",
    "                            a_random_y = np.random.uniform(-ath_directional_density_limit[0], ath_directional_density_limit[0])\n",
    "                            a_random_z = np.random.uniform(-ath_directional_density_limit[0], ath_directional_density_limit[0])\n",
    "                        for j in np.arange(0, len(nucleus_a_inner_cutoffs)):\n",
    "                            if nucleus_a_inner_cutoffs[j] < np.sqrt(a_random_x**2 + a_random_y**2 + a_random_z**2) < bond_a_corrected_nuclear_separations[j]:\n",
    "                                inner_cutoff_flag = True\n",
    "                        else:\n",
    "                                inner_cutoff_flag = False\n",
    "                        if inner_cutoff_flag == True:\n",
    "                            continue\n",
    "                        elif np.sqrt(a_random_x**2 + a_random_y**2 + a_random_z**2) >= R_inner and np.sqrt(a_random_x**2 + a_random_y**2 + a_random_z**2) <= r_eff_max[a]:\n",
    "                            a_random_samples = np.append(a_random_samples, (a_random_x**2 + a_random_y**2 + a_random_z**2)**(1/2))  \n",
    "                            sample_count += 1\n",
    "                        else:\n",
    "                            continue\n",
    "                        sample_count = 0\n",
    "                        while sample_count < n_random_samples:\n",
    "                            b_random_x = np.random.uniform(-bth_directional_density_limit[0], bth_directional_density_limit[0])\n",
    "                            b_random_y = np.random.uniform(-bth_directional_density_limit[0], bth_directional_density_limit[0])\n",
    "                            b_random_z = np.random.uniform(-bth_directional_density_limit[0], bth_directional_density_limit[0])\n",
    "                        for j in np.arange(0, len(nucleus_b_inner_cutoffs)):\n",
    "                            if nucleus_b_inner_cutoffs[j] < np.sqrt(b_random_x**2 + b_random_y**2 + b_random_z**2) < bond_b_corrected_nuclear_separations[j]:\n",
    "                            inner_cutoff_flag = True\n",
    "                        else:\n",
    "                            inner_cutoff_flag = False\n",
    "                        if inner_cutoff_flag == True:\n",
    "                            continue\n",
    "                        elif np.sqrt(b_random_x**2 + b_random_y**2 + b_random_z**2) >= R_inner and np.sqrt(b_random_x**2 + b_random_y**2 + b_random_z**2) <= r_eff_max[b]:\n",
    "                            b_random_samples = np.append(b_random_samples, (b_random_x**2 + b_random_y**2 + b_random_z**2)**(1/2))  \n",
    "                            sample_count += 1\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        if inner_overlap_matrix[a][b] != 0:\n",
    "                            ath_effective_density_limit = inner_overlap_matrix[a][b]\n",
    "                            bth_effective_density_limit = bond_separation_matrix[a][b] - inner_overlap_matrix.transpose()[a][b]\n",
    "                            ath_spherical_max_expression = sympy.sqrt(3 *  ath_directional_effective_density_limit**2) - r_eff_max[a]\n",
    "                            ath_spherical_density_limit = np.abs(np.array(sympy.solvers.solve(bth_directional_max_expression, bth_directional_effective_density_limit)))\n",
    "                            bth_spherical_max_expression = sympy.sqrt(3 *  bth_directional_effective_density_limit**2) - r_eff_max[b]\n",
    "                            ath_unoverlapped_effective_limit = ath_spherical_density_limit * (ath_effective_density_limit / ath_spherical_density_limit)\n",
    "                            bth_unoverlapped_effective_limit = bth_spherical_density_limit * (bth_effective_density_limit / bth_spherical_density_limit)\n",
    "                            overlap_dir = np.random.uniform(1, 3)\n",
    "                            sample_count = 0\n",
    "                            while sample_count < n_random_samples:\n",
    "                                if overlap_dir == 1:\n",
    "                                    a_random_x = np.random.uniform(-ath_spherical_density_limit[0], ath_unoverlapped_effective_limit)\n",
    "                                    a_random_y = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                    a_random_z = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                elif overlap_dir == 2:\n",
    "                                    a_random_x = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                    a_random_y = np.random.uniform(-ath_spherical_density_limit[0], ath_unoverlapped_effective_limit)\n",
    "                                    a_random_z = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                elif overlap_dir == 2:\n",
    "                                    a_random_x = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                    a_random_y = np.random.uniform(-ath_spherical_density_limit[0], ath_spherical_density_limit[0])\n",
    "                                    a_random_z = np.random.uniform(-ath_spherical_density_limit[0], ath_unoverlapped_effective_limit)\n",
    "                max_density_separations = np.array([])\n",
    "                for j in np.arange(0, len(random_pos_samples)):\n",
    "                    for k in np.arange(0, len(possible_density_maxima)):\n",
    "                        max_density_separations = np.append(max_density_separations, abs(random_pos_samples[j] - possible_density_maxima[k]))\n",
    "                max_density_separations = max_density_separations.reshape(len(random_pos_samples), len(possible_density_maxima))\n",
    "                for j in np.arange(0, len(max_density_separations)):\n",
    "                    point_pdf_score = np.append(point_pdf_score, min(max_density_separations[j]))\n",
    "                for j in np.arange(0, n_atoms):\n",
    "                    v_ext = ath_electron_density_surface * (-atomic_numbers[j] / abs(atomic_positions[j] - r))\n",
    "                    wavefunction_domain_volume= (4/3) * np.pi * ath_effective_density_limit**3\n",
    "                for k in np.arange(0, n_random_samples):\n",
    "                    BCP_bias = sympy.exp(BCP_bias_decay * point_pdf_score[k])\n",
    "                    PDF = BCP_bias / wavefunction_domain_volume\n",
    "                    KS_functional_sample = v_ext.replace(r, random_pos_samples[k])\n",
    "                    MC_estimate = MC_estimate + KS_functional_sample\n",
    "                MC_integral_approx = ((1 / PDF) / n_random_samples) + MC_estimate\n",
    "                print(MC_integral_approx)\n",
    "        return MC_integral_approx\n",
    "\n",
    "\n",
    "    def compute_system_energy_eigenval(self, C_i_C_n, E_xc, n_bonding_electrons, n_atoms, unit_charge, R_inner, delta_o_cut, maximum_density_bound, input_tensor, atomic_orbital_states, exponential_range, nuclear_separation_matrix, bond_separation_matrix, degree_vector, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, orbital_tracker, KS_functional_tracker, pos_matrix):\n",
    "        degree_vector = degree_vector.astype(int)\n",
    "        degree_vector = np.insert(degree_vector, 0, 0)\n",
    "        single_electron_wavefunctions, single_electron_wavefunc_eqns, r = self.construct_single_electron_wavefunctions(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el)\n",
    "        r_prime = sympy.symbols(\"r_prime\", real = True)\n",
    "        kinetic_energy_operator = 0\n",
    "        external_potential = 0\n",
    "        exchange_correlation_potential = sympy.symbols(\"v_e_xc\", real = True)\n",
    "        electronic_repulsion_potential = sympy.symbols(\"v_el\", real = True)\n",
    "        contraction_coeff = sympy.symbols(\"Ci\", real = True)\n",
    "        k_symb_expressions = np.array([])\n",
    "        atomic_numbers = input_tensor.transpose()[2]\n",
    "        atomic_positions = input_tensor.transpose()[0]\n",
    "        if n_bonding_electrons % 2 == 0:\n",
    "            i = 0\n",
    "            while i < n_bonding_electrons:\n",
    "                laplacian = (1/r**2) * (sympy.diff(single_electron_wavefunctions[2*i], r) * (r**2 * sympy.diff(single_electron_wavefunctions[2*i], r)))\n",
    "                ith_electron_density_surface = single_electron_wavefunctions[2*i]**2\n",
    "                K = sympy.integrals.integrate(ith_electron_density_surface * laplacian, (r, R_inner, max(bond_separation_matrix[single_electron_wavefunctions[2*i+1] - 1]) + delta_o_cut))\n",
    "                kinetic_energy_operator = kinetic_energy_operator + K\n",
    "                print(kinetic_energy_operator)\n",
    "                i += 1\n",
    "            KS_functional_tracker = \"v_ext\"\n",
    "            i = 0\n",
    "            while i < n_bonding_electrons:\n",
    "                orbital_tracker = i\n",
    "                ith_el_external_potential = self.MC_functional_integration_estimate(input_tensor, n_atoms, atomic_orbital_states, C_i_C_n, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, delta_o_cut, maximum_density_bound, nuclear_separation_matrix, bond_separation_matrix, atomic_positions, aromatic_rings, aromatic_cages, orbital_tracker, KS_functional_tracker)\n",
    "                external_potential = external_potential + ith_el_external_potential\n",
    "                print(external_potential)\n",
    "                i += 1\n",
    "            KS_functional_tracker = \"v_coul\"\n",
    "            i = 0\n",
    "            while i < n_bonding_electrons:\n",
    "                orbital_tracker = i\n",
    "                ith_el_external_potential = self.MC_functional_integration_estimate(input_tensor, n_atoms, atomic_orbital_states, C_i_C_n, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, delta_o_cut, maximum_density_bound, nuclear_separation_matrix, bond_separation_matrix, atomic_positions, aromatic_rings, aromatic_cages, orbital_tracker, KS_functional_tracker)\n",
    "                external_potential = external_potential + ith_el_external_potential\n",
    "                print(external_potential)\n",
    "                i += 1\n",
    "            \n",
    "        return kinetic_energy_operator, external_potential\n",
    "        \n",
    "                \n",
    "        i = 0\n",
    "        while i <= n_bonding_electrons:\n",
    "            j = i + 2\n",
    "            #while j <= n_bonding_electrons:\n",
    "                #v_coul_min_char_list = []\n",
    "                #v_coul_max_char_list = []\n",
    "                #v_coul_min_replacement_str = \"\"\n",
    "                #v_coul_max_replacement_str = \"\"\n",
    "                #jth_electron_density_surface = single_electron_wavefunctions[j].replace(r, r_prime)**2\n",
    "                #v_coul_electron_j = jth_electron_density_surface / abs(r - r_prime)\n",
    "                #electron_j_series_approx = sympy.series(v_coul_electron_j)\n",
    "                #v_coul_electron_j = sympy.integrals.integrate(electron_j_series_approx, r_prime)\n",
    "                #v_coul_j_str = str(v_coul_electron_j)\n",
    "                #k = 0\n",
    "                #for k in range(0, len(v_coul_j_str)):\n",
    "                    #v_coul_min_char_list.append(v_coul_j_str[k])\n",
    "                    #v_coul_max_char_list.append(v_coul_j_str[k])\n",
    "                    #k += 1\n",
    "               # k = 0\n",
    "                #for k in range(0, len(v_coul_min_char_list)):\n",
    "                    #if v_coul_min_char_list[k] == \"r_prime\":\n",
    "                        #v_coul_min_char_list[k] = str(R_inner)\n",
    "                    #elif v_coul_min_char_list[k] == \"O\":\n",
    "                        #v_coul_min_drop_index = k\n",
    "                    #else:\n",
    "                        #k += 1\n",
    "                #del v_coul_min_char_list[v_coul_min_drop_index - 2:]\n",
    "                #k = 0\n",
    "                #for k in range(0, len(v_coul_max_char_list)):\n",
    "                    #if v_coul_max_char_list[k] == \"r\":\n",
    "                        #v_coul_max_char_list[k] = str(maximum_density_bound)\n",
    "                    #elif v_coul_max_char_list[k] == \"O\":\n",
    "                        #v_coul_max_drop_index = k\n",
    "                    #else:\n",
    "                        #k += 1\n",
    "                #del v_coul_max_char_list[v_coul_max_drop_index - 2:]\n",
    "                #k = 0\n",
    "                #for k in range(0, len(v_coul_min_char_list)):\n",
    "                    #v_coul_min_replacement_str =  v_coul_min_replacement_str + v_coul_min_char_list[k]\n",
    "               # k = 0\n",
    "                #for k in range(0, len(v_coul_max_char_list)):\n",
    "                    #v_coul_max_replacement_str =  v_coul_max_replacement_str + v_coul_max_char_list[k]\n",
    "                    #v_coul_electron_j_max = sympy.parsing.sympy_parser.parse_expr(v_coul_max_replacement_str)\n",
    "                    #v_coul_electron_j_min = sympy.parsing.sympy_parser.parse_expr(v_coul_min_replacement_str)\n",
    "                    #v_coul_electron_j = v_coul_electron_j_max - v_coul_electron_j_min\n",
    "                    #j += 2\n",
    "            #i += 2\n",
    "\n",
    "\n",
    "            \n",
    "                    #v_ext_i_placeholder = sympy.symbols(\"v_ext_i\", real = True) \n",
    "                    #ith_el_external_potential = ith_el_external_potential + v_ext_i\n",
    "                    #ith_el_external_potential = ith_el_external_potential.replace(v_ext_i_placeholder, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dfb2331-74c9-4e6f-a2a9-50879391650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          2.49721845  3.10412629  5.4         1.9037857   2.70118493\n",
      "   4.7       ]\n",
      " [ 2.49721845  0.          4.06148987  7.68427615  4.25775763  3.11173585\n",
      "   2.78210352]\n",
      " [ 3.10412629  4.06148987  0.          4.63849113  4.32185146  5.76055553\n",
      "   6.83853786]\n",
      " [ 5.4         7.68427615  4.63849113  0.          4.6887525   7.5625657\n",
      "  10.1       ]\n",
      " [ 1.9037857   4.25775763  4.32185146  4.6887525   0.          2.93339394\n",
      "   5.92574046]\n",
      " [ 2.70118493  3.11173585  5.76055553  7.5625657   2.93339394  0.\n",
      "   3.36725407]\n",
      " [ 4.7         2.78210352  6.83853786 10.1         5.92574046  3.36725407\n",
      "   0.        ]] [[0.         2.49721845 0.         0.         0.         2.70118493\n",
      "  4.7       ]\n",
      " [2.49721845 0.         4.06148987 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         4.06148987 0.         4.63849113 0.         0.\n",
      "  6.83853786]\n",
      " [0.         0.         4.63849113 0.         4.6887525  0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         4.6887525  0.         2.93339394\n",
      "  5.92574046]\n",
      " [2.70118493 0.         0.         0.         2.93339394 0.\n",
      "  0.        ]\n",
      " [4.7        0.         6.83853786 0.         5.92574046 0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def compute_interatomic_separations(nuclear_coordinates, adj_matrix):\n",
    "    nuclear_positions = pd.read_csv(nuclear_coordinates)\n",
    "    pos_matrix = nuclear_positions.to_numpy()\n",
    "    interatomic_distances = np.zeros_like(adj_matrix)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in np.arange(0, len(pos_matrix)):\n",
    "        for j in np.arange(0, len(pos_matrix)):\n",
    "            if i == j:\n",
    "                i_j_internuclear_separation = 0\n",
    "                interatomic_distances[i][j] = i_j_internuclear_separation\n",
    "            else:\n",
    "                i_j_internuclear_separation = np.sqrt((pos_matrix[i][0] - pos_matrix[j][0])**2 + (pos_matrix[i][1] - pos_matrix[j][1])**2 + (pos_matrix[i][2] - pos_matrix[j][2])**2)\n",
    "                interatomic_distances[i][j] = i_j_internuclear_separation\n",
    "    return interatomic_distances\n",
    "\n",
    "def compute_bond_separations(nuclear_coordinates, degree_vector, adj_matrix):\n",
    "    nuclear_positions = pd.read_csv(nuclear_coordinates)\n",
    "    pos_matrix = nuclear_positions.to_numpy()\n",
    "    bond_sep_matrix = np.zeros_like(adj_matrix)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in np.arange(0, len(pos_matrix)):\n",
    "        if degree_vector[i] > 0:\n",
    "            for j in np.arange(0, len(adj_matrix[i])):\n",
    "                if adj_matrix[i][j] == 1:\n",
    "                    i_j_internuclear_separation = np.sqrt((pos_matrix[j][0] - pos_matrix[i][0])**2 + (pos_matrix[j][1] - pos_matrix[i][1])**2 + (pos_matrix[j][2] - pos_matrix[i][2])**2)\n",
    "                    bond_sep_matrix[i][j] = i_j_internuclear_separation\n",
    "                j += 1\n",
    "        i += 1\n",
    "    bond_sep_list = list(bond_sep_matrix.flatten())\n",
    "    for k in bond_sep_list:\n",
    "        if abs(k) == 0:\n",
    "            bond_sep_list.pop(bond_sep_list.index(k))\n",
    "    bond_sep_set = np.array(bond_sep_list)\n",
    "    return bond_sep_matrix, pos_matrix, bond_sep_set\n",
    "                    \n",
    "degree_vector = compute_node_connection_degrees(adj_matrix, n_atoms)\n",
    "nuclear_coordinates = \"/users/haydenprescott/documents/nuclear_pos_test.csv\"\n",
    "bond_separation_matrix, pos_matrix, bond_separation_set = compute_bond_separations(nuclear_coordinates, degree_vector, adj_matrix)\n",
    "nuclear_separation_matrix = compute_interatomic_separations(nuclear_coordinates, adj_matrix)\n",
    "print(nuclear_separation_matrix, bond_separation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bb578b-220e-4dab-aef3-d73161a2c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          2.49721845  3.10412629  5.4         1.9037857   2.70118493\n",
      "   4.7       ]\n",
      " [ 2.49721845  0.          4.06148987  7.68427615  4.25775763  3.11173585\n",
      "   2.78210352]\n",
      " [ 3.10412629  4.06148987  0.          4.63849113  4.32185146  5.76055553\n",
      "   6.83853786]\n",
      " [ 5.4         7.68427615  4.63849113  0.          4.6887525   7.5625657\n",
      "  10.1       ]\n",
      " [ 1.9037857   4.25775763  4.32185146  4.6887525   0.          2.93339394\n",
      "   5.92574046]\n",
      " [ 2.70118493  3.11173585  5.76055553  7.5625657   2.93339394  0.\n",
      "   3.36725407]\n",
      " [ 4.7         2.78210352  6.83853786 10.1         5.92574046  3.36725407\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(nuclear_separation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb01d70-b72d-48a0-acea-b9abcb95a01b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1858509338.py, line 422)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 422\u001b[0;36m\u001b[0m\n\u001b[0;31m    for j in range(0, n_atoms):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    def construct_grad_descent_schedule(self, LR_o, t, K, gradient_descent_schedule):\n",
    "        # implement RMS normalization for stochastic gradient descent - calculate gradients as cumulative moving average of sqaures, normalize by square root of mean-square gradient, and update weights in direction of gloabl min in accordance with sign of previous gradient with respect to the previous weight \n",
    "        # paper link: https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a\n",
    "        if gradient_descent_schedule == \"MBGD\":\n",
    "            LR = LR_o * np.exp(-K * t)\n",
    "        return LR\n",
    "   \n",
    "    def construct_single_electron_wavefunctions(self, input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el):\n",
    "        s_MO_set = sympy.Array([])\n",
    "        p_MO_set = sympy.Array([])\n",
    "        d_MO_set = sympy.Array([])\n",
    "        f_MO_set = sympy.Array([])\n",
    "        s_ref_set = sympy.Array([])\n",
    "        p_ref_set = sympy.Array([])\n",
    "        d_ref_set = sympy.Array([])\n",
    "        f_ref_set = sympy.Array([])\n",
    "        s_exp_set = sympy.Array([])\n",
    "        p_exp_set = sympy.Array([])\n",
    "        d_exp_set = sympy.Array([])\n",
    "        f_exp_set = sympy.Array([])\n",
    "        exp_set = sympy.Array([])\n",
    "        one_electron_MOs = np.array([])\n",
    "        gaussian_terms = []\n",
    "        coefficient_sequence = []\n",
    "        exp_set = []\n",
    "        r = sympy.symbols(\"r\", real = True)\n",
    "        j = sympy.symbols(\"j\", real = True)\n",
    "        s_exponentials = 1\n",
    "        p_exponentials = atomic_orbital_states[\"p\"][1] - atomic_orbital_states[\"s\"]\n",
    "        d_exponentials = atomic_orbital_states[\"d\"][1] - atomic_orbital_states[\"p\"][1]\n",
    "        f_exponentials = atomic_orbital_states[\"f\"][0]\n",
    "        i = 0\n",
    "        for i in range(0, n_atoms):\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials - 1:\n",
    "                exp_start = exponential_range[s_exponentials - 1]\n",
    "                s_coefficient_range = C_i_C_n[i][0:maximum_s_el * s_exponentials]\n",
    "                j = 0\n",
    "                for j in range(0, len(s_coefficient_range)):\n",
    "                    current_contraction_coeff = s_coefficient_range[j]\n",
    "                    if current_contraction_coeff != 0:\n",
    "                        current_s_MO = current_contraction_coeff * sympy.exp(-input_tensor[i][exp_start] * r)\n",
    "                        s_MO_set = np.append(s_MO_set, np.array([current_s_MO, i + 1]))\n",
    "                        s_ref_set = np.append(s_ref_set, current_s_MO)\n",
    "                        s_exp_set = np.append(s_exp_set, sympy.exp(-input_tensor[i][exp_start] * r))\n",
    "                        gaussian_terms.append(current_s_MO)\n",
    "                        coefficient_sequence.append(current_contraction_coeff)\n",
    "                        j += s_exponentials\n",
    "            else:\n",
    "                pass\n",
    "            exp_range_vals = np.arange(exponential_range[0], exponential_range[1] + 1)\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el:\n",
    "                p_coefficient_range = C_i_C_n[i][maximum_s_el * s_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials]\n",
    "                j = 0\n",
    "                p_MO_contributions = 0\n",
    "                while j <= len(p_coefficient_range):\n",
    "                    current_contraction_coeffs = p_coefficient_range[j: j + p_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            p_exp_set = np.append(p_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"p\"][0]] * r))\n",
    "                            p_MO_contributions = p_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += p_exponentials\n",
    "                    if j <= len(p_coefficient_range):\n",
    "                        p_MO_set = np.append(p_MO_set, np.array([p_MO_contributions, i + 1]))  \n",
    "                        p_ref_set = np.append(p_ref_set, p_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el:\n",
    "                d_coefficient_range = C_i_C_n[i][maximum_s_el * s_exponentials + maximum_p_el * p_exponentials : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el + d_exponentials]\n",
    "                j = 0\n",
    "                d_MO_contributions = 0\n",
    "                while j <= len(d_coefficient_range):\n",
    "                    current_contraction_coeffs = d_coefficient_range[j: j + d_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            d_exp_set = np.append(d_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"d\"][0]] * r))\n",
    "                            d_MO_contributions = d_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += d_exponentials\n",
    "                    if j <= len(d_coefficient_range):\n",
    "                        d_MO_set = np.append(d_MO_set, np.array([d_MO_contributions, i + 1])) \n",
    "                        d_ref_set = np.append(d_ref_set, d_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            if len(C_i_C_n.transpose()) > s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el:\n",
    "                f_coefficient_range = C_i_C_n[i][s_exponentials * maximum_s_el + p_exponentials * maximum_p_el + d_exponentials * maximum_d_el : maximum_s_el * s_exponentials + maximum_p_el * p_exponentials + maximum_d_el * d_exponentials + maximum_f_el * f_exponentials]\n",
    "                j = 0\n",
    "                f_MO_contributions = 0\n",
    "                while j <= len(f_coefficient_range):\n",
    "                    current_contraction_coeffs = d_coefficient_range[j: j + f_exponentials] \n",
    "                    k = 0\n",
    "                    for k in range(0, len(current_contraction_coeffs)):\n",
    "                        if current_contraction_coeffs[k] != 0:\n",
    "                            current_gaussian_term = current_contraction_coeffs[k] * sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r)\n",
    "                            gaussian_terms.append(current_gaussian_term)\n",
    "                            coefficient_sequence.append([current_contraction_coeffs[k]])\n",
    "                            f_exp_set = np.append(f_exp_set, sympy.exp(-input_tensor[i][exp_range_vals][k + atomic_orbital_states[\"f\"][0]] * r))\n",
    "                            f_MO_contributions = f_MO_contributions + current_gaussian_term\n",
    "                            k += 1\n",
    "                    j += f_exponentials\n",
    "                    if j <= len(f_coefficient_range):\n",
    "                        f_MO_set = np.append(f_MO_set, np.array([f_MO_contributions, i])) \n",
    "                        f_ref_set = np.append(f_ref_set, f_MO_contributions)\n",
    "            else:\n",
    "                pass\n",
    "            i += 1\n",
    "        Ci = sympy.symbols(\"Ci\", real = True)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, s_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, p_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, d_MO_set)\n",
    "        one_electron_MOs = np.append(one_electron_MOs, f_MO_set)\n",
    "        exp_set = np.append(exp_set, s_exp_set)\n",
    "        exp_set = np.append(exp_set, p_exp_set)\n",
    "        exp_set = np.append(exp_set, d_exp_set)\n",
    "        exp_set = np.append(exp_set, f_exp_set)\n",
    "        one_electron_MO_eqns = np.array([])\n",
    "        k = 0\n",
    "        for k in range(0, len(s_ref_set) * s_exponentials):\n",
    "            current_s_MO_eqn = Ci * exp_set[k]\n",
    "            one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_s_MO_eqn)\n",
    "            k += 1\n",
    "        p_gaussian_start_index = (len(s_ref_set) * s_exponentials) - 1\n",
    "        p_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        p_gaussian_count = p_gaussian_end_index - p_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(p_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials * k + p_exponentials]\n",
    "            current_exponentials = exp_set[p_gaussian_start_index + p_exponentials * k : p_gaussian_start_index + p_exponentials* k + p_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        d_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials) - 1\n",
    "        d_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        d_gaussian_count = d_gaussian_end_index - d_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(d_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials * k + d_exponentials]\n",
    "            current_exponentials = exp_set[d_gaussian_start_index + d_exponentials * k : d_gaussian_start_index + d_exponentials* k + d_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "        f_gaussian_start_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials) - 1\n",
    "        f_gaussian_end_index = (len(s_ref_set) * s_exponentials + len(p_ref_set) * p_exponentials + len(d_ref_set) * d_exponentials + len(f_ref_set) * f_exponentials) - 1\n",
    "        f_gaussian_count = f_gaussian_end_index - f_gaussian_start_index\n",
    "        k = 0\n",
    "        for k in range(0, int(f_gaussian_count / 2)):\n",
    "            current_gaussian_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials])\n",
    "            current_ref_fxns = list(gaussian_terms[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials + 1])\n",
    "            current_contraction_coefficients = coefficient_sequence[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials * k + f_exponentials]\n",
    "            current_exponentials = exp_set[f_gaussian_start_index + f_exponentials * k : f_gaussian_start_index + f_exponentials* k + f_exponentials]\n",
    "            tracker = 1\n",
    "            prev_gaussian = 0\n",
    "            for tracker in range(1, len(current_ref_fxns)):\n",
    "                sample_gaussian = random.choice(current_gaussian_fxns)\n",
    "                if sample_gaussian != prev_gaussian:\n",
    "                    gaussian_index = current_gaussian_fxns.index(sample_gaussian)\n",
    "                    sample_gaussian_eqn = Ci * current_exponentials[gaussian_index]\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian_eqn\n",
    "                    current_gaussian_eqn = sum(current_gaussian_fxns)\n",
    "                    one_electron_MO_eqns = np.append(one_electron_MO_eqns, current_gaussian_eqn)\n",
    "                    current_ref_fxns.pop(gaussian_index)\n",
    "                    prev_gaussian = sample_gaussian\n",
    "                    current_gaussian_fxns[gaussian_index] = sample_gaussian\n",
    "                    tracker += 1\n",
    "                else:\n",
    "                    continue\n",
    "                k += 1\n",
    "                    \n",
    "        return one_electron_MOs, one_electron_MO_eqns, r\n",
    "\n",
    "    def compute_effective_density_cutoffs(self, input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, maximum_density_bound):\n",
    "        single_el_wavefunctions, single_el_wavefunction_eqs, r = self.construct_single_electron_wavefunctions(energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.n_atoms, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el)\n",
    "        normalized_dist_fxns = np.array([])\n",
    "        maximum_el_density_radii = np.array([])\n",
    "        i = 0\n",
    "        while i < len(single_el_wavefunctions):\n",
    "            norm_constant = sympy.symbols(\"A\", real = True)\n",
    "            normalized_wavefunc = norm_constant * single_el_wavefunctions[i]\n",
    "            total_probability_density = sympy.integrals.integrate(normalized_wavefunc, (r, R_inner, maximum_density_bound))\n",
    "            norm_constant = sympy.solve(total_probability_density - 1, norm_constant)\n",
    "            normalized_wavefunc = norm_constant[0] * single_el_wavefunctions[i]\n",
    "            normalized_dist_fxns = np.append(normalized_dist_fxns, normalized_wavefunc)\n",
    "            enclosed_probability_density = sympy.integrals.integrate(normalized_wavefunc, r)\n",
    "            inner_cutoff_single_electron_density = enclosed_probability_density.replace(r, R_inner)\n",
    "            ith_electron_density_range = ((enclosed_probability_density - inner_cutoff_single_electron_density) - 0.98)**2\n",
    "            ith_density_range_fxn = sympy.lambdify(r, ith_electron_density_range)\n",
    "            min_square_enclosed_density = scipy.optimize.minimize_scalar(ith_density_range_fxn)\n",
    "            ith_maximum_density_radius = min_square_enclosed_density.x\n",
    "            maximum_el_density_radii = np.append(maximum_el_density_radii, ith_maximum_density_radius)\n",
    "            maximum_el_density_radii = np.append(maximum_el_density_radii, single_el_wavefunctions[i + 1])\n",
    "            i += 2\n",
    "        return maximum_el_density_radii\n",
    "\n",
    "    \n",
    "    def MC_functional_integration_estimate(self, input_tensor, n_atoms, atomic_orbital_states, C_i_C_n, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, delta_o_cut, maximum_density_bound, nuclear_separation_matrix, atomic_positions, aromatic_rings, aromatic_cages):  \n",
    "        single_electron_wavefunctions, single_electron_eqns, r = self.construct_single_electron_wavefunctions(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el)\n",
    "        r_eff_max = self.compute_effective_density_cutoffs(input_tensor, atomic_orbital_states, C_i_C_n, n_atoms, exponential_range, maximum_s_el, maximum_p_el, maximum_d_el, maximum_f_el, R_inner, maximum_density_bound)\n",
    "        BCP_bias_decay = -0.1\n",
    "        # implement either straight-line distance of random var point on sphere from zero-gradient point of single-electron wavefunction, or staight-line distance from random R3 point from R3 line separating nuclei in bond\n",
    "        MC_estimate = 0\n",
    "        n_random_samples = 1000\n",
    "        gradient_eval_samples = 500 #for evaluation of electron density gradient at every pm of the internuclear/ring/cage max effective separation\n",
    "        sample_count = 0\n",
    "        prev_gradient_sample = 0\n",
    "        atomic_numbers = input_tensor.transpose()[2]\n",
    "        a = 0\n",
    "        while a < 1:\n",
    "            max_density_separations = np.array([])\n",
    "            random_pos_samples = np.array([])\n",
    "            known_rings = np.array([])\n",
    "            known_cages = np.array([])\n",
    "            point_pdf_score = np.array([])\n",
    "            for j in np.arange(0, len(aromatic_rings)):\n",
    "                if single_electron_wavefunctions[a+1] in aromatic_rings[j]:\n",
    "                    nucleus_on_ring = True\n",
    "                    electron_i_aromatic_ring = j\n",
    "                    known_rings = np.append(known_rings, j)\n",
    "                else:\n",
    "                    nucleus_on_ring = False\n",
    "            for k in np.arange(0, len(aromatic_cages)):\n",
    "                if single_electron_wavefunctions[a+1] in aromatic_cages[j]:\n",
    "                    nucleus_on_cage = True\n",
    "                    electron_i_cage_surface = j\n",
    "                    known_cages = np.append(known_cages, j)\n",
    "                else:\n",
    "                    nucleus_on_cage = False\n",
    "            if nucleus_on_ring == True:\n",
    "                RCPs = np.array([])\n",
    "                ring_gradient_changes = []\n",
    "                ring_atom_separations = np.array([])\n",
    "                ring_density_gradient_step = 0\n",
    "                for k in np.arange(0, len(aromicatic_rings[electron_i_aromatic_ring])):\n",
    "                    ring_atom_separations = np.append(ring_atom_separations, np.sqrt((pos_matrix[electron_i_aromatic_ring[j]][0] - pos_matrix[single_electron_wavefunctions[a+1]][0])**2 + (pos_matrix[electron_i_aromatic_ring[j]][1] - pos_matrix[single_electron_wavefunctions[a+1]][1])**2 + (pos_matrix[electron_i_aromatic_ring[j]][2] - pos_matrix[single_electron_wavefunctions[a+1]][2])**2))\n",
    "                adjusted_max_ring_pos = max(ring_atom_separations) - 2*R_inner\n",
    "                ring_density_gradient_step = ring_density_gradient_step + (adjusted_max_ring_pos / gradient_eval_samples)\n",
    "                j = 0\n",
    "                ring_density_gradient_eval_set = np.array([R_inner])\n",
    "                while j <= gradient_eval_samples:\n",
    "                    ring_density_gradient_eval_set = np.append(ring_density_gradient_eval_set, R_inner + j * ring_density_gradient_step)\n",
    "                    j += 1\n",
    "                j = 0\n",
    "                ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                while j <= gradient_eval_samples:\n",
    "                    current_gradient_sample = ath_electron_density_gradient.replace(r, ring_density_gradient_eval_set[j])\n",
    "                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                    ring_gradient_changes.append(current_gradient_change)\n",
    "                    prev_gradient_sample = current_gradient_sample\n",
    "                    j += 1\n",
    "                gradient_min = min(np.abs(np.array(bond_gradient_changes)))\n",
    "                gradient_min_separation = ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)]\n",
    "                preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                next_density_vals = [ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                preceeding_max = max(preceeding_density_vals)\n",
    "                next_max = max(next_density_vals)\n",
    "                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                    RCPs = np.append(RCPs, gradient_min_separation)\n",
    "                possible_density_maxima = np.array([R_inner])\n",
    "                possible_density_maxima = np.append(possible_density_maxima, RCPs)\n",
    "                for j in np.arange(0, len(ring_atom_separations)):\n",
    "                    possible_density_maxima = np.append(possible_density_maxima, ring_atom_separations[j] - R_inner)\n",
    "                least_separation_from_density_max = min(possible_density_maxima)\n",
    "            elif nucleus_on_cage == True:\n",
    "                CCPs = np.array([])\n",
    "                cage_gradient_changes = []\n",
    "                cage_atom_separations = np.array([])\n",
    "                cage_density_gradient_step = 0\n",
    "                for k in np.arange(0, len(aromicatic_cages[electron_i_cage_surface])):\n",
    "                    cage_atom_separations = np.append(cage_atom_separations, np.sqrt((pos_matrix[electron_i_cage_surface[j]][0] - pos_matrix[single_electron_wavefunctions[a+1]][0])**2 + (pos_matrix[electron_i_cage_surface[j]][1] - pos_matrix[single_electron_wavefunctions[a+1]][1])**2 + (pos_matrix[electron_i_cage_surface[j]][2] - pos_matrix[single_electron_wavefunctions[a+1]][2])**2))\n",
    "                adjusted_max_cage_pos = max(cage_atom_separations) - 2*R_inner\n",
    "                cage_density_gradient_step = cage_densiy_gradient_step + (adjusted_max_cage_pos / gradient_eval_samples)\n",
    "                j = 0\n",
    "                cage_density_gradient_eval_set = np.array([R_inner])\n",
    "                while j <= gradient_eval_samples:\n",
    "                    cage_density_gradient_eval_set = np.append(cage_density_gradient_eval_set, R_inner + j * cage_density_gradient_step)\n",
    "                    j += 1\n",
    "                ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    current_gradient_sample = ath_electron_density_gradient.replace(r, cage_density_gradient_eval_set[j])\n",
    "                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                    cage_gradient_changes.append(current_gradient_change)\n",
    "                    prev_gradient_sample = current_gradient_sample\n",
    "                    j += 1\n",
    "                gradient_min = min(np.abs(np.array(bond_gradient_changes)))\n",
    "                gradient_min_separation = cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)]\n",
    "                preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                next_density_vals = [ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                preceeding_max = max(preceeding_density_vals)\n",
    "                next_max = max(next_density_vals)\n",
    "                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(cage_atom_separations) - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(cage_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                    CCPs = np.append(CCPs, gradient_min_separation)\n",
    "                possible_density_maxima = np.array([R_inner])\n",
    "                possible_density_maxima = np.append(possible_density_maxima, CCPs)\n",
    "                for j in np.arange(0, len(cage_atom_separations)):\n",
    "                    possible_density_maxima = np.append(possible_density_maxima, cage_atom_separations[j] - R_inner)\n",
    "                least_separation_from_density_max = min(possible_density_maxima)\n",
    "            else:\n",
    "                BCPs = np.array([])\n",
    "                bond_gradient_changes = []\n",
    "                bond_density_gradient_step = 0\n",
    "                bond_maximum_separation = max(nuclear_separation_matrix[single_electron_wavefunctions[a+1] - 1])\n",
    "                adjusted_bond_max_separation = bond_maximum_separation - 2*R_inner\n",
    "                bond_density_gradient_step = bond_density_gradient_step + (adjusted_bond_max_separation / gradient_eval_samples)\n",
    "                j = 0\n",
    "                bond_density_gradient_eval_set = np.array([R_inner])\n",
    "                while j <= gradient_eval_samples:\n",
    "                    bond_density_gradient_eval_set = np.append(bond_density_gradient_eval_set, R_inner + j * bond_density_gradient_step)\n",
    "                    j += 1\n",
    "                ath_electron_density_surface = single_electron_wavefunctions[a]**2\n",
    "                ath_electron_density_gradient = sympy.diff(ath_electron_density_surface, r)\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    current_gradient_sample = ath_electron_density_gradient.replace(r, bond_density_gradient_eval_set[j])\n",
    "                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                    bond_gradient_changes.append(current_gradient_change)\n",
    "                    prev_gradient_sample = current_gradient_sample\n",
    "                    j += 1\n",
    "                gradient_min = min(np.abs(np.array(bond_gradient_changes)))\n",
    "                gradient_min_separation = bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)]\n",
    "                preceeding_density_vals = [ath_electron_density_surface.replace(r, gradient_min_separation - 0.01), ath_electron_density_surface.replace(r, gradient_min_separation - 0.02), ath_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                next_density_vals = [ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.01), ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.02), ath_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                preceeding_radial_pos = [gradient_min_separation - 0.01, gradient_min_separation - 0.02, gradient_min_separation - 0.03]\n",
    "                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                preceeding_max = max(preceeding_density_vals)\n",
    "                next_max = max(next_density_vals)\n",
    "                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                if (ath_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(bond_maximum_separation - preceeding_max_pos)]) < R_inner) and (ath_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(bond_maximum_separation - next_max_pos)]) < R_inner):\n",
    "                    BCPs = np.append(BCPs, gradient_min_separation)\n",
    "                possible_density_maxima = np.array([R_inner])\n",
    "                possible_density_maxima = np.append(possible_density_maxima, BCPs)\n",
    "                for j in np.arange(0, len(nuclear_separation_matrix[single_electron_wavefunctions[a+1]])):\n",
    "                    if nuclear_separation_matrix[single_electron_wavefunctions[a+1]][j] != 0:\n",
    "                        possible_density_maxima = np.append(possible_density_maxima, nuclear_separation_matrix[single_electron_wavefunctions[a+1]][j] - R_inner)\n",
    "                    else:\n",
    "                        continue\n",
    "                ath_effective_density_limit = r_eff_max[a]\n",
    "                print(ath_effective_density_limit)\n",
    "            while sample_count < n_random_samples:\n",
    "                random_x = uniform(R_inner, maximum_density_bound)\n",
    "                random_y = uniform(R_inner, maximum_density_bound)\n",
    "                random_z = uniform(R_inner, maximum_density_bound)\n",
    "                if np.sqrt((random_x - pos_matrix[(a+1)][0])**2 + (random_y - pos_matrix[(a+1)][1])**2 + (random_z - pos_matrix[(a+1)][2])**2) <= r_eff_max[a]:\n",
    "                    random_pos_samples = np.append(random_pos_samples, np.sqrt(random_x**2 + random_y**2 + random_z**2))\n",
    "                    sample_count += 1\n",
    "                else:\n",
    "                    continue\n",
    "            max_density_separations = np.array([])\n",
    "            for j in np.arange(0, len(random_pos_samples)):\n",
    "                for k in np.arange(0, len(possible_density_maxima)):\n",
    "                    max_density_separations = np.append(max_density_separations, abs(random_pos_samples[j] - possible_density_maxima[k]))\n",
    "            max_density_separations = max_density_separations.reshape(len(random_pos_samples), len(possible_density_maxima))\n",
    "            for j in np.arange(0, len(max_density_separations)):\n",
    "                point_pdf_score = np.append(point_pdf_score, min(max_density_separations[j]))\n",
    "            for j in np.arange(0, n_atoms):\n",
    "                v_ext = ath_electron_density_surface * (-atomic_numbers[j] / abs(atomic_positions[j] - r))\n",
    "                wavefunction_domain_volume= (4/3) * np.pi * ath_effective_density_limit**3\n",
    "            for k in np.arange(0, n_random_samples):\n",
    "                BCP_bias = sympy.exp(BCP_bias_decay * point_pdf_score[k])\n",
    "                PDF = BCP_bias / wavefunction_domain_volume\n",
    "                KS_functional_sample = v_ext.replace(r, random_pos_samples[k])\n",
    "                MC_estimate = MC_estimate + KS_functional_sample\n",
    "            MC_integral_approx = ((1 / PDF) / n_random_samples) + MC_estimate\n",
    "            a += 2\n",
    "        return MC_integral_approx\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "                for j in range(0, n_atoms):\n",
    "                    v_min_char_list = []\n",
    "                    v_max_char_list = []\n",
    "                    v_min_replacement_str = \"\"\n",
    "                    v_max_replacement_str = \"\"\n",
    "                    v_ext = ith_electron_density_surface * (-atomic_numbers[j] / abs(atomic_positions[j] - r))\n",
    "                    v_ext_approx = sympy.series(v_ext)\n",
    "                    v_ext_i = sympy.integrals.integrate(v_ext_approx, r)\n",
    "                    v_ext_i_str = str(v_ext_i)\n",
    "                    k = 0\n",
    "                    for k in range(0, len(v_ext_i_str)):\n",
    "                        v_min_char_list.append(v_ext_i_str[k])\n",
    "                        v_max_char_list.append(v_ext_i_str[k])\n",
    "                        k += 1\n",
    "                    k = 0\n",
    "                    for k in range(0, len(v_min_char_list)):\n",
    "                        if v_min_char_list[k] == \"r\":\n",
    "                            v_min_char_list[k] = str(R_inner)\n",
    "                        elif v_min_char_list[k] == \"O\":\n",
    "                            v_min_drop_index = k\n",
    "                        else:\n",
    "                            k += 1\n",
    "                    del v_min_char_list[v_min_drop_index - 2:]\n",
    "                    k = 0\n",
    "                    for k in range(0, len(v_max_char_list)):\n",
    "                        if v_max_char_list[k] == \"r\":\n",
    "                            v_max_char_list[k] = str(max(nuclear_separation_matrix[single_electron_wavefunctions[i+1]]) + delta_o_cut)\n",
    "                        elif v_max_char_list[k] == \"O\":\n",
    "                            v_max_drop_index = k\n",
    "                        else:\n",
    "                            k += 1\n",
    "                    del v_max_char_list[v_max_drop_index - 2:]\n",
    "                    k = 0\n",
    "                    for k in range(0, len(v_min_char_list)):\n",
    "                        v_min_replacement_str =  v_min_replacement_str + v_min_char_list[k]\n",
    "                    k = 0\n",
    "                    for k in range(0, len(v_max_char_list)):\n",
    "                        v_max_replacement_str =  v_max_replacement_str + v_max_char_list[k]\n",
    "                    v_ext_i_max = sympy.parsing.sympy_parser.parse_expr(v_max_replacement_str)\n",
    "                    v_ext_i_min = sympy.parsing.sympy_parser.parse_expr(v_min_replacement_str)\n",
    "                    v_ext_i = v_ext_i_max - v_ext_i_min\n",
    "                    v_ext_i_placeholder = sympy.symbols(\"v_ext_i\", real = True) \n",
    "                    ith_el_external_potential = ith_el_external_potential + v_ext_i\n",
    "                    ith_el_external_potential = ith_el_external_potential.replace(v_ext_i_placeholder, 0)\n",
    "                    j += 1\n",
    "                v_ext_placeholder = sympy.symbols(\"v_ext\", real = True)\n",
    "                external_potential = external_potential + ith_el_external_potential\n",
    "                external_potential = external_potential.replace(v_ext_placeholder, 0)\n",
    "                i += 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d805dbd0-7f19-4e1d-b54b-d8eac5f6d484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "energy_surface_optimizer = System_Energy_Optimizer(LR_o = 0.2, K = 0.8, t = 0, input_tensor = initial_state_floats, C_i_C_n = H_f_val, H_o_H_f = hidden_states, hidden_state_eqns = hidden_state_eqns, W_o_W_f = weight_eqns, B_o_B_f = bias_eqns, lin_regs = lin_eqns, E_xc = \"GGA\", n_bonding_electrons = 42, n_atoms = 7, unit_charge = 1.6e-19, atomic_orbital_states = bonding_states, R_inner = 0.01, delta_o_cut = 0.5, maximum_density_bound = 11, gradient_descent_schedule = \"MBGD\", exponential_range = exponential_range, nuclear_separation_matrix = nuclear_separation_matrix, bond_separation_matrix = bond_separation_matrix, pos_matrix = pos_matrix, degree_vector = degree_vector, atomic_positions = bond_separation_set, maximum_s_el = molecular_graph_details.maximum_s_el, maximum_p_el = molecular_graph_details.maximum_p_el, maximum_d_el = molecular_graph_details.maximum_d_el, maximum_f_el = molecular_graph_details.maximum_f_el, aromatic_rings = aromatic_rings, aromatic_cages = aromatic_cages, orbital_tracker = 0, KS_functional_tracker = \"\")\n",
    "#print(energy_surface_optimizer.construct_grad_descent_schedule(energy_surface_optimizer.LR_o, energy_surface_optimizer.t, energy_surface_optimizer.K, energy_surface_optimizer.gradient_descent_schedule))\n",
    "#basis_set = energy_surface_optimizer.compute_system_energy_eigenval(energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.E_xc, energy_surface_optimizer.n_bonding_electrons, energy_surface_optimizer.n_atoms, energy_surface_optimizer.unit_charge, energy_surface_optimizer.R_inner, energy_surface_optimizer.delta_o_cut, energy_surface_optimizer.maximum_density_bound, energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.exponential_range)\n",
    "#print(energy_wsurface_optimizer.C_i_C_n[0][energy_surface_optimizer.atomic_orbital_states[\"p\"][1]])\n",
    "#print(type(energy_surface_optimizer.atomic_orbital_states[\"p\"][1]))\n",
    "#print(energy_surface_optimizer.exponential_range)\n",
    "#print(energy_surface_optimizer.compute_system_energy_eigenval(energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.E_xc, energy_surface_optimizer.n_bonding_electrons, energy_surface_optimizer.n_atoms, energy_surface_optimizer.unit_charge, energy_surface_optimizer.R_inner, energy_surface_optimizer.delta_o_cut, energy_surface_optimizer.maximum_density_bound, energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.exponential_range, energy_surface_optimizer.nuclear_separation_matrix, energy_surface_optimizer.bond_separation_matrix, energy_surface_optimizer.degree_vector, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el, energy_surface_optimizer.orbital_tracker, energy_surface_optimizer.KS_functional_tracker, energy_surface_optimizer.pos_matrix))\n",
    "#maximum_density_radii, domain_overlap_matrix, inner_overlap_distances, outer_overlap_distances = energy_surface_optimizer.compute_effective_density_cutoffs(energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.n_atoms, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el, energy_surface_optimizer.R_inner, energy_surface_optimizer.maximum_density_bound, energy_surface_optimizer.bond_separation_matrix, energy_surface_optimizer.pos_matrix, energy_surface_optimizer.nuclear_separation_matrix)\n",
    "#print(maximum_density_radii, domain_overlap_matrix, inner_overlap_distances, outer_overlap_distances)\n",
    "#single_el_orbitals, single_el_eqns, r = energy_surface_optimizer.construct_single_electron_wavefunctions(energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.n_atoms, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el)  \n",
    "#print(single_el_orbitals)\n",
    "print(energy_surface_optimizer.MC_functional_integration_estimate(energy_surface_optimizer.input_tensor, energy_surface_optimizer.n_atoms, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el, energy_surface_optimizer.R_inner, energy_surface_optimizer.delta_o_cut, energy_surface_optimizer.maximum_density_bound, energy_surface_optimizer.nuclear_separation_matrix, energy_surface_optimizer.atomic_positions, energy_surface_optimizer.aromatic_rings, energy_surface_optimizer.aromatic_cages, energy_surface_optimizer.orbital_tracker, energy_surface_optimizer.KS_functional_tracker))\n",
    "#print(energy_surface_optimizer.test_bond_max_algorithm(energy_surface_optimizer.nuclear_separation_matrix, energy_surface_optimizer.degree_vector, energy_surface_optimizer.delta_o_cut, energy_surface_optimizer.input_tensor, energy_surface_optimizer.atomic_orbital_states, energy_surface_optimizer.C_i_C_n, energy_surface_optimizer.n_atoms, energy_surface_optimizer.exponential_range, energy_surface_optimizer.maximum_s_el, energy_surface_optimizer.maximum_p_el, energy_surface_optimizer.maximum_d_el, energy_surface_optimizer.maximum_f_el))                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47dbd7-7dbc-4a89-8de2-54fd8c1f6104",
   "metadata": {},
   "outputs": [],
   "source": [
    " while i < 84:\n",
    "            print(i)\n",
    "            for j in np.arange(0, len(aromatic_rings)):\n",
    "                if single_electron_wavefunctions[i+1] in aromatic_rings[j]:\n",
    "                    nucleus_on_ring = True\n",
    "                    electron_i_aromatic_ring = j\n",
    "                    known_rings = np.append(known_rings, j)\n",
    "                else:\n",
    "                    nucleus_on_ring = False\n",
    "            for k in np.arange(0, len(aromatic_cages)):\n",
    "                if single_electron_wavefunctions[i+1] in aromatic_cages[j]:\n",
    "                    nucleus_on_cage = True\n",
    "                    electron_i_cage_surface = j\n",
    "                    known_cages = np.append(known_cages, j)\n",
    "                else:\n",
    "                    nucleus_on_cage = False\n",
    "            if nucleus_on_ring == True:\n",
    "                ring_atom_separations = np.array([])\n",
    "                for k in np.arange(0, len(aromicatic_rings[electron_i_aromatic_ring])):\n",
    "                    ring_atom_separations = np.append(ring_atom_separations, np.sqrt(pos_matrix[single_electron_wavefunctions[i+1]][0]**2 + pos_matrix[single_electron_wavefunctions[i+1]][1]**2 + pos_matrix[single_electron_wavefunctions[i+1]][2]**2))\n",
    "                ring_density_gradient_steps = np.append(ring_density_gradient_steps, (max(ring_atom_separations) - 2*R_inner) / gradient_eval_samples)\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    ring_density_gradient_eval_set = np.append(ring_density_gradient_eval_set, R_inner + j * density_gradient_steps[i])\n",
    "                    j += 1\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    current_gradient_sample = ith_electron_density_gradient.replace(r, ring_density_gradient_eval_set[j])\n",
    "                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                    ring_gradient_changes.append(current_gradient_change)\n",
    "                    prev_gradient_sample = current_gradient_sample\n",
    "                    j += 1\n",
    "                gradient_min = min(ring_gradient_changes)\n",
    "                gradient_min_separation = ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)]\n",
    "                preceeding_density_vals = [ith_electron_density_surface.replace(r, gradient_min_separation - 0.01), ith_electron_density_surface.replace(r, gradient_min_separation - 0.02), ith_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                next_density_vals = [ith_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.01), ith_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.02), ith_electron_density_surface.replace(r, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                preceeding_radial_pos = [ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] - 0.01, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] - 0.02, ring_density_gradient_eval_set[ring_gradient_changes.index(gradient_min)] - 0.03]\n",
    "                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                preceeding_max = max(preceeding_density_vals)\n",
    "                next_max = max(next_density_vals)\n",
    "                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                if (ith_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(ring_atom_separations) - preceeding_max_pos)]) < R_inner) and (ith_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(ring_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                    RCPs = np.append(RCPs, gradient_min_separation)\n",
    "                possible_density_maxima = np.append(possible_density_maxima, R_inner)\n",
    "                possible_density_maxima = np.append(possible_density_maxima, RCPs)\n",
    "                for j in np.arange(0, len(ring_atom_separations)):\n",
    "                     possible_density_maxima = np.append(possible_density_maxima, ring_atom_separations[j] - R_inner)\n",
    "                least_separation_from_density_max = min(possible_density_maxima)\n",
    "            elif nucleus_on_cage == True:\n",
    "                for k in np.arange(0, len(aromicatic_cages[electron_i_cage_surface])):\n",
    "                    cage_atom_separations = np.append(cage_atom_separations, np.sqrt(pos_matrix[single_electron_wavefunctions[i+1]][0]**2 + pos_matrix[single_electron_wavefunctions[i+1]][1]**2 + pos_matrix[single_electron_wavefunctions[i+1]][2]**2))\n",
    "                cage_density_gradient_steps = np.append(cage_density_gradient_steps, (max(cage_atom_separations) - 2*R_inner) / gradient_eval_samples)\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    cage_density_gradient_eval_set = np.append(cage_density_gradient_eval_set, R_inner + j * density_gradient_steps[i])\n",
    "                    j += 1\n",
    "                j = 0\n",
    "                while j <= gradient_eval_samples:\n",
    "                    current_gradient_sample = ith_electron_density_gradient.replace(r, cage_density_gradient_eval_set[j])\n",
    "                    current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                    cage_gradient_changes.append(current_gradient_change)\n",
    "                    prev_gradient_sample = current_gradient_sample\n",
    "                    j += 1\n",
    "                gradient_min = min(bond_gradient_changes)\n",
    "                gradient_min_separation = cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)]\n",
    "                preceeding_density_vals = [ith_electron_density_surface.replace(r, gradient_min_separation - 0.01), ith_electron_density_surface.replace(r, gradient_min_separation - 0.02), ith_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "                next_density_vals = [ith_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.01), ith_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.02), ith_electron_density_surface.replace(r, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "                preceeding_radial_pos = [cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] - 0.01, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] - 0.02, cage_density_gradient_eval_set[cage_gradient_changes.index(gradient_min)] - 0.03]\n",
    "                next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "                preceeding_max = max(preceeding_density_vals)\n",
    "                next_max = max(next_density_vals)\n",
    "                preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "                next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "                if (ith_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(max(cage_atom_separations) - preceeding_max_pos)]) < R_inner) and (ith_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(max(cage_atom_separations) - next_max_pos)]) < R_inner):\n",
    "                    CCPs = np.append(CCPs, gradient_min_separation)\n",
    "                possible_density_maxima = cage_atom_separations\n",
    "                possible_density_maxima = np.append(possible_density_maxima, CCPs)\n",
    "                least_separation_from_density_max = min(possible_density_maxima)\n",
    "            else:\n",
    "                bond_maximum_separation = max(nuclear_separation_matrix[single_electron_wavefunctions[i+1]])\n",
    "                bond_density_gradient_steps = np.append(bond_density_gradient_steps, bond_maximum_separation / gradient_eval_samples)\n",
    "            i += 2\n",
    "            #return single_electron_wavefunctions\n",
    "               # j = 0\n",
    "               # while j <= gradient_eval_samples:\n",
    "                    #bond_density_gradient_eval_set = np.append(bond_density_gradient_eval_set, R_inner + j * bond_density_gradient_steps[i])\n",
    "                    #j += 1\n",
    "            #ith_electron_density_surface = single_electron_wavefunctions[i+1]**2\n",
    "            #ith_electron_density_gradient = sympy.diff(ith_electron_density_surface, r)\n",
    "            #j = 0\n",
    "            #while j <= gradient_eval_samples:\n",
    "                #current_gradient_sample = ith_electron_density_gradient.replace(r, bond_density_gradient_eval_set[j])\n",
    "                #current_gradient_change = current_gradient_sample - prev_gradient_sample\n",
    "                #bond_gradient_changes.append(current_gradient_change)\n",
    "                #prev_gradient_sample = current_gradient_sample\n",
    "                #j += 1\n",
    "            #gradient_min = min(bond_gradient_changes)\n",
    "            #gradient_min_separation = bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)]\n",
    "            #preceeding_density_vals = [ith_electron_density_surface.replace(r, gradient_min_separation - 0.01), ith_electron_density_surface.replace(r, gradient_min_separation - 0.02), ith_electron_density_surface.replace(r, gradient_min_separation - 0.03)]\n",
    "            #next_density_vals = [ith_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.01), ith_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.02), ith_electron_density_surface.replace(r, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] + 0.03)]\n",
    "            #preceeding_radial_pos = [bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] - 0.01, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] - 0.02, bond_density_gradient_eval_set[bond_gradient_changes.index(gradient_min)] - 0.03]\n",
    "            #next_radial_pos = [gradient_min_separation + 0.01, gradient_min_separation + 0.02, gradient_min_separation + 0.03]\n",
    "            #preceeding_max = max(preceeding_density_vals)\n",
    "            #next_max = max(next_density_vals)\n",
    "            #preceeding_max_pos = preceeding_radial_pos[preceeding_density_vals.index(preceeding_max)]\n",
    "            #next_max_pos = next_radial_pos[next_density_vals.index(next_max)]\n",
    "            #if (ith_electron_density_surface.replace(r, gradient_min_separation) > preceeding_max or min([preceeding_max_pos, abs(bond_maximum_separation - preceeding_max_pos)]) < R_inner) and (ith_electron_density_surface.replace(r, gradient_min_separation) > next_max or min([next_max_pos, abs(bond_maximum_separation - next_max_pos)]) < R_inner):\n",
    "                #BCPs = np.append(BCPs, gradient_min_separation)\n",
    "            #possible_density_maxima = cage_atom_separations\n",
    "            #possible_density_maxima = np.append(possible_density_maxima, BCPs)\n",
    "       # while sample_count < n_random_samples:\n",
    "            #random_x = randrange(R_inner, maximum_density_bound)\n",
    "            #random_y = randrange(R_inner, maximum_density_bound)\n",
    "            #random_z = randrange(R_inner, maximum_density_bound)\n",
    "            #if np.sqrt((random_x - pos_matrix[i][0])**2 + (random_y - pos_matrix[i][1])**2 + (random_z - pos_matrix[i][2])**2) <= r_eff_max[i]:\n",
    "                #random_pos_samples = np.append(random_pos_samples, np.sqrt(random_x**2 + random_y**2 + random_z**2))\n",
    "                #sample_count += 1\n",
    "            #else:\n",
    "                #continue\n",
    "        #possible_density_maxima = np.arrray([])\n",
    "        #max_density_separations = np.array([])\n",
    "        #for j in np.arange(0, len(random_pos_samples)):\n",
    "            #for k in np.arange(0, len(possible_density_maxima)):\n",
    "                #max_density_separations = np.append(max_density_separations, abs(random_pos_samples[j] - possible_density_separations[k]))\n",
    "        #max_density_separations = max_density_separations.reshape(len(random_pos_samples), len(possible_density_maxima))\n",
    "       # for j in np.arange(0, len(max_density_separations)):\n",
    "            #point_pdf_score = np.append(point_pdf_score, min(max_density_separations[j]))\n",
    "        #for j in np.arange(0, n_atoms):\n",
    "            #v_ext = ith_electron_density_surface * (-atomic_numbers[j] / abs(atomic_positions[j] - r))\n",
    "           # wavefunction_domain_volume= (4/3) * np.pi * r_eff_max[i]**3\n",
    "            #for k in np.arange(0, n_random_samples):\n",
    "                #BCP_bias = sympy.exp(BCP_bias_decay * point_pdf_score[k])\n",
    "                #PDF = BCP_bias / wavefunction_domain_volume\n",
    "                #KS_functional_sample = v_ext.replace(r, random_pos_samples[k])\n",
    "                #MC_estimate = MC_estimate + KS_functional_sample\n",
    "            #MC_integral_approx = ((1 / PDF) / n_random_samples) + MC_estimate\n",
    "        #i += 2\n",
    "        #return MC_integral_approx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9bc9715-0c50-416e-ad9c-6dc0439873ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.  ]\n",
      " [-1.2  -2.19  0.  ]\n",
      " [-2.66  1.6   0.  ]\n",
      " [ 0.    5.4   0.  ]\n",
      " [ 1.62  1.    0.  ]\n",
      " [ 1.9  -1.92  0.  ]\n",
      " [ 0.   -4.7   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a09d1d6f-095a-4b2d-9b65-26035f292fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8384513726034*exp(-4.62*r) 4.8384513726034*exp(-4.62*r)\n",
      " 12.254282112114*exp(-10.98*r) 12.254282112114*exp(-10.98*r)\n",
      " 4.03350271109592*exp(-3.88*r) 4.03350271109592*exp(-3.88*r)\n",
      " 2.93239548478395*exp(-2.85*r) 2.93239548478395*exp(-2.85*r)\n",
      " 2.62638950400997*exp(-2.56*r) 2.62638950400997*exp(-2.56*r)\n",
      " 3.2934018875625*exp(-3.19*r) 3.2934018875625*exp(-3.19*r)\n",
      " 4.95910461147127*exp(-4.73*r) 4.95910461147127*exp(-4.73*r)\n",
      " 0.311313148682589*exp(-2.91*r) + 0.311313148682589*exp(-0.244*r)\n",
      " 0.31131314868259*exp(-2.91*r) + 0.31131314868259*exp(-0.244*r)\n",
      " 0.31131314868259*exp(-2.91*r) + 0.31131314868259*exp(-0.244*r)\n",
      " 0.31131314868259*exp(-2.91*r) + 0.31131314868259*exp(-0.244*r)\n",
      " 1.52695675706325*exp(-3.15*r) + 1.52695675706325*exp(-2.8*r)\n",
      " 1.52695675706325*exp(-3.15*r) + 1.52695675706325*exp(-2.8*r)\n",
      " 1.52695675706325*exp(-3.15*r) + 1.52695675706325*exp(-2.8*r)\n",
      " 1.52695675706324*exp(-3.15*r) + 1.52695675706324*exp(-2.8*r)\n",
      " 0.69532621842468*exp(-2.98*r) + 0.69532621842468*exp(-0.88*r)\n",
      " 0.69532621842468*exp(-2.98*r) + 0.69532621842468*exp(-0.88*r)\n",
      " 0.695326218424681*exp(-2.98*r) + 0.695326218424681*exp(-0.88*r)\n",
      " 0.69532621842468*exp(-2.98*r) + 0.69532621842468*exp(-0.88*r)\n",
      " 0.597614229908556*exp(-3.25*r) + 0.597614229908556*exp(-0.7*r)\n",
      " 0.597614229908554*exp(-3.25*r) + 0.597614229908554*exp(-0.7*r)\n",
      " 0.597614229908555*exp(-3.25*r) + 0.597614229908555*exp(-0.7*r)\n",
      " 0.597614229908554*exp(-3.25*r) + 0.597614229908554*exp(-0.7*r)\n",
      " 2.37774760617805*exp(-9.58*r) + 2.37774760617805*exp(-2.98*r)\n",
      " 2.37774760617806*exp(-9.58*r) + 2.37774760617806*exp(-2.98*r)\n",
      " 2.37774760617806*exp(-9.58*r) + 2.37774760617806*exp(-2.98*r)\n",
      " 2.37774760617806*exp(-9.58*r) + 2.37774760617806*exp(-2.98*r)\n",
      " 0.878844550387914*exp(-7.43*r) + 0.878844550387914*exp(-0.97*r)\n",
      " 0.878844550387914*exp(-7.43*r) + 0.878844550387914*exp(-0.97*r)\n",
      " 0.878844550387914*exp(-7.43*r) + 0.878844550387914*exp(-0.97*r)\n",
      " 0.878844550387912*exp(-7.43*r) + 0.878844550387912*exp(-0.97*r)\n",
      " 0.560452705223758*exp(-2.9*r) + 0.560452705223758*exp(-0.66*r)\n",
      " 0.560452705223758*exp(-2.9*r) + 0.560452705223758*exp(-0.66*r)\n",
      " 0.560452705223758*exp(-2.9*r) + 0.560452705223758*exp(-0.66*r)\n",
      " 0.560452705223758*exp(-2.9*r) + 0.560452705223758*exp(-0.66*r)]\n"
     ]
    }
   ],
   "source": [
    "# use 1-2 varibale MC integration to compute eigenvalues of KS potential energy functionals using random var sampling with bias along bond paths for all r or (r, r_prime) points within the maximum density radius of the nucleus from which the single-electron orbital in question originates: (also add to energy optimizer class)\n",
    "# remember: if 2 electrons both participating in the same bound are used in calculation of coulomb potential, compute overlap integral between M.O's of the 2 different electrons, then evaluate MC integration for the spherical sets of radial points between R_inner and maximum bound with 0 overlap in probability density for each electron separately, then add result of MC integration for coulomb functional for spherical set of points with probability density overlap.\n",
    "# paper links: https://deepblue.lib.umich.edu/bitstream/handle/2027.42/70465/JCPSA6-56-9-4419-1.pdf;sequence=2\n",
    "# https://pbr-book.org/4ed/Monte_Carlo_Integration/Monte_Carlo_Basics\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "KS_functional = \n",
    "#print(single_el_wavefunctions)\n",
    "#r = sympy.symbols(\"r\", real = True)\n",
    "#r_prime = sympy.symbols(\"r_prime\", real = True)\n",
    "#pos_var_list = [r, r_prime]\n",
    "#ex_fxn = 2.5e+10 * sympy.exp(0.53 * r) + 3.3e+10 * sympy.exp(2.2 * r) + (1/(sympy.exp(2.72 * r_prime)))\n",
    "#new_ex_fxn = ex_fxn * (235/(0.009-r))\n",
    "#reference_val = [0.01, 0.01]\n",
    "#degree = 5\n",
    "#print(energy_component_series_approx(new_ex_fxn, pos_var_list, reference_val, degree))\n",
    "#print(energy_component_series_approx(new_ex_fxn, pos_var_list, reference_val, degree).replace(r, reference_val[0] + 2).replace(r_prime, reference_val[1] + 2))\n",
    "#print(new_ex_fxn.replace(r, reference_val[0] + 2).replace(r_prime, reference_val[1] + 2))\n",
    "\n",
    "#test_series = sympy.series(new_ex_fxn, r_prime)\n",
    "#test_series = sympy.series(test_series, r)\n",
    "#print(test_series)\n",
    "#simplified_fxn = 2.5e+10 * sympy.exp(0.53 * r) + 3.3e+10 * sympy.exp(2.2 * r)\n",
    "#print(energy_component_series_approx(simplified_fxn, [r], [0.01], 5))\n",
    "#series = sympy.series(new_ex_fxn, r2, x0 = 0.01)\n",
    "#series = sympy.\n",
    "#print(series)\n",
    "#series_int = sympy.integrals.integrate(series, r)\n",
    "#series_int_str = \"log(2.997) + \" + str(series_int) \n",
    "#series_int_str_replacement = \"\"\n",
    "#series_char_list = []\n",
    "#for i in range(0, len(series_int_str)):\n",
    "   #series_char_list.append(series_int_str[i])\n",
    "#for j in range(0, len(series_char_list)):\n",
    "    #if series_char_list[j] == \"r\":\n",
    "        #series_char_list[j] = str(10)\n",
    "    #elif series_char_list[j] == \"O\":\n",
    "        #drop_index = j\n",
    "    #else:\n",
    "        #j += 1\n",
    "#del series_char_list[drop_index - 2:]\n",
    "#for k in range(0, len(series_char_list)):\n",
    "    #series_int_str_replacement = series_int_str_replacement + series_char_list[k]\n",
    "#series_int = sympy.parsing.sympy_parser.parse_expr(series_int_str_replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccd2bf-6d9e-456f-95db-8fae45d40189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_seq = np.arange(0, 5, 10e-5)\n",
    "rand = np.random.choice(np.random.permutation(ex_seq))\n",
    "print(np.sqrt(rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38e9095b-81ad-4de6-b926-0b41fb5eddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0.]\n",
      "1\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[ 0.  -4.7  0. ]\n",
      "7\n",
      "[ 0.  -4.7  0. ]\n",
      "7\n",
      "[ 0.  -4.7  0. ]\n",
      "0\n",
      "[ 0.  -4.7  0. ]\n",
      "0\n",
      "[ 0.  -4.7  0. ]\n",
      "0\n",
      "[ 0.  -4.7  0. ]\n",
      "0\n",
      "[0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0.]\n",
      "1\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-1.2  -2.19  0.  ]\n",
      "2\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[-2.66  1.6   0.  ]\n",
      "3\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[0.  5.4 0. ]\n",
      "4\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[1.62 1.   0.  ]\n",
      "5\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[ 1.9  -1.92  0.  ]\n",
      "6\n",
      "[[ 0.    0.    0.  ]\n",
      " [-1.2  -2.19  0.  ]\n",
      " [-2.66  1.6   0.  ]\n",
      " [ 0.    5.4   0.  ]\n",
      " [ 1.62  1.    0.  ]\n",
      " [ 1.9  -1.92  0.  ]\n",
      " [ 0.   -4.7   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < energy_surface_optimizer.n_bonding_electrons:\n",
    "    print(pos_matrix[single_el_orbitals[2*i + 1] - 1])\n",
    "    print(single_el_orbitals[2*i+1])\n",
    "    i += 1\n",
    "print(pos_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738bba28-5e45-477b-93be-a4dfe22f3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    " if prev_flag == True:\n",
    "                        xrange = np.arange(-directional_density_limit[0], directional_density_limit[0], 10e-3)\n",
    "                        yrange = np.arange(-directional_density_limit[0], directional_density_limit[0], 10e-3)\n",
    "                        zrange = np.arange(-directional_density_limit[0], directional_density_limit[0], 10e-3)\n",
    "                        random_x = np.random.choice(np.random.permutation(xrange))\n",
    "                        random_y = np.random.choice(np.random.permutation(yrange))\n",
    "                        random_z = np.random.choice(np.random.permutation(zrange))\n",
    "                        for j in np.arange(0, len(nucleus_a_inner_cutoffs)):\n",
    "                            if nucleus_a_inner_cutoffs[j] < (random_x**2 + random_y**2 + random_z**2)**(1/2) < corrected_nuclear_separations[j]:\n",
    "                                inner_cutoff_flag = True\n",
    "                        print((random_x**2 + random_y**2 + random_z**2)**(1/2))\n",
    "                        print(inner_cutoff_flag, sample_count)\n",
    "                        if inner_cutoff_flag == True:\n",
    "                            sample_count += 1\n",
    "                            prev_flag = True\n",
    "                        elif (random_x**2 + random_y**2 + random_z**2)**(1/2) >= R_inner and (random_x**2 + random_y**2 + random_z**2)**(1/2) <= r_eff_max[a]:\n",
    "                            random_pos_samples = np.append(random_pos_samples, (random_x**2 + random_y**2 + random_z**2)**(1/2))  \n",
    "                            prev_flag = False\n",
    "                            sample_count += 1\n",
    "                        else:\n",
    "                            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7deeaa5b-b7fe-486e-8c82-3cd936574999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "print(energy_surface_optimizer.n_bonding_electrons * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acc184-44c2-41da-a43f-c6fa54c065cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
