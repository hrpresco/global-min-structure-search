{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7793c01b-f689-47a6-89da-fdde3426872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6af5bd-3931-42ee-ac1c-8fdee7cf5a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/msxr0yxx71d4flsgsqvzh5c80000gn/T/ipykernel_26867/1287427792.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ea00d617-ded8-4c6c-8011-c9283137d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RGCN layer architecture for predictive cluster energy and structure model, set up forward and backward computation, n_layers = 11 (10 computational, 1 readout of SCF contraction coefficients) by default to ensure interdependency of electron density in all bonds on largest computed delocalized surfces\n",
    "class RGCN_layer:\n",
    "    def __init__(self, input_tensor, convolution_operation, computational_weight_paramaters, computational_bias_paramaters, computational_base_weights, computational_base_biases, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, orbital_overlap_schemes, activation_fxns, n_contraction_coefficients, atom_node_connections):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.convolution_operation = convolution_operation\n",
    "        self.weight_paramaters = weight_paramaters\n",
    "        self.bias_paramaters = bias_paramaters\n",
    "        self.base_weights = base_weights\n",
    "        self.base_biases = base_biases\n",
    "        self.orbital_overlap_schemes = orbital_overlap_schemes\n",
    "        self.activation_fxn = activation_fxn\n",
    "        self.n_contraction_coefficients = n_contraction_coefficients\n",
    "        self.atom_node_connections = atom_node_connections\n",
    "\n",
    "\n",
    "    def apply_convolution(self, convolution_operation, input_tensor):\n",
    "        H_i = input_tensor\n",
    "        H_i_T = H_i.transpose()\n",
    "        H_i_conv_T = H_i_T @ convolution_operation\n",
    "        H_i_conv = H_i_conv_T.transpose()\n",
    "        return H_i_conv, H_i_conv_T\n",
    "\n",
    "    def compute_weigths_given_orbital_overlap_types(self, orbital_overlap_schemes, base_weights, weight_paramaters, input_tensor):\n",
    "        i = 0\n",
    "        ith_state_weights = np.zeros((len(input_tensor), len(input_tensor)))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, computational_weight_paramaters will be set to an input_tensor * input_tensor matrix of ones, but will be set to the output of the update_weight_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_weights = weight_paramaters.transpose() @ base_weights\n",
    "            ith_state_weights = ith_state_weights + overlap_type_weights\n",
    "            i += 1\n",
    "        A_RBT = sympy.symbols(\"A_RBT\", real = True)\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        weight_expression = sympy.concrete.summations.Sum(A_RBT * computational_base_weights, (b, 1, len(orbital_overlap_schemes)))\n",
    "        return ith_state_weights, weight_expression\n",
    "\n",
    "    def compute_biases_given_orbital_overlap_types(self, orbital_overlap_schemes, base_biases, bias_paramaters, input_tensor):\n",
    "        i = 0\n",
    "        ith_state_biases = np.zeros((len(input_tensor),))\n",
    "        for i in np.arange(0, len(orbital_overlap_schemes)):\n",
    "            # initially, computational_bias_paramaters will be set to an input_tensor * 1 vector of ones, but will be set to the output of the update_bias_paramaters function in the backpropagation for all paramater_update_count > 1\n",
    "            overlap_type_biases = bias_paramaters @ base_biases\n",
    "            ith_state_biases = ith_state_biases + overlap_type_biases\n",
    "            i += 1\n",
    "        A_RBB = sympy.symbols(\"A_RBB\", real = True)\n",
    "        b = sympy.symbols(\"b\", real = True)\n",
    "        bias_expression = sympy.concrete.summations.Sum(A_RBB * base_biases, (b, l, len(orbital_overlap_schemes)))\n",
    "        return ith_state_biases, bias_expression\n",
    "\n",
    "\n",
    "    def lin_reg_operation(self, convolution_operation, input_tensor, weight_paramaters, bias_paramaters, base_weights, base_biases, orbital_overlap_schemes, atom_node_connections):\n",
    "        ith_state_weights, weight_expression = self.compute_weights_given_orbital_overlap_types(orbital_overlap_schemes, base_weights, weight_paramaters, input_tensor)\n",
    "        ith_state_biases, bias_expression = self.compute_biases_given_orbital_overlap_typers(orbital_overlap_schemes, base_biases, bias_paramaters, input_tensor)\n",
    "        H_i_conv, H_i_conv_T = self.apply_convolution(convolution_operation, input_tensor)\n",
    "        H_i_lin = np.array([])\n",
    "        H_i_lin = H_i_lin[np.newaxis, :]\n",
    "        H_i_lin_reg = H_i_conv_T @ ith_state_weights + ith_state_biases\n",
    "        i = 0\n",
    "        for i in np.arange(0, len(atom_node_connections)):\n",
    "            H_i_lin = np.append(H_i_lin, H_i_lin_reg[i] * (1/atom_node_connections[i]))\n",
    "            i += 1\n",
    "        H_i_lin = H_i_lin.reshape(H_i_lin, np.shape(H_i_lin_reg))\n",
    "        H_i_lin_T = H_i_lin.transpose()\n",
    "        CiR, W_R, H_i_conv_T, B_R = sympy.symbols(\"CiR\", \"W_R\", \"H_i_conv_T\", \"B_R\", real = True)\n",
    "        i = sympy.symbols(\"i\", real = True)\n",
    "        lin_reg_expression = sympy.concrete.summations.Sum((1/CiR) * (W_R * H_i_conv_T + B_R), (i, 1, len(atom_node_connections)))\n",
    "        return H_i_lin, H_i_lin_T, lin_reg_expression\n",
    "\n",
    "    \n",
    "    def gelu(self, input_tensor):\n",
    "        activation_output = (0.5 * input_tensor) * (1 + np.tanh(np.sqrt(2/np.pi) * (input_tensor + 0.044715*input_tensor**3)))\n",
    "        return activation_output\n",
    "\n",
    "    def forward_computational_graph_update(self, convolution_operation, input_tensor, computational_weight_paramaters, computational_bias_paramaters, computational_base_weights, computational_base_biases, orbital_overlap_schemes, activation_fxns, atom_node_connections):\n",
    "        computational_activation = activation_fxns[\"computational\"]\n",
    "        H_i_conv, H_i_conv_T = self.apply_convolution(convolution_operation, input_tensor)\n",
    "        ith_state_weights, ith_state_weight_expression = self.compute_computational_weights_given_orbital_overlap_types(orbital_overlap_schemes, computational_base_weights, computational_weight_paramaters, input_tensor)\n",
    "        ith_state_biases, ith_state_bias_expression = self.compute_computational_biases_given_orbital_overlap_typers(orbital_overlap_schemes, computational_base_biases, computational_bias_paramaters, input_tensor)\n",
    "        H_i_lin, H_i_lin_T, computational_lin_reg = self.computational_lin_reg_operation(convolution_operation, input_tensor, computational_weight_paramaters, computational_bias_paramaters, computational_base_weigts, computational_base_biases, orbital_overlap_schemes, atom_node_connections)\n",
    "        if computational_activation == \"gelu\":\n",
    "            H_i = self.gelu(H_i_lin)\n",
    "            H_i = sympy.symbols(\"H_i\", real = True)\n",
    "            gelu_expression = (0.5 * H_i) * (1 + sympy.functions.elementary.hyperbolic.tanh((sympy.sqrt(2/np.pi)) * (H_i + 0.044715*H_i**3)))\n",
    "        else:\n",
    "            computational_activation = None\n",
    "            pass\n",
    "        return H_i, H_i_conv, H_i_conv_T, H_i_lin, H_i_lin_T, ith_state_weights, ith_state_biases, ith_state_weight_expression, ith_state_bias_expression, gelu_expression\n",
    "\n",
    "    def forward_readout_graph_update(self, input_tensor, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, computational_weight_paramaters, computational_bias_paramaters, computational_base_weights, computational_base_biases, orbital_overlap_schemes, activation_fxns, n_contraction_coefficients, atom_node_connections):\n",
    "        readout_activation = activation_fxns[\"readout\"]\n",
    "        nth_state_weights = self.compute_readout_weights_given_orbital_overlap_types(orbital_overlap_schemes, readout_base_weights, readout_weight_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        previous_layer_weights, nth_state_weight_expression = self.compute_computational_weigths_given_orbital_overlap_types(orbital_overlap_schemes, computational_base_weights, computational_weight_paramaters, input_tensor)\n",
    "        nth_state_biases = self.compute_readout_biases_given_orbital_overlap_typers(orbital_overlap_schemes, readout_base_biases, readout_bias_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        previous_layer_biases, nth_state_bias_expression = self.compute_computational_biases_given_orbital_overlap_types(orbital_overlap_schemes, computational_base_biases, computational_bias_paramaters, input_tensor)\n",
    "        H_n_lin, readout_lin_reg = self.readout_lin_reg_operation(input_tensor, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, orbital_overlap_schemes, n_contraction_coefficients, atom_node_connections)\n",
    "        if readout_activation == \"Lrelu\":\n",
    "            H_n = self.Lrelu(H_n_lin)\n",
    "            H_n = sympy.symbols(\"H_n\", real = True)\n",
    "            Lrelu_expression = sympy.Piecewise((0.01 * H_n, H_n < 0), (H_n, H_n >= 0))\n",
    "        else:\n",
    "            readout_activation = None\n",
    "            pass\n",
    "        return H_n, H_n_lin, nth_state_weights, nth_state_biases, nth_state_weight_expression, nth_state_bias_expression, Lrelu_expression\n",
    "            \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f8bfeb49-65ee-4d49-91c3-5db7ac7c4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    ", H_i_lin_T.transpose()[i] * (1/atom_node_connections[i]))\n",
    "            i += 1\n",
    "        H_i_lin = H_i_lin.reshape(H_i_lin, np.shape(H_i_lin_T.transpose()))\n",
    "        H_i_lin_T = H_i_lin.transpose()\n",
    "        CiR, W_R, H_i_conv_T, B_R = sympy.symbols(\"CiR\", \"W_R\", \"H_i_conv_T\", \"B_R\", real = True)\n",
    "        i = sympy.symbols(\"i\", real = True)\n",
    "        computational_lin_reg_expression = sympy.concrete.summations.Sum((1/CiR) * (W_R * H_i_conv_T + B_R), (i, 1, len(atom_node_connections)))\n",
    "        return H_i_lin, H_i_lin_T, computational_lin_reg_expression\n",
    "\n",
    "     def readout_lin_reg_operation(self, input_tensor, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, orbital_overlap_schemes, n_contraction_coefficients, atom_node_connections):\n",
    "        nth_state_weights = self.compute_readout_weights_given_orbital_overlap_types(orbital_overlap_schemes, readout_base_weights, readout_weight_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        nth_state_biases = self.compute_readout_biases_given_orbital_overlap_typers(orbital_overlap_schemes, readout_base_biases, readout_bias_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        H_n_lin = np.array([])\n",
    "        H_n_lin = H_n_lin[np.newaxis, :]\n",
    "        H_n_lin_reg = input_tensor @ nth_state_weights + nth_state_biases\n",
    "        i = 0\n",
    "        for i in np.arange(0, len(atom_node_connections)):\n",
    "            H_n_lin = np.append(H_n_lin, \n",
    "        H_n_lin = H_n_lin @ (1 / atom_node_connections)\n",
    "        return H_n_lin\n",
    "\n",
    "    def Lrelu(self, input_tensor):\n",
    "        activation_output = np.maximum(input_tensor, 0.01 * input_tensor)\n",
    "        return activation_output\n",
    "\n",
    "    def gelu(self, input_tensor):\n",
    "        activation_output = (0.5 * input_tensor) * (1 + np.tanh(np.sqrt(2/np.pi) * (input_tensor + 0.044715*input_tensor**3)))\n",
    "        return activation_output\n",
    "\n",
    "\n",
    "    def forward_readout_graph_update(self, input_tensor, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, orbital_overlap_schemes, activation_fxns, n_contraction_coefficients):\n",
    "        readout_activation = activation_fxns[\"readout\"]\n",
    "        nth_state_weights = self.compute_readout_weights_given_orbital_overlap_types(orbital_overlap_schemes, readout_base_weights, readout_weight_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        nth_state_biases = self.compute_readout_biases_given_orbital_overlap_typers(orbital_overlap_schemes, readout_base_biases, readout_bias_paramaters, input_tensor, n_contraction_coefficients)\n",
    "        H_n_lin = self.readout_lin_reg_operation(input_tensor, readout_weight_paramaters, readout_bias_paramaters, readout_base_weights, readout_base_biases, orbital_overlap_schemes, n_contraction_coefficients)\n",
    "        if readout_activation == \"Lrelu\":\n",
    "            H_n = self.Lrelu(H_n_lin)\n",
    "            H_n = sympy.symbols(\"H_n\", real = True)\n",
    "            Lrelu_expression = sympy.Piecewise((0.01 * H_n, H_n < 0), (H_n, H_n >= 0))\n",
    "        else:\n",
    "            readout_activation = None\n",
    "            pass\n",
    "        return H_n, H_n_lin, nth_state_weights, nth_state_biases, Lrelu_expression\n",
    "            \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afa721d-ce34-4e07-90b7-99f2a7c2ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.    0.25] [-1.  4.]\n"
     ]
    }
   ],
   "source": [
    "mat_1 = np.array([[-1,3], [2,0]])\n",
    "mat_2 = np.array([[7,-3], [-2,6]])\n",
    "eigenval_1, eigenvec_1, = np.linalg.eig(mat_1)\n",
    "eigenval_2, eigenvec_2 = np.linalg.eig(mat_2)\n",
    "new_mat = np.array([[(-3/4), 1/2], [1/2, 0]])\n",
    "new_mat_inv = np.linalg.inv(new_mat)\n",
    "eigval, eigvec = np.linalg.eig(new_mat)\n",
    "eigval_inv, eigvec_inv = np.linalg.eig(new_mat_inv)\n",
    "print(eigval, eigval_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9fcf2-6a4e-4855-9770-c4e0f716d7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
